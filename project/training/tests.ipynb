{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cf8877-b77d-4b94-a229-ece6a2b2a5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebcb5fb4-4014-498c-8156-e0287fd84d94",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: (('T1', 'T2', 'T3'), 1),\n",
       " 2: (('T1', 'T2', 'T4'), 1),\n",
       " 3: (('T1', 'T2', 'T5'), 1),\n",
       " 4: (('T1', 'T3', 'T4'), 1),\n",
       " 5: (('T1', 'T3', 'T5'), 1),\n",
       " 6: (('T1', 'T4', 'T5'), 1),\n",
       " 7: (('T2', 'T3', 'T4'), 1),\n",
       " 8: (('T2', 'T3', 'T5'), 1),\n",
       " 9: (('T2', 'T4', 'T5'), 1),\n",
       " 10: (('T3', 'T4', 'T5'), 1),\n",
       " 11: (('T1', 'T2', 'T3', 'T4'), 1),\n",
       " 12: (('T1', 'T2', 'T3', 'T5'), 1),\n",
       " 13: (('T1', 'T2', 'T4', 'T5'), 1),\n",
       " 14: (('T1', 'T3', 'T4', 'T5'), 1),\n",
       " 15: (('T2', 'T3', 'T4', 'T5'), 1),\n",
       " 16: (('T1', 'T2', 'T3', 'T4', 'T5'), 1),\n",
       " 17: (('T1', 'T2', 'T3'), 2),\n",
       " 18: (('T1', 'T2', 'T4'), 2),\n",
       " 19: (('T1', 'T2', 'T5'), 2),\n",
       " 20: (('T1', 'T3', 'T4'), 2),\n",
       " 21: (('T1', 'T3', 'T5'), 2),\n",
       " 22: (('T1', 'T4', 'T5'), 2),\n",
       " 23: (('T2', 'T3', 'T4'), 2),\n",
       " 24: (('T2', 'T3', 'T5'), 2),\n",
       " 25: (('T2', 'T4', 'T5'), 2),\n",
       " 26: (('T3', 'T4', 'T5'), 2),\n",
       " 27: (('T1', 'T2', 'T3', 'T4'), 2),\n",
       " 28: (('T1', 'T2', 'T3', 'T5'), 2),\n",
       " 29: (('T1', 'T2', 'T4', 'T5'), 2),\n",
       " 30: (('T1', 'T3', 'T4', 'T5'), 2),\n",
       " 31: (('T2', 'T3', 'T4', 'T5'), 2),\n",
       " 32: (('T1', 'T2', 'T3', 'T4', 'T5'), 2),\n",
       " 33: (('T1', 'T2', 'T3'), 3),\n",
       " 34: (('T1', 'T2', 'T4'), 3),\n",
       " 35: (('T1', 'T2', 'T5'), 3),\n",
       " 36: (('T1', 'T3', 'T4'), 3),\n",
       " 37: (('T1', 'T3', 'T5'), 3),\n",
       " 38: (('T1', 'T4', 'T5'), 3),\n",
       " 39: (('T2', 'T3', 'T4'), 3),\n",
       " 40: (('T2', 'T3', 'T5'), 3),\n",
       " 41: (('T2', 'T4', 'T5'), 3),\n",
       " 42: (('T3', 'T4', 'T5'), 3),\n",
       " 43: (('T1', 'T2', 'T3', 'T4'), 3),\n",
       " 44: (('T1', 'T2', 'T3', 'T5'), 3),\n",
       " 45: (('T1', 'T2', 'T4', 'T5'), 3),\n",
       " 46: (('T1', 'T3', 'T4', 'T5'), 3),\n",
       " 47: (('T2', 'T3', 'T4', 'T5'), 3),\n",
       " 48: (('T1', 'T2', 'T3', 'T4', 'T5'), 3),\n",
       " 49: (('T1', 'T2', 'T3'), 4),\n",
       " 50: (('T1', 'T2', 'T4'), 4),\n",
       " 51: (('T1', 'T2', 'T5'), 4),\n",
       " 52: (('T1', 'T3', 'T4'), 4),\n",
       " 53: (('T1', 'T3', 'T5'), 4),\n",
       " 54: (('T1', 'T4', 'T5'), 4),\n",
       " 55: (('T2', 'T3', 'T4'), 4),\n",
       " 56: (('T2', 'T3', 'T5'), 4),\n",
       " 57: (('T2', 'T4', 'T5'), 4),\n",
       " 58: (('T3', 'T4', 'T5'), 4),\n",
       " 59: (('T1', 'T2', 'T3', 'T4'), 4),\n",
       " 60: (('T1', 'T2', 'T3', 'T5'), 4),\n",
       " 61: (('T1', 'T2', 'T4', 'T5'), 4),\n",
       " 62: (('T1', 'T3', 'T4', 'T5'), 4),\n",
       " 63: (('T2', 'T3', 'T4', 'T5'), 4),\n",
       " 64: (('T1', 'T2', 'T3', 'T4', 'T5'), 4),\n",
       " 65: (('T1', 'T2', 'T3'), 5),\n",
       " 66: (('T1', 'T2', 'T4'), 5),\n",
       " 67: (('T1', 'T2', 'T5'), 5),\n",
       " 68: (('T1', 'T3', 'T4'), 5),\n",
       " 69: (('T1', 'T3', 'T5'), 5),\n",
       " 70: (('T1', 'T4', 'T5'), 5),\n",
       " 71: (('T2', 'T3', 'T4'), 5),\n",
       " 72: (('T2', 'T3', 'T5'), 5),\n",
       " 73: (('T2', 'T4', 'T5'), 5),\n",
       " 74: (('T3', 'T4', 'T5'), 5),\n",
       " 75: (('T1', 'T2', 'T3', 'T4'), 5),\n",
       " 76: (('T1', 'T2', 'T3', 'T5'), 5),\n",
       " 77: (('T1', 'T2', 'T4', 'T5'), 5),\n",
       " 78: (('T1', 'T3', 'T4', 'T5'), 5),\n",
       " 79: (('T2', 'T3', 'T4', 'T5'), 5),\n",
       " 80: (('T1', 'T2', 'T3', 'T4', 'T5'), 5)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def subsets(nums):\n",
    "    result = []\n",
    "    for i in range(len(nums) + 1):\n",
    "        result += itertools.combinations(nums, i)\n",
    "    return result\n",
    "\n",
    "MIN_TASK_GROUP_SIZE = 3\n",
    "\n",
    "def get_vocab():\n",
    "    list_n_fcs = [1,2,3,4,5]\n",
    "    layers = ['n_denses_0','n_denses_1','n_denses_2','n_denses_3']\n",
    "    tasks = ['T1','T2','T3','T4','T5']\n",
    "    tasks_groups_list = subsets(tasks)\n",
    "    tasks_groups_list = [x for x in tasks_groups_list if len(x) >= MIN_TASK_GROUP_SIZE]\n",
    "    \n",
    "    tasks_groups_params = []\n",
    "    tasks_groups_id = []\n",
    "    \n",
    "    for i in range(len(list_n_fcs)):\n",
    "        for j in range(len(tasks_groups_list)):\n",
    "            tasks_groups_params.append((tasks_groups_list[j], list_n_fcs[i]))\n",
    "            tasks_groups_id.append(len(tasks_groups_list) * i + j + 1)\n",
    "    \n",
    "    vocab = dict(zip(tasks_groups_id, tasks_groups_params))\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fb65ef6-54ba-4b52-86ee-a6cb6d3e8a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ('n_denses_0', 1),\n",
       " 2: ('n_denses_1', 1),\n",
       " 3: ('n_denses_2', 1),\n",
       " 4: ('n_denses_3', 1),\n",
       " 5: ('n_denses_0', 2),\n",
       " 6: ('n_denses_1', 2),\n",
       " 7: ('n_denses_2', 2),\n",
       " 8: ('n_denses_3', 2),\n",
       " 9: ('n_denses_0', 3),\n",
       " 10: ('n_denses_1', 3),\n",
       " 11: ('n_denses_2', 3),\n",
       " 12: ('n_denses_3', 3),\n",
       " 13: ('n_denses_0', 4),\n",
       " 14: ('n_denses_1', 4),\n",
       " 15: ('n_denses_2', 4),\n",
       " 16: ('n_denses_3', 4),\n",
       " 17: ('n_denses_0', 5),\n",
       " 18: ('n_denses_1', 5),\n",
       " 19: ('n_denses_2', 5),\n",
       " 20: ('n_denses_3', 5)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_vocab_orig():\n",
    "    list_n_fcs = [1,2,3,4,5]\n",
    "    layers = ['n_denses_0','n_denses_1','n_denses_2','n_denses_3']\n",
    "    layers_params = []\n",
    "    layer_id = []\n",
    "    for i in range(len(list_n_fcs)):\n",
    "        for j in range(len(layers)):\n",
    "            layers_params.append((layers[j], list_n_fcs[i]))\n",
    "            layer_id.append(len(layers) * i + j + 1)\n",
    "    vocab = dict(zip(layer_id, layers_params))\n",
    "    return vocab\n",
    "\n",
    "get_vocab_orig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7131b4-42f7-4e93-9046-b457e52777d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f2979d-9ef8-44b9-877d-eed1ca4e837f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c449508c-6991-483c-ac8b-33189abe8913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ff00fba-8b7b-47e2-90db-b99319557746",
   "metadata": {},
   "source": [
    "# Testing Network Modification"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c789cdb-97b9-43ba-b201-b20b08f00ce1",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Input, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_tensor = Input(shape=(20,), name=\"input\")\n",
    "hidden = Dense(100, activation='relu')(input_tensor)\n",
    "out = Dense(10, activation='relu', name=\"out\")(hidden)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=out)\n",
    "model.compile(loss=\"mse\", optimizer='adam')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "out = Dense(5, activation='softmax', name='new_out')(model.layers[-2].output)\n",
    "\n",
    "new_model = Model(input_tensor, out)\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0f294d-dd93-430f-8d4b-4e3ae8e9bb40",
   "metadata": {},
   "source": [
    "# Test - Customized Loss Function"
   ]
  },
  {
   "cell_type": "raw",
   "id": "15e6d1ce-12d5-4e1e-b41e-aab37d59c089",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Input, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "def my_loss_func(y_true, y_pred):\n",
    "    print(y_true, y_pred)\n",
    "    squared_difference = tf.square(y_true - y_pred)\n",
    "    return tf.reduce_mean(squared_difference, axis=-1)\n",
    "\n",
    "\n",
    "def _controller_loss(y_true, y_pred):\n",
    "    baseline = None\n",
    "    baseline_decay = 0.999\n",
    "    reward = 0\n",
    "\n",
    "    if baseline is None:\n",
    "        baseline = 0\n",
    "    else:\n",
    "        baseline -= (1 - baseline_decay) * (baseline - reward)\n",
    "    return y_pred * (reward - baseline)\n",
    "\n",
    "def _define_loss(controller_loss):\n",
    "    print(controller_loss)\n",
    "    a =  {f\"out\": controller_loss for i in range(4)}\n",
    "    print(a)\n",
    "    return a\n",
    "\n",
    "\n",
    "\n",
    "input_tensor = Input(shape=(4), name=\"input\")\n",
    "hidden = Dense(64, activation='relu')(input_tensor)\n",
    "out = Dense(4, activation='softmax', name=\"out\")(hidden)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=out)\n",
    "#model.compile(loss=my_loss_func, optimizer='adam')\n",
    "model.compile(loss=_define_loss(_controller_loss), optimizer='adam')\n",
    "\n",
    "#print(model.summary())\n",
    "\n",
    "#x = np.random.rand(4,4)\n",
    "#y = np.random.rand(4,1)\n",
    "\n",
    "x = np.matrix([[2,1,4,5], [3,4,5,2]], dtype='float32').A\n",
    "y = np.array([4,2], dtype='float32')\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "H = model.fit(x, y, epochs=3, batch_size=1)\n",
    "H.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858fca27-778a-46ce-802c-bcdf6c695d43",
   "metadata": {},
   "source": [
    "# Test - "
   ]
  },
  {
   "cell_type": "raw",
   "id": "aa7ea0d3-b1bb-478b-a186-85d57e8e0e24",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "# disable tensorflow log level infos\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # show only errors\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def __create_rnn_model():\n",
    "    model = Sequential([\n",
    "        Dense(4, activation=\"relu\"),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(4, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(), metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "def __preprocess_config(config):\n",
    "    return np.linalg.norm(config)\n",
    "    \n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "X = np.random.rand(400,4)\n",
    "y = np.random.rand(400,4)\n",
    "\n",
    "# X = tf.expand_dims(X, axis=0)\n",
    "# y = np.expand_dims(y, axis=0)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "X_test = np.random.rand(20,4)\n",
    "y_test = np.random.rand(20,4)\n",
    "\n",
    "# X_test = tf.expand_dims(X_test, axis=0)\n",
    "# y_test = tf.expand_dims(y_test, axis=0)\n",
    "\n",
    "m = __create_rnn_model()\n",
    "\n",
    "m.fit(X,y, batch_size=32, epochs=5)\n",
    "\n",
    "loss, acc = m.evaluate(X_test,y_test, batch_size=32)\n",
    "\n",
    "print(f'loss: {loss}%')\n",
    "print(f'acc: {round(acc*100,2)}%')\n",
    "\n",
    "print(f'prediction: {m.predict(np.array(X_test[0]).reshape(1,4))}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
