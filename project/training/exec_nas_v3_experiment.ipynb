{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['NEPTUNE_API_TOKEN']=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI5NDc0ZmNhNi0wODFlLTRhYTktYjgwZS01MWJkMDMxNWJhNTAifQ==\"\n",
    "os.environ['NEPTUNE_PROJECT']=\"guilhermemg/icao-nets-training-2\"\n",
    "os.environ['NEPTUNE_NOTEBOOK_ID']=\"98a391a1-c710-40bd-aaf4-42c31862cbbe\"\n",
    "os.environ['NEPTUNE_NOTEBOOK_PATH']=\"training/exec_nas_experiment.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# disable tensorflow log level infos\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # show only errors\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> Restrict GPU memory growth: True\n"
     ]
    }
   ],
   "source": [
    "from src.m_utils import constants as cts\n",
    "from src.base.data_loaders.data_loader import DLName\n",
    "from src.base.gt_loaders.gt_names import GTName\n",
    "from src.exp_runner import ExperimentRunner\n",
    "\n",
    "from src.base.experiment.dataset.dataset import Dataset\n",
    "from src.base.experiment.evaluation.model_evaluator import DataSource, DataPredSelection\n",
    "from src.base.experiment.training.base_models import BaseModel\n",
    "from src.base.experiment.training.optimizers import Optimizer\n",
    "\n",
    "from src.m_utils.stl_approach import STLApproach\n",
    "from src.m_utils.mtl_approach import MTLApproach\n",
    "from src.m_utils.nas_mtl_approach import NAS_MTLApproach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Network runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Init ExperimentRunner -------------------\n",
      "---------------------------\n",
      "Parent Process ID: 76168\n",
      "Process ID: 94278\n",
      "---------------------------\n",
      "-----\n",
      "Use Neptune:  False\n",
      "-----\n",
      "-------------------\n",
      "Args: \n",
      "{'controller_params': {'controller_decay': 0.1,\n",
      "                       'controller_learning_rate': 0.01,\n",
      "                       'controller_loss_alpha': 0.9,\n",
      "                       'controller_lstm_dim': 100,\n",
      "                       'controller_momentum': 0.0,\n",
      "                       'controller_optimizer': <Optimizer.ADAM: 'Adam'>,\n",
      "                       'controller_sampling_epochs': 6,\n",
      "                       'controller_training_epochs': 5,\n",
      "                       'controller_use_predictor': True},\n",
      " 'exp_params': {'description': 'NAS with Approach 3',\n",
      "                'name': 'NAS experiment',\n",
      "                'src_files': ['../src/**/*.py'],\n",
      "                'tags': ['mnist', 'nas', 'nas_approach_3']},\n",
      " 'mlp_params': {'max_architecture_length': 5,\n",
      "                'min_task_group_size': 3,\n",
      "                'mlp_base_model': <BaseModel.MOBILENET_V2: {'name': 'mobilnet_v2', 'target_size': (224, 224), 'prep_function': <function preprocess_input at 0x7feee9a9cf70>}>,\n",
      "                'mlp_batch_size': 64,\n",
      "                'mlp_decay': 0.0,\n",
      "                'mlp_dropout': 0.3,\n",
      "                'mlp_early_stopping': 50,\n",
      "                'mlp_learning_rate': 0.001,\n",
      "                'mlp_loss_function': 'sparse_categorical_crossentropy',\n",
      "                'mlp_momentum': 0.0,\n",
      "                'mlp_n_epochs': 50,\n",
      "                'mlp_one_shot': True,\n",
      "                'mlp_optimizer': <Optimizer.ADAMAX: 'Adamax'>},\n",
      " 'nas_params': {'architecture_training_epochs': 2,\n",
      "                'nas_algorithm': 'rl',\n",
      "                'nas_search_space': 'ss_1',\n",
      "                'samples_per_controller_epoch': 3,\n",
      "                'total_num_proposed_architectures': 6},\n",
      " 'properties': {'approach': <NAS_MTLApproach.APPROACH_3: 'approach_3'>,\n",
      "                'balance_input_data': False,\n",
      "                'dataset': <Dataset.MNIST: {'name': 'mnist', 'target_cols': ['n_0', 'n_1', 'n_2', 'n_3', 'n_4', 'n_5', 'n_6', 'n_7', 'n_8', 'n_9'], 'tasks': [<MNIST_TASK.N_0: 'n_0'>, <MNIST_TASK.N_1: 'n_1'>, <MNIST_TASK.N_2: 'n_2'>, <MNIST_TASK.N_3: 'n_3'>, <MNIST_TASK.N_4: 'n_4'>, <MNIST_TASK.N_5: 'n_5'>, <MNIST_TASK.N_6: 'n_6'>, <MNIST_TASK.N_7: 'n_7'>, <MNIST_TASK.N_8: 'n_8'>, <MNIST_TASK.N_9: 'n_9'>]}>,\n",
      "                'exec_nas': True,\n",
      "                'orig_model_experiment_id': '',\n",
      "                'sample_prop': 1.0,\n",
      "                'sample_training_data': False,\n",
      "                'save_trained_model': True,\n",
      "                'tasks': [<MNIST_TASK.N_0: 'n_0'>,\n",
      "                          <MNIST_TASK.N_1: 'n_1'>,\n",
      "                          <MNIST_TASK.N_2: 'n_2'>,\n",
      "                          <MNIST_TASK.N_3: 'n_3'>,\n",
      "                          <MNIST_TASK.N_4: 'n_4'>,\n",
      "                          <MNIST_TASK.N_5: 'n_5'>,\n",
      "                          <MNIST_TASK.N_6: 'n_6'>,\n",
      "                          <MNIST_TASK.N_7: 'n_7'>,\n",
      "                          <MNIST_TASK.N_8: 'n_8'>,\n",
      "                          <MNIST_TASK.N_9: 'n_9'>],\n",
      "                'train_model': True},\n",
      " 'use_neptune': False}\n",
      "-------------------\n",
      "----\n",
      "Base Model Name:  BaseModel.MOBILENET_V2\n",
      "----\n",
      "MTL Model: True\n",
      "Approach: NAS_MTLApproach.APPROACH_3\n",
      "NAS MTL Model: True\n",
      "----\n",
      "--------------------  starting neptune  -------------------\n",
      "Not using Neptune to record Experiment Metadata\n",
      "Model path:  trained_model\n",
      "----\n",
      "Checking model existence locally...\n",
      "Training a new model! Not checking model existence\n",
      "----\n",
      "------------------------------\n",
      "Checking GPU availability\n",
      " ..GPU is available!\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "DATASET = Dataset.MNIST\n",
    "APPROACH = NAS_MTLApproach.APPROACH_3\n",
    "\n",
    "kwargs = { \n",
    "    'use_neptune': False,\n",
    "    'exp_params' : {\n",
    "        'name': 'NAS experiment',\n",
    "        'description': 'NAS with Approach 3',\n",
    "        'tags': [f'{DATASET.value[\"name\"]}', 'nas', 'nas_approach_3'],\n",
    "        'src_files': [\"../src/**/*.py\"]\n",
    "    },\n",
    "    'properties': {\n",
    "        'approach': APPROACH,\n",
    "        'dataset': DATASET,\n",
    "        'tasks': DATASET.value['tasks'],\n",
    "        'balance_input_data': False,\n",
    "        'train_model': True,\n",
    "        'save_trained_model': True,\n",
    "        'exec_nas': True,\n",
    "        'orig_model_experiment_id': '',\n",
    "        'sample_training_data': False,\n",
    "        'sample_prop': 1.0\n",
    "    },\n",
    "    'nas_params': {\n",
    "        'samples_per_controller_epoch': 3,    # nas batch size (#architectures proposed per controller epoch)\n",
    "        'architecture_training_epochs': 2,     # n_epochs for training proposed architecture\n",
    "        'total_num_proposed_architectures': 6,\n",
    "        'nas_algorithm': 'rl',\n",
    "        'nas_search_space': 'ss_1'\n",
    "    },\n",
    "    'controller_params': {\n",
    "        'controller_lstm_dim': 100,\n",
    "        'controller_optimizer': Optimizer.ADAM,\n",
    "        'controller_learning_rate': 0.01,\n",
    "        'controller_decay': 0.1,\n",
    "        'controller_momentum': 0.0,\n",
    "        'controller_use_predictor': True,\n",
    "        'controller_loss_alpha': 0.9,\n",
    "        'controller_training_epochs': 5,\n",
    "        'controller_sampling_epochs': 6,\n",
    "    },\n",
    "    'mlp_params': {\n",
    "        'max_architecture_length': 5,\n",
    "        'min_task_group_size': 3,\n",
    "        'mlp_base_model': BaseModel.MOBILENET_V2,\n",
    "        'mlp_n_epochs': 50,\n",
    "        'mlp_batch_size': 64,\n",
    "        'mlp_early_stopping': 50,\n",
    "        'mlp_optimizer': Optimizer.ADAMAX,\n",
    "        'mlp_learning_rate': 1e-3,\n",
    "        'mlp_decay': 0.0,\n",
    "        'mlp_momentum': 0.0,\n",
    "        'mlp_dropout': 0.3,\n",
    "        'mlp_loss_function': 'sparse_categorical_crossentropy',\n",
    "        'mlp_one_shot': True\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "runner = ExperimentRunner(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- load training data -------------------\n",
      "Loading data\n",
      "TrainData.shape: (48000, 11)\n",
      "ValidationData.shape: (12000, 11)\n",
      "TestData.shape: (10000, 11)\n",
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "runner.load_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>n_0</th>\n",
       "      <th>n_1</th>\n",
       "      <th>n_2</th>\n",
       "      <th>n_3</th>\n",
       "      <th>n_4</th>\n",
       "      <th>n_5</th>\n",
       "      <th>n_6</th>\n",
       "      <th>n_7</th>\n",
       "      <th>n_8</th>\n",
       "      <th>n_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/guilherme/data1/Dropbox/Link to Desktop/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/guilherme/data1/Dropbox/Link to Desktop/...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/guilherme/data1/Dropbox/Link to Desktop/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/guilherme/data1/Dropbox/Link to Desktop/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/guilherme/data1/Dropbox/Link to Desktop/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_name  n_0  n_1  n_2  n_3  n_4  \\\n",
       "0  /home/guilherme/data1/Dropbox/Link to Desktop/...  0.0  0.0  0.0  0.0  1.0   \n",
       "1  /home/guilherme/data1/Dropbox/Link to Desktop/...  1.0  0.0  0.0  0.0  0.0   \n",
       "2  /home/guilherme/data1/Dropbox/Link to Desktop/...  0.0  1.0  0.0  0.0  0.0   \n",
       "3  /home/guilherme/data1/Dropbox/Link to Desktop/...  0.0  0.0  0.0  0.0  0.0   \n",
       "4  /home/guilherme/data1/Dropbox/Link to Desktop/...  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   n_5  n_6  n_7  n_8  n_9  \n",
       "0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  1.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  1.0  0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Producing Fake Data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- producing fake data for experimental purposes -------------------\n",
      "fake_train_data.shape: (500, 11)\n",
      "fake_validation_data_df.shape: (100, 11)\n",
      "fake_test_data_df.shape: (50, 11)\n"
     ]
    }
   ],
   "source": [
    "runner.produce_fake_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- setup data generators -------------------\n",
      "Starting data generators\n",
      "Found 500 validated image filenames.\n",
      "Found 100 validated image filenames.\n",
      "Found 50 validated image filenames.\n",
      "TOTAL: 650\n",
      "\n",
      "Logging class indices\n",
      " .. MTL model not logging class indices!\n",
      "\n",
      "Using benchmarking dataset. Not logging class labels!\n"
     ]
    }
   ],
   "source": [
    "runner.setup_data_generators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- create experiment -------------------\n",
      "Not using Neptune\n"
     ]
    }
   ],
   "source": [
    "runner.setup_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Labels Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "runner.summary_labels_dist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Architecture Search - v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- run neural architecture search -------------------\n",
      "Model path:  trained_model\n",
      "----\n",
      "Checking model existence locally...\n",
      "Training a new model! Not checking model existence\n",
      "----\n",
      "------------------------------\n",
      "Checking GPU availability\n",
      " ..GPU is available!\n",
      "------------------------------\n",
      "\n",
      "training model - len(self.data) 0\n",
      "\n",
      " ..new pred: [0.9834920124579731, 0.43657571122985284, 0.7616951771215359, 0.033818984896348936]\n",
      " ..converted pred: [4, 2, 3, 0]\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 1 | Feedback DNA: DNA([4, 2, 3, 0])\n",
      "----------------------------------------------------------------------\n",
      " -- Architecture 1: {'n_denses_0': 5, 'n_denses_1': 3, 'n_denses_2': 4, 'n_denses_3': 1}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 3,145,684\n",
      "  .. Trainable params: 887,700\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.92376, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.92376 to 0.91917, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "2/2 [==============================] - 1s 37ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.45830 | EER_interp: 0.45030 | ACC: 0.55000\n",
      "  Task  1: n_1             | EER_mean: 0.47170 | EER_interp: 0.46990 | ACC: 0.53000\n",
      "  Task  2: n_2             | EER_mean: 0.57410 | EER_interp: 0.56960 | ACC: 0.43000\n",
      "  Task  3: n_3             | EER_mean: 0.52940 | EER_interp: 0.51980 | ACC: 0.48000\n",
      "  Task  4: n_4             | EER_mean: 0.46810 | EER_interp: 0.46990 | ACC: 0.53000\n",
      "  Task  5: n_5             | EER_mean: 0.53330 | EER_interp: 0.53030 | ACC: 0.47000\n",
      "  Task  6: n_6             | EER_mean: 0.61110 | EER_interp: 0.59900 | ACC: 0.40000\n",
      "  Task  7: n_7             | EER_mean: 0.43180 | EER_interp: 0.43020 | ACC: 0.57000\n",
      "  Task  8: n_8             | EER_mean: 0.51110 | EER_interp: 0.51920 | ACC: 0.48000\n",
      "  Task  9: n_9             | EER_mean: 0.50980 | EER_interp: 0.51000 | ACC: 0.49000\n",
      "final_EER_mean: 50.68% | final_EER_median: 51.46% | final_EER_std_dv: 5.01% | final_ACC: 49.3%\n",
      " ..new data: [[DNA([4, 2, 3, 0]), 49.3]]\n",
      " ..len(self.data): 1\n",
      "logging data...\n",
      " ..self.data:  [[DNA([4, 2, 3, 0]), 49.3]]\n",
      "======================================================================\n",
      " ..new pred: [0.2842004566679871, 0.7810461173041533, 0.5833438145069784, 0.12952639680896416]\n",
      " ..converted pred: [1, 3, 2, 0]\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 2 | Feedback DNA: DNA([1, 3, 2, 0])\n",
      "----------------------------------------------------------------------\n",
      " -- Architecture 2: {'n_denses_0': 2, 'n_denses_1': 4, 'n_denses_2': 3, 'n_denses_3': 1}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 3,137,364\n",
      "  .. Trainable params: 879,380\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03802, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.03802\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "2/2 [==============================] - 1s 33ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.44230 | EER_interp: 0.43990 | ACC: 0.56000\n",
      "  Task  1: n_1             | EER_mean: 0.51060 | EER_interp: 0.50060 | ACC: 0.50000\n",
      "  Task  2: n_2             | EER_mean: 0.55560 | EER_interp: 0.54960 | ACC: 0.45000\n",
      "  Task  3: n_3             | EER_mean: 0.46940 | EER_interp: 0.46020 | ACC: 0.54000\n",
      "  Task  4: n_4             | EER_mean: 0.55320 | EER_interp: 0.54080 | ACC: 0.46000\n",
      "  Task  5: n_5             | EER_mean: 0.58180 | EER_interp: 0.60200 | ACC: 0.40000\n",
      "  Task  6: n_6             | EER_mean: 0.44440 | EER_interp: 0.43960 | ACC: 0.56000\n",
      "  Task  7: n_7             | EER_mean: 0.51790 | EER_interp: 0.50900 | ACC: 0.49000\n",
      "  Task  8: n_8             | EER_mean: 0.64440 | EER_interp: 0.64940 | ACC: 0.35000\n",
      "  Task  9: n_9             | EER_mean: 0.56860 | EER_interp: 0.57000 | ACC: 0.43000\n",
      "final_EER_mean: 52.61% | final_EER_median: 52.49% | final_EER_std_dv: 6.62% | final_ACC: 47.4%\n",
      " ..new data: [[DNA([4, 2, 3, 0]), 49.3], [DNA([1, 3, 2, 0]), 47.4]]\n",
      " ..len(self.data): 2\n",
      "logging data...\n",
      " ..self.data:  [[DNA([4, 2, 3, 0]), 49.3], [DNA([1, 3, 2, 0]), 47.4]]\n",
      "======================================================================\n",
      "\n",
      "training model - len(self.data) 2\n",
      "\n",
      " ..new pred: [0.8387677926363966, 0.2928008175170721, 0.9134980169258134, 0.8382549131208132]\n",
      " ..converted pred: [4, 1, 4, 4]\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 3 | Feedback DNA: DNA([4, 1, 4, 4])\n",
      "----------------------------------------------------------------------\n",
      " -- Architecture 3: {'n_denses_0': 5, 'n_denses_1': 2, 'n_denses_2': 5, 'n_denses_3': 5}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 3,208,084\n",
      "  .. Trainable params: 950,100\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.81372, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.81372\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "2/2 [==============================] - 1s 37ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.45830 | EER_interp: 0.45030 | ACC: 0.55000\n",
      "  Task  1: n_1             | EER_mean: 0.54720 | EER_interp: 0.53960 | ACC: 0.46000\n",
      "  Task  2: n_2             | EER_mean: 0.51850 | EER_interp: 0.50920 | ACC: 0.49000\n",
      "  Task  3: n_3             | EER_mean: 0.50980 | EER_interp: 0.49980 | ACC: 0.50000\n",
      "  Task  4: n_4             | EER_mean: 0.46810 | EER_interp: 0.46990 | ACC: 0.53000\n",
      "  Task  5: n_5             | EER_mean: 0.56360 | EER_interp: 0.55960 | ACC: 0.44000\n",
      "  Task  6: n_6             | EER_mean: 0.56520 | EER_interp: 0.56040 | ACC: 0.44000\n",
      "  Task  7: n_7             | EER_mean: 0.47730 | EER_interp: 0.47080 | ACC: 0.53000\n",
      "  Task  8: n_8             | EER_mean: 0.42220 | EER_interp: 0.42930 | ACC: 0.57000\n",
      "  Task  9: n_9             | EER_mean: 0.48980 | EER_interp: 0.48020 | ACC: 0.52000\n",
      "final_EER_mean: 49.69% | final_EER_median: 49.0% | final_EER_std_dv: 4.29% | final_ACC: 50.3%\n",
      " ..new data: [[DNA([4, 2, 3, 0]), 49.3], [DNA([1, 3, 2, 0]), 47.4], [DNA([4, 1, 4, 4]), 50.3]]\n",
      " ..len(self.data): 3\n",
      "logging data...\n",
      " ..self.data:  [[DNA([4, 2, 3, 0]), 49.3], [DNA([1, 3, 2, 0]), 47.4], [DNA([4, 1, 4, 4]), 50.3]]\n",
      "======================================================================\n",
      " ..new pred: [0.3738350978937687, 0.3196668033202221, 0.4383291438756043, 0.3472295188162653]\n",
      " ..converted pred: [1, 1, 2, 1]\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 4 | Feedback DNA: DNA([1, 1, 2, 1])\n",
      "----------------------------------------------------------------------\n",
      " -- Architecture 4: {'n_denses_0': 2, 'n_denses_1': 2, 'n_denses_2': 3, 'n_denses_3': 2}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 3,129,044\n",
      "  .. Trainable params: 871,060\n",
      "  .. Non-trainable params: 2,257,984\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7fee3c7cbee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.75998, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.75998\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fee544d7ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 38ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.54170 | EER_interp: 0.54010 | ACC: 0.46000\n",
      "  Task  1: n_1             | EER_mean: 0.53190 | EER_interp: 0.54900 | ACC: 0.45000\n",
      "  Task  2: n_2             | EER_mean: 0.46300 | EER_interp: 0.45980 | ACC: 0.54000\n",
      "  Task  3: n_3             | EER_mean: 0.46940 | EER_interp: 0.46020 | ACC: 0.54000\n",
      "  Task  4: n_4             | EER_mean: 0.46810 | EER_interp: 0.48880 | ACC: 0.51000\n",
      "  Task  5: n_5             | EER_mean: 0.50910 | EER_interp: 0.49900 | ACC: 0.50000\n",
      "  Task  6: n_6             | EER_mean: 0.57410 | EER_interp: 0.56960 | ACC: 0.43000\n",
      "  Task  7: n_7             | EER_mean: 0.44640 | EER_interp: 0.43910 | ACC: 0.56000\n",
      "  Task  8: n_8             | EER_mean: 0.53330 | EER_interp: 0.54840 | ACC: 0.45000\n",
      "  Task  9: n_9             | EER_mean: 0.40820 | EER_interp: 0.42960 | ACC: 0.57000\n",
      "final_EER_mean: 49.84% | final_EER_median: 49.39% | final_EER_std_dv: 4.81% | final_ACC: 50.1%\n",
      " ..new data: [[DNA([4, 2, 3, 0]), 49.3], [DNA([1, 3, 2, 0]), 47.4], [DNA([4, 1, 4, 4]), 50.3], [DNA([1, 1, 2, 1]), 50.1]]\n",
      " ..len(self.data): 4\n",
      "logging data...\n",
      " ..self.data:  [[DNA([4, 2, 3, 0]), 49.3], [DNA([1, 3, 2, 0]), 47.4], [DNA([4, 1, 4, 4]), 50.3], [DNA([1, 1, 2, 1]), 50.1]]\n",
      "======================================================================\n",
      "\n",
      "training model - len(self.data) 4\n",
      "\n",
      " ..new pred: [0.7725376981091557, 0.160364236295511, 0.3822838082414789, 0.9719543311041019]\n",
      " ..converted pred: [3, 0, 1, 4]\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 5 | Feedback DNA: DNA([3, 0, 1, 4])\n",
      "----------------------------------------------------------------------\n",
      " -- Architecture 5: {'n_denses_0': 4, 'n_denses_1': 1, 'n_denses_2': 2, 'n_denses_3': 5}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 3,166,484\n",
      "  .. Trainable params: 908,500\n",
      "  .. Non-trainable params: 2,257,984\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fedb40ab160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.85356, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.85356\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fedb4264f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 37ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.56250 | EER_interp: 0.55050 | ACC: 0.45000\n",
      "  Task  1: n_1             | EER_mean: 0.49060 | EER_interp: 0.49000 | ACC: 0.51000\n",
      "  Task  2: n_2             | EER_mean: 0.44440 | EER_interp: 0.43960 | ACC: 0.56000\n",
      "  Task  3: n_3             | EER_mean: 0.56570 | EER_interp: 0.55940 | ACC: 0.44000\n",
      "  Task  4: n_4             | EER_mean: 0.50940 | EER_interp: 0.49940 | ACC: 0.50000\n",
      "  Task  5: n_5             | EER_mean: 0.60000 | EER_interp: 0.60000 | ACC: 0.40000\n",
      "  Task  6: n_6             | EER_mean: 0.48150 | EER_interp: 0.46900 | ACC: 0.53000\n",
      "  Task  7: n_7             | EER_mean: 0.47730 | EER_interp: 0.46180 | ACC: 0.54000\n",
      "  Task  8: n_8             | EER_mean: 0.54550 | EER_interp: 0.53940 | ACC: 0.46000\n",
      "  Task  9: n_9             | EER_mean: 0.47060 | EER_interp: 0.49040 | ACC: 0.51000\n",
      "final_EER_mean: 50.99% | final_EER_median: 49.49% | final_EER_std_dv: 4.79% | final_ACC: 49.0%\n",
      " ..new data: [[DNA([4, 2, 3, 0]), 49.3], [DNA([1, 3, 2, 0]), 47.4], [DNA([4, 1, 4, 4]), 50.3], [DNA([1, 1, 2, 1]), 50.1], [DNA([3, 0, 1, 4]), 49.0]]\n",
      " ..len(self.data): 5\n",
      "logging data...\n",
      " ..self.data:  [[DNA([4, 2, 3, 0]), 49.3], [DNA([1, 3, 2, 0]), 47.4], [DNA([4, 1, 4, 4]), 50.3], [DNA([1, 1, 2, 1]), 50.1], [DNA([3, 0, 1, 4]), 49.0]]\n",
      "======================================================================\n",
      " ..new pred: [0.09795137868543258, 0.7110955343830873, 0.7300747680911281, 0.143364115483551]\n",
      " ..converted pred: [0, 3, 3, 0]\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 6 | Feedback DNA: DNA([0, 3, 3, 0])\n",
      "----------------------------------------------------------------------\n",
      " -- Architecture 6: {'n_denses_0': 1, 'n_denses_1': 4, 'n_denses_2': 4, 'n_denses_3': 1}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 3,141,524\n",
      "  .. Trainable params: 883,540\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.95729, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.95729\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "2/2 [==============================] - 1s 35ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.51920 | EER_interp: 0.50960 | ACC: 0.49000\n",
      "  Task  1: n_1             | EER_mean: 0.46810 | EER_interp: 0.45100 | ACC: 0.55000\n",
      "  Task  2: n_2             | EER_mean: 0.50000 | EER_interp: 0.50000 | ACC: 0.50000\n",
      "  Task  3: n_3             | EER_mean: 0.54900 | EER_interp: 0.53980 | ACC: 0.46000\n",
      "  Task  4: n_4             | EER_mean: 0.46810 | EER_interp: 0.46990 | ACC: 0.53000\n",
      "  Task  5: n_5             | EER_mean: 0.43640 | EER_interp: 0.40710 | ACC: 0.59000\n",
      "  Task  6: n_6             | EER_mean: 0.39130 | EER_interp: 0.39010 | ACC: 0.61000\n",
      "  Task  7: n_7             | EER_mean: 0.50000 | EER_interp: 0.50000 | ACC: 0.50000\n",
      "  Task  8: n_8             | EER_mean: 0.46670 | EER_interp: 0.46970 | ACC: 0.53000\n",
      "  Task  9: n_9             | EER_mean: 0.51020 | EER_interp: 0.51000 | ACC: 0.49000\n",
      "final_EER_mean: 47.47% | final_EER_median: 48.5% | final_EER_std_dv: 4.51% | final_ACC: 52.5%\n",
      " ..new data: [[DNA([4, 2, 3, 0]), 49.3], [DNA([1, 3, 2, 0]), 47.4], [DNA([4, 1, 4, 4]), 50.3], [DNA([1, 1, 2, 1]), 50.1], [DNA([3, 0, 1, 4]), 49.0], [DNA([0, 3, 3, 0]), 52.5]]\n",
      " ..len(self.data): 6\n",
      "logging data...\n",
      " ..self.data:  [[DNA([4, 2, 3, 0]), 49.3], [DNA([1, 3, 2, 0]), 47.4], [DNA([4, 1, 4, 4]), 50.3], [DNA([1, 1, 2, 1]), 50.1], [DNA([3, 0, 1, 4]), 49.0], [DNA([0, 3, 3, 0]), 52.5]]\n",
      "======================================================================\n",
      "\n",
      "\n",
      "------------------ TOP ARCHITECTURES FOUND --------------------\n",
      "Top 5 Architectures:\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_archs_list = runner.run_neural_architecture_search_v3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create Model with Best Architecture Found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_arch = {'n_denses_0':2,'n_denses_1':2,'n_denses_2':2,'n_denses_3':2}\n",
    "best_arch = best_archs_list[0]['Architecture'] if best_archs_list is not None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.create_model(best_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "runner.visualize_model(outfile_path=f\"training/figs/nas/nas_model_{APPROACH.name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "runner.model_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.draw_training_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.load_best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.set_model_evaluator_data_src(DataSource.VALIDATION)\n",
    "runner.test_model(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.set_model_evaluator_data_src(DataSource.TEST)\n",
    "runner.test_model(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Model Classification"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "runner.visualize_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finishing Experiment Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.finish_experiment()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "85f5044ba23e75135dc4c908fd4d7609c1c80b195047fdb4d16ee0e66a953254"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "neptune": {
   "notebookId": "98a3967a-428e-4576-add1-6bd753600673",
   "projectVersion": 2
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
