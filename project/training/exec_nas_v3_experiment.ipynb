{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['NEPTUNE_API_TOKEN']=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI5NDc0ZmNhNi0wODFlLTRhYTktYjgwZS01MWJkMDMxNWJhNTAifQ==\"\n",
    "os.environ['NEPTUNE_PROJECT']=\"guilhermemg/icao-nets-training-2\"\n",
    "os.environ['NEPTUNE_NOTEBOOK_ID']=\"98a391a1-c710-40bd-aaf4-42c31862cbbe\"\n",
    "os.environ['NEPTUNE_NOTEBOOK_PATH']=\"training/exec_nas_experiment.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# disable tensorflow log level infos\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # show only errors\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> Restrict GPU memory growth: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/base/experiment/evaluation/model_evaluator.py:10: NeptuneDeprecationWarning: You're importing the Neptune client library via the deprecated `neptune.new` module, which will be removed in a future release. Import directly from `neptune` instead.\n",
      "  from neptune.new.types import File\n"
     ]
    }
   ],
   "source": [
    "from src.m_utils import constants as cts\n",
    "from src.base.data_loaders.data_loader import DLName\n",
    "from src.base.gt_loaders.gt_names import GTName\n",
    "from src.exp_runner import ExperimentRunner\n",
    "\n",
    "from src.base.experiment.dataset.dataset import Dataset\n",
    "from src.base.experiment.evaluation.model_evaluator import DataSource, DataPredSelection\n",
    "from src.base.experiment.training.base_models import BaseModel\n",
    "from src.base.experiment.training.optimizers import Optimizer\n",
    "\n",
    "from src.m_utils.stl_approach import STLApproach\n",
    "from src.m_utils.mtl_approach import MTLApproach\n",
    "from src.m_utils.nas_mtl_approach import NAS_MTLApproach\n",
    "\n",
    "from src.nas.v3.nas_algorithm import NASAlgorithm\n",
    "from src.nas.v3.mlp_search_space import MLPSearchSpaceIndicator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Network Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Init ExperimentRunner -------------------\n",
      "---------------------------\n",
      "Parent Process ID: 10755\n",
      "Process ID: 161521\n",
      "---------------------------\n",
      "-----\n",
      "Use Neptune:  True\n",
      "-----\n",
      "-------------------\n",
      "Args: \n",
      "{'controller_params': {'controller_batch_size': 10,\n",
      "                       'controller_classes': 8,\n",
      "                       'controller_decay': 0.0,\n",
      "                       'controller_learning_rate': 0.006,\n",
      "                       'controller_loss_alpha': 0.3,\n",
      "                       'controller_lstm_dim': 100,\n",
      "                       'controller_max_proposed_arch_len': 8,\n",
      "                       'controller_momentum': 0.0,\n",
      "                       'controller_optimizer': <Optimizer.ADAM: 'Adam'>,\n",
      "                       'controller_training_epochs': 20,\n",
      "                       'controller_use_predictor': False},\n",
      " 'exp_params': {'description': 'NAS with Approach 3 - Testing parametrization '\n",
      "                               'of n_convs',\n",
      "                'name': 'NAS experiment',\n",
      "                'src_files': ['../src/**/*.py'],\n",
      "                'tags': ['mnist',\n",
      "                         'nas',\n",
      "                         'nas_approach_3_v3',\n",
      "                         'final_experiments_2']},\n",
      " 'mlp_params': {'mlp_base_model': <BaseModel.MOBILENET_V2: {'name': 'mobilnet_v2', 'target_size': (224, 224), 'prep_function': <function preprocess_input at 0x7f66c1dd3f70>}>,\n",
      "                'mlp_batch_size': 64,\n",
      "                'mlp_decay': 0.0,\n",
      "                'mlp_dropout': 0.3,\n",
      "                'mlp_early_stopping': 50,\n",
      "                'mlp_learning_rate': 0.001,\n",
      "                'mlp_loss_function': 'sparse_categorical_crossentropy',\n",
      "                'mlp_momentum': 0.0,\n",
      "                'mlp_n_epochs': 50,\n",
      "                'mlp_one_shot': False,\n",
      "                'mlp_optimizer': <Optimizer.ADAMAX: 'Adamax'>},\n",
      " 'nas_params': {'architecture_training_epochs': 5,\n",
      "                'nas_algorithm': <NASAlgorithm.RL: 'rl'>,\n",
      "                'nas_search_space': <MLPSearchSpaceIndicator.SS_2: {'name': 'ss_2', 'n_classes': 8}>,\n",
      "                'total_num_proposed_architectures': 30},\n",
      " 'properties': {'approach': <NAS_MTLApproach.APPROACH_3: 'approach_3'>,\n",
      "                'balance_input_data': False,\n",
      "                'dataset': <Dataset.MNIST: {'name': 'mnist', 'target_cols': ['n_0', 'n_1', 'n_2', 'n_3', 'n_4', 'n_5', 'n_6', 'n_7', 'n_8', 'n_9'], 'tasks': [<MNIST_TASK.N_0: 'n_0'>, <MNIST_TASK.N_1: 'n_1'>, <MNIST_TASK.N_2: 'n_2'>, <MNIST_TASK.N_3: 'n_3'>, <MNIST_TASK.N_4: 'n_4'>, <MNIST_TASK.N_5: 'n_5'>, <MNIST_TASK.N_6: 'n_6'>, <MNIST_TASK.N_7: 'n_7'>, <MNIST_TASK.N_8: 'n_8'>, <MNIST_TASK.N_9: 'n_9'>]}>,\n",
      "                'exec_nas': True,\n",
      "                'orig_model_experiment_id': '',\n",
      "                'sample_prop': 1,\n",
      "                'sample_training_data': False,\n",
      "                'save_trained_model': True,\n",
      "                'tasks': [<MNIST_TASK.N_0: 'n_0'>,\n",
      "                          <MNIST_TASK.N_1: 'n_1'>,\n",
      "                          <MNIST_TASK.N_2: 'n_2'>,\n",
      "                          <MNIST_TASK.N_3: 'n_3'>,\n",
      "                          <MNIST_TASK.N_4: 'n_4'>,\n",
      "                          <MNIST_TASK.N_5: 'n_5'>,\n",
      "                          <MNIST_TASK.N_6: 'n_6'>,\n",
      "                          <MNIST_TASK.N_7: 'n_7'>,\n",
      "                          <MNIST_TASK.N_8: 'n_8'>,\n",
      "                          <MNIST_TASK.N_9: 'n_9'>],\n",
      "                'train_model': True},\n",
      " 'use_neptune': True}\n",
      "-------------------\n",
      "----\n",
      "Base Model Name:  BaseModel.MOBILENET_V2\n",
      "----\n",
      "MTL Model: True\n",
      "Approach: NAS_MTLApproach.APPROACH_3\n",
      "NAS MTL Model: True\n",
      "----\n",
      "--------------------  starting neptune  -------------------\n",
      "Starting Neptune\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/m_utils/neptune_utils.py:27: NeptuneWarning: To avoid unintended consumption of logging hours during interactive sessions, the following monitoring options are disabled unless set to 'True' when initializing the run: 'capture_stdout', 'capture_stderr', and 'capture_hardware_metrics'.\n",
      "  self.neptune_run = neptune.init_run(name=self.config_interp.exp_args['name'],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/guilhermemg/icao-nets-training-2/e/ICAO-492\n",
      "----\n",
      "Model path:  trained_model\n",
      "----\n",
      "Checking model existence locally...\n",
      "Training a new model! Not checking model existence\n",
      "----\n",
      "------------------------------\n",
      "Checking GPU availability\n",
      " ..GPU is available!\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "DATASET = Dataset.MNIST\n",
    "APPROACH = NAS_MTLApproach.APPROACH_3\n",
    "\n",
    "kwargs = { \n",
    "    'use_neptune': True,\n",
    "    'exp_params' : {\n",
    "        'name': 'NAS experiment',\n",
    "        'description': 'NAS with Approach 3 - Testing parametrization of n_convs',\n",
    "        'tags': [f'{DATASET.value[\"name\"]}', 'nas', 'nas_approach_3_v3', 'final_experiments_2'],\n",
    "        'src_files': [\"../src/**/*.py\"]\n",
    "    },\n",
    "    'properties': {\n",
    "        'approach': APPROACH,\n",
    "        'dataset': DATASET,\n",
    "        'tasks': DATASET.value['tasks'],\n",
    "        'balance_input_data': False,\n",
    "        'train_model': True,\n",
    "        'save_trained_model': True,\n",
    "        'exec_nas': True,\n",
    "        'orig_model_experiment_id': '',\n",
    "        'sample_training_data': False,\n",
    "        'sample_prop': 1,\n",
    "    },\n",
    "    'nas_params': {\n",
    "        'architecture_training_epochs': 5,     # n_epochs for training proposed architecture\n",
    "        'total_num_proposed_architectures': 30,\n",
    "        'nas_algorithm': NASAlgorithm.RL,\n",
    "        'nas_search_space': MLPSearchSpaceIndicator.SS_2\n",
    "    },\n",
    "    'controller_params': {\n",
    "        'controller_max_proposed_arch_len': 8,   # == sss = 5 / tss = 6 / max_len = 8 (n_denses+n_convs)\n",
    "        'controller_classes': MLPSearchSpaceIndicator.SS_2.value['n_classes'],    # == n_candidates ==> sss = 8 / n_operations ==> tss = 5 / classes = 8 (n_denses+n_convs)\n",
    "        'controller_lstm_dim': 100,\n",
    "        'controller_optimizer': Optimizer.ADAM,\n",
    "        'controller_learning_rate': 0.006,\n",
    "        'controller_decay': 0.0,\n",
    "        'controller_momentum': 0.0,\n",
    "        'controller_use_predictor': False,\n",
    "        'controller_loss_alpha': 0.3,  # 0.9, 0.6, 0.3\n",
    "        'controller_training_epochs': 20,\n",
    "        'controller_batch_size': 10\n",
    "    },\n",
    "    'mlp_params': {\n",
    "        'mlp_base_model': BaseModel.MOBILENET_V2,\n",
    "        'mlp_n_epochs': 50,\n",
    "        'mlp_batch_size': 64,\n",
    "        'mlp_early_stopping': 50,\n",
    "        'mlp_optimizer': Optimizer.ADAMAX,\n",
    "        'mlp_learning_rate': 1e-3,\n",
    "        'mlp_decay': 0.0,\n",
    "        'mlp_momentum': 0.0,\n",
    "        'mlp_dropout': 0.3,\n",
    "        'mlp_loss_function': 'sparse_categorical_crossentropy',\n",
    "        'mlp_one_shot': False\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "runner = ExperimentRunner(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- load training data -------------------\n",
      "Loading data\n",
      "TrainData.shape: (48000, 11)\n",
      "ValidationData.shape: (12000, 11)\n",
      "TestData.shape: (10000, 11)\n",
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "runner.load_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- sample training data -------------------\n",
      "Not applying subsampling in training data!\n"
     ]
    }
   ],
   "source": [
    "runner.sample_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>n_0</th>\n",
       "      <th>n_1</th>\n",
       "      <th>n_2</th>\n",
       "      <th>n_3</th>\n",
       "      <th>n_4</th>\n",
       "      <th>n_5</th>\n",
       "      <th>n_6</th>\n",
       "      <th>n_7</th>\n",
       "      <th>n_8</th>\n",
       "      <th>n_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/guilherme/data1/Dropbox/Link to Desktop/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/guilherme/data1/Dropbox/Link to Desktop/...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/guilherme/data1/Dropbox/Link to Desktop/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/guilherme/data1/Dropbox/Link to Desktop/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/guilherme/data1/Dropbox/Link to Desktop/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_name  n_0  n_1  n_2  n_3  n_4  \\\n",
       "0  /home/guilherme/data1/Dropbox/Link to Desktop/...  0.0  0.0  0.0  0.0  1.0   \n",
       "1  /home/guilherme/data1/Dropbox/Link to Desktop/...  1.0  0.0  0.0  0.0  0.0   \n",
       "2  /home/guilherme/data1/Dropbox/Link to Desktop/...  0.0  1.0  0.0  0.0  0.0   \n",
       "3  /home/guilherme/data1/Dropbox/Link to Desktop/...  0.0  0.0  0.0  0.0  0.0   \n",
       "4  /home/guilherme/data1/Dropbox/Link to Desktop/...  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   n_5  n_6  n_7  n_8  n_9  \n",
       "0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  1.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  1.0  0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.train_data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# <font color='red'>Producing Fake Data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "runner.produce_fake_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- setup data generators -------------------\n",
      "Starting data generators\n",
      "Found 48000 validated image filenames.\n",
      "Found 12000 validated image filenames.\n",
      "Found 10000 validated image filenames.\n",
      "TOTAL: 70000\n",
      "\n",
      "Logging class indices\n",
      " .. MTL model not logging class indices!\n",
      "\n",
      "Using benchmarking dataset. Not logging class labels!\n"
     ]
    }
   ],
   "source": [
    "runner.setup_data_generators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- create experiment -------------------\n",
      "Setting up neptune experiment\n",
      "Neptune experiment setup done!\n"
     ]
    }
   ],
   "source": [
    "runner.setup_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Labels Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "runner.summary_labels_dist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Architecture Search - v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- run neural architecture search -------------------\n",
      " -- Using search space: {'name': 'ss_2', 'n_classes': 8}\n",
      " -- Using NAS algorithm: NASAlgorithm.RL\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "main_input (InputLayer)      [(None, 1, 10)]           0         \n",
      "_________________________________________________________________\n",
      "rnn (RNN)                    (None, 1, 100)            44400     \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1, 8)              808       \n",
      "=================================================================\n",
      "Total params: 45,208\n",
      "Trainable params: 45,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model path:  trained_model\n",
      "----\n",
      "Checking model existence locally...\n",
      "Training a new model! Not checking model existence\n",
      "----\n",
      "------------------------------\n",
      "Checking GPU availability\n",
      " ..GPU is available!\n",
      "------------------------------\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 1 | Feedback DNA: DNA([[2, 0, 2, 2], [2, 2, 2, 1]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 1: {'n_denses_0': 3, 'n_denses_1': 1, 'n_denses_2': 3, 'n_denses_3': 3, 'n_convs_0': 3, 'n_convs_1': 3, 'n_convs_2': 3, 'n_convs_3': 2}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,324,020\n",
      "  .. Trainable params: 4,066,036\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03224, saving model to training/training_ckpt/best_model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_loss improved from 0.03224 to 0.01306, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.01306\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01306 to 0.00753, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00753\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 11s 55ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00260 | EER_interp: 0.00230 | ACC: 0.99780\n",
      "  Task  1: n_1             | EER_mean: 0.00160 | EER_interp: 0.00160 | ACC: 0.99840\n",
      "  Task  2: n_2             | EER_mean: 0.00140 | EER_interp: 0.00110 | ACC: 0.99870\n",
      "  Task  3: n_3             | EER_mean: 0.00260 | EER_interp: 0.00250 | ACC: 0.99740\n",
      "  Task  4: n_4             | EER_mean: 0.00310 | EER_interp: 0.00320 | ACC: 0.99690\n",
      "  Task  5: n_5             | EER_mean: 0.00190 | EER_interp: 0.00190 | ACC: 0.99810\n",
      "  Task  6: n_6             | EER_mean: 0.00330 | EER_interp: 0.00320 | ACC: 0.99690\n",
      "  Task  7: n_7             | EER_mean: 0.00320 | EER_interp: 0.00300 | ACC: 0.99720\n",
      "  Task  8: n_8             | EER_mean: 0.00680 | EER_interp: 0.00620 | ACC: 0.99420\n",
      "  Task  9: n_9             | EER_mean: 0.00850 | EER_interp: 0.00840 | ACC: 0.99160\n",
      "final_EER_mean: 0.33% | final_EER_median: 0.27% | final_EER_std_dv: 0.21% | final_ACC: 99.67%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 2 | Feedback DNA: DNA([[2, 1, 1, 2], [2, 2, 1, 1]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 2: {'n_denses_0': 3, 'n_denses_1': 2, 'n_denses_2': 2, 'n_denses_3': 3, 'n_convs_0': 3, 'n_convs_1': 3, 'n_convs_2': 2, 'n_convs_3': 2}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,318,932\n",
      "  .. Trainable params: 4,060,948\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02390, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02390 to 0.01253, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01253 to 0.00582, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00582\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00582\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 11s 53ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00090 | EER_interp: 0.00060 | ACC: 0.99960\n",
      "  Task  1: n_1             | EER_mean: 0.00220 | EER_interp: 0.00220 | ACC: 0.99790\n",
      "  Task  2: n_2             | EER_mean: 0.00170 | EER_interp: 0.00160 | ACC: 0.99840\n",
      "  Task  3: n_3             | EER_mean: 0.00240 | EER_interp: 0.00230 | ACC: 0.99770\n",
      "  Task  4: n_4             | EER_mean: 0.00250 | EER_interp: 0.00240 | ACC: 0.99760\n",
      "  Task  5: n_5             | EER_mean: 0.00280 | EER_interp: 0.00280 | ACC: 0.99730\n",
      "  Task  6: n_6             | EER_mean: 0.00250 | EER_interp: 0.00250 | ACC: 0.99750\n",
      "  Task  7: n_7             | EER_mean: 0.00210 | EER_interp: 0.00180 | ACC: 0.99790\n",
      "  Task  8: n_8             | EER_mean: 0.00430 | EER_interp: 0.00400 | ACC: 0.99630\n",
      "  Task  9: n_9             | EER_mean: 0.00350 | EER_interp: 0.00340 | ACC: 0.99650\n",
      "final_EER_mean: 0.24% | final_EER_median: 0.23% | final_EER_std_dv: 0.09% | final_ACC: 99.77%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 3 | Feedback DNA: DNA([[2, 2, 1, 2], [2, 1, 1, 1]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 3: {'n_denses_0': 3, 'n_denses_1': 3, 'n_denses_2': 2, 'n_denses_3': 3, 'n_convs_0': 3, 'n_convs_1': 2, 'n_convs_2': 2, 'n_convs_3': 2}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,322,164\n",
      "  .. Trainable params: 4,064,180\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08654, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08654 to 0.01305, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01305 to 0.01165, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01165 to 0.00749, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00749 to 0.00491, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 11s 54ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00070 | EER_interp: 0.00000 | ACC: 0.99930\n",
      "  Task  1: n_1             | EER_mean: 0.00220 | EER_interp: 0.00200 | ACC: 0.99820\n",
      "  Task  2: n_2             | EER_mean: 0.00340 | EER_interp: 0.00320 | ACC: 0.99700\n",
      "  Task  3: n_3             | EER_mean: 0.00190 | EER_interp: 0.00180 | ACC: 0.99820\n",
      "  Task  4: n_4             | EER_mean: 0.00240 | EER_interp: 0.00240 | ACC: 0.99770\n",
      "  Task  5: n_5             | EER_mean: 0.00140 | EER_interp: 0.00120 | ACC: 0.99870\n",
      "  Task  6: n_6             | EER_mean: 0.00190 | EER_interp: 0.00180 | ACC: 0.99820\n",
      "  Task  7: n_7             | EER_mean: 0.00160 | EER_interp: 0.00150 | ACC: 0.99860\n",
      "  Task  8: n_8             | EER_mean: 0.00260 | EER_interp: 0.00240 | ACC: 0.99770\n",
      "  Task  9: n_9             | EER_mean: 0.00320 | EER_interp: 0.00330 | ACC: 0.99680\n",
      "final_EER_mean: 0.2% | final_EER_median: 0.19% | final_EER_std_dv: 0.09% | final_ACC: 99.8%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 4 | Feedback DNA: DNA([[2, 0, 0, 2], [0, 2, 2, 2]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 4: {'n_denses_0': 3, 'n_denses_1': 1, 'n_denses_2': 1, 'n_denses_3': 3, 'n_convs_0': 1, 'n_convs_1': 3, 'n_convs_2': 3, 'n_convs_3': 3}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,298,132\n",
      "  .. Trainable params: 4,040,148\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05172, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05172 to 0.00708, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00708\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00708 to 0.00708, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00708 to 0.00573, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 10s 51ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00090 | EER_interp: 0.00080 | ACC: 0.99920\n",
      "  Task  1: n_1             | EER_mean: 0.00150 | EER_interp: 0.00100 | ACC: 0.99930\n",
      "  Task  2: n_2             | EER_mean: 0.00170 | EER_interp: 0.00140 | ACC: 0.99880\n",
      "  Task  3: n_3             | EER_mean: 0.00160 | EER_interp: 0.00150 | ACC: 0.99860\n",
      "  Task  4: n_4             | EER_mean: 0.00290 | EER_interp: 0.00310 | ACC: 0.99720\n",
      "  Task  5: n_5             | EER_mean: 0.00280 | EER_interp: 0.00270 | ACC: 0.99740\n",
      "  Task  6: n_6             | EER_mean: 0.00140 | EER_interp: 0.00110 | ACC: 0.99870\n",
      "  Task  7: n_7             | EER_mean: 0.00240 | EER_interp: 0.00170 | ACC: 0.99880\n",
      "  Task  8: n_8             | EER_mean: 0.00770 | EER_interp: 0.00760 | ACC: 0.99240\n",
      "  Task  9: n_9             | EER_mean: 0.00340 | EER_interp: 0.00330 | ACC: 0.99680\n",
      "final_EER_mean: 0.24% | final_EER_median: 0.16% | final_EER_std_dv: 0.19% | final_ACC: 99.77%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 5 | Feedback DNA: DNA([[3, 2, 2, 1], [1, 2, 1, 1]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 5: {'n_denses_0': 4, 'n_denses_1': 3, 'n_denses_2': 3, 'n_denses_3': 2, 'n_convs_0': 2, 'n_convs_1': 3, 'n_convs_2': 2, 'n_convs_3': 2}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,318,004\n",
      "  .. Trainable params: 4,060,020\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09109, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09109 to 0.01973, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01973 to 0.01904, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01904 to 0.01421, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01421 to 0.00691, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 10s 49ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00260 | EER_interp: 0.00240 | ACC: 0.99770\n",
      "  Task  1: n_1             | EER_mean: 0.00440 | EER_interp: 0.00420 | ACC: 0.99600\n",
      "  Task  2: n_2             | EER_mean: 0.00170 | EER_interp: 0.00140 | ACC: 0.99880\n",
      "  Task  3: n_3             | EER_mean: 0.00180 | EER_interp: 0.00170 | ACC: 0.99820\n",
      "  Task  4: n_4             | EER_mean: 0.00340 | EER_interp: 0.00330 | ACC: 0.99680\n",
      "  Task  5: n_5             | EER_mean: 0.00220 | EER_interp: 0.00200 | ACC: 0.99780\n",
      "  Task  6: n_6             | EER_mean: 0.00250 | EER_interp: 0.00210 | ACC: 0.99820\n",
      "  Task  7: n_7             | EER_mean: 0.00240 | EER_interp: 0.00230 | ACC: 0.99770\n",
      "  Task  8: n_8             | EER_mean: 0.00340 | EER_interp: 0.00320 | ACC: 0.99700\n",
      "  Task  9: n_9             | EER_mean: 0.00510 | EER_interp: 0.00480 | ACC: 0.99530\n",
      "final_EER_mean: 0.27% | final_EER_median: 0.23% | final_EER_std_dv: 0.11% | final_ACC: 99.74%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 6 | Feedback DNA: DNA([[2, 0, 1, 1], [2, 2, 1, 1]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 6: {'n_denses_0': 3, 'n_denses_1': 1, 'n_denses_2': 2, 'n_denses_3': 2, 'n_convs_0': 3, 'n_convs_1': 3, 'n_convs_2': 2, 'n_convs_3': 2}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,289,812\n",
      "  .. Trainable params: 4,031,828\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04715, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04715 to 0.01306, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01306 to 0.00894, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00894 to 0.00837, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00837 to 0.00563, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 10s 51ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00090 | EER_interp: 0.00080 | ACC: 0.99930\n",
      "  Task  1: n_1             | EER_mean: 0.00290 | EER_interp: 0.00290 | ACC: 0.99720\n",
      "  Task  2: n_2             | EER_mean: 0.00170 | EER_interp: 0.00120 | ACC: 0.99910\n",
      "  Task  3: n_3             | EER_mean: 0.00410 | EER_interp: 0.00400 | ACC: 0.99610\n",
      "  Task  4: n_4             | EER_mean: 0.00250 | EER_interp: 0.00250 | ACC: 0.99750\n",
      "  Task  5: n_5             | EER_mean: 0.00190 | EER_interp: 0.00160 | ACC: 0.99860\n",
      "  Task  6: n_6             | EER_mean: 0.00260 | EER_interp: 0.00260 | ACC: 0.99740\n",
      "  Task  7: n_7             | EER_mean: 0.00240 | EER_interp: 0.00220 | ACC: 0.99780\n",
      "  Task  8: n_8             | EER_mean: 0.00430 | EER_interp: 0.00280 | ACC: 0.99830\n",
      "  Task  9: n_9             | EER_mean: 0.00300 | EER_interp: 0.00280 | ACC: 0.99710\n",
      "final_EER_mean: 0.23% | final_EER_median: 0.26% | final_EER_std_dv: 0.09% | final_ACC: 99.78%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 7 | Feedback DNA: DNA([[3, 0, 2, 1], [2, 2, 2, 2]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 7: {'n_denses_0': 4, 'n_denses_1': 1, 'n_denses_2': 3, 'n_denses_3': 2, 'n_convs_0': 3, 'n_convs_1': 3, 'n_convs_2': 3, 'n_convs_3': 3}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,320,788\n",
      "  .. Trainable params: 4,062,804\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02920, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02920 to 0.01048, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01048 to 0.00902, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00902 to 0.00628, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00628\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 10s 51ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00090 | EER_interp: 0.00070 | ACC: 0.99950\n",
      "  Task  1: n_1             | EER_mean: 0.00300 | EER_interp: 0.00300 | ACC: 0.99710\n",
      "  Task  2: n_2             | EER_mean: 0.00260 | EER_interp: 0.00260 | ACC: 0.99740\n",
      "  Task  3: n_3             | EER_mean: 0.00240 | EER_interp: 0.00220 | ACC: 0.99790\n",
      "  Task  4: n_4             | EER_mean: 0.00420 | EER_interp: 0.00280 | ACC: 0.99840\n",
      "  Task  5: n_5             | EER_mean: 0.00370 | EER_interp: 0.00320 | ACC: 0.99710\n",
      "  Task  6: n_6             | EER_mean: 0.00170 | EER_interp: 0.00160 | ACC: 0.99840\n",
      "  Task  7: n_7             | EER_mean: 0.00220 | EER_interp: 0.00230 | ACC: 0.99780\n",
      "  Task  8: n_8             | EER_mean: 0.00510 | EER_interp: 0.00520 | ACC: 0.99480\n",
      "  Task  9: n_9             | EER_mean: 0.00420 | EER_interp: 0.00420 | ACC: 0.99580\n",
      "final_EER_mean: 0.28% | final_EER_median: 0.27% | final_EER_std_dv: 0.12% | final_ACC: 99.74%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 8 | Feedback DNA: DNA([[2, 0, 0, 0], [2, 1, 2, 1]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 8: {'n_denses_0': 3, 'n_denses_1': 1, 'n_denses_2': 1, 'n_denses_3': 1, 'n_convs_0': 3, 'n_convs_1': 2, 'n_convs_2': 3, 'n_convs_3': 2}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,264,852\n",
      "  .. Trainable params: 4,006,868\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05694, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05694 to 0.01251, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.01251\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01251 to 0.00818, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00818 to 0.00623, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 11s 51ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00170 | EER_interp: 0.00110 | ACC: 0.99940\n",
      "  Task  1: n_1             | EER_mean: 0.00110 | EER_interp: 0.00130 | ACC: 0.99880\n",
      "  Task  2: n_2             | EER_mean: 0.00320 | EER_interp: 0.00330 | ACC: 0.99680\n",
      "  Task  3: n_3             | EER_mean: 0.00160 | EER_interp: 0.00140 | ACC: 0.99880\n",
      "  Task  4: n_4             | EER_mean: 0.00590 | EER_interp: 0.00390 | ACC: 0.99770\n",
      "  Task  5: n_5             | EER_mean: 0.00330 | EER_interp: 0.00350 | ACC: 0.99670\n",
      "  Task  6: n_6             | EER_mean: 0.00250 | EER_interp: 0.00230 | ACC: 0.99780\n",
      "  Task  7: n_7             | EER_mean: 0.00350 | EER_interp: 0.00340 | ACC: 0.99650\n",
      "  Task  8: n_8             | EER_mean: 0.00260 | EER_interp: 0.00170 | ACC: 0.99890\n",
      "  Task  9: n_9             | EER_mean: 0.00180 | EER_interp: 0.00170 | ACC: 0.99820\n",
      "final_EER_mean: 0.24% | final_EER_median: 0.2% | final_EER_std_dv: 0.1% | final_ACC: 99.8%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 9 | Feedback DNA: DNA([[2, 2, 2, 2], [2, 2, 2, 1]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 9: {'n_denses_0': 3, 'n_denses_1': 3, 'n_denses_2': 3, 'n_denses_3': 3, 'n_convs_0': 3, 'n_convs_1': 3, 'n_convs_2': 3, 'n_convs_3': 2}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,348,980\n",
      "  .. Trainable params: 4,090,996\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.01809, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.01809\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01809 to 0.00842, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00842\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00842 to 0.00558, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 11s 55ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00060 | EER_interp: 0.00000 | ACC: 0.99950\n",
      "  Task  1: n_1             | EER_mean: 0.00140 | EER_interp: 0.00140 | ACC: 0.99860\n",
      "  Task  2: n_2             | EER_mean: 0.00080 | EER_interp: 0.00060 | ACC: 0.99950\n",
      "  Task  3: n_3             | EER_mean: 0.00450 | EER_interp: 0.00430 | ACC: 0.99560\n",
      "  Task  4: n_4             | EER_mean: 0.00340 | EER_interp: 0.00300 | ACC: 0.99740\n",
      "  Task  5: n_5             | EER_mean: 0.00280 | EER_interp: 0.00280 | ACC: 0.99720\n",
      "  Task  6: n_6             | EER_mean: 0.00180 | EER_interp: 0.00170 | ACC: 0.99820\n",
      "  Task  7: n_7             | EER_mean: 0.00160 | EER_interp: 0.00160 | ACC: 0.99840\n",
      "  Task  8: n_8             | EER_mean: 0.00340 | EER_interp: 0.00340 | ACC: 0.99660\n",
      "  Task  9: n_9             | EER_mean: 0.00250 | EER_interp: 0.00250 | ACC: 0.99750\n",
      "final_EER_mean: 0.21% | final_EER_median: 0.21% | final_EER_std_dv: 0.12% | final_ACC: 99.78%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 10 | Feedback DNA: DNA([[2, 0, 2, 1], [2, 2, 2, 1]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 10: {'n_denses_0': 3, 'n_denses_1': 1, 'n_denses_2': 3, 'n_denses_3': 2, 'n_convs_0': 3, 'n_convs_1': 3, 'n_convs_2': 3, 'n_convs_3': 2}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,307,380\n",
      "  .. Trainable params: 4,049,396\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05234, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05234 to 0.01275, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.01275\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01275 to 0.00573, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00573\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 11s 56ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00090 | EER_interp: 0.00070 | ACC: 0.99950\n",
      "  Task  1: n_1             | EER_mean: 0.00250 | EER_interp: 0.00240 | ACC: 0.99750\n",
      "  Task  2: n_2             | EER_mean: 0.00140 | EER_interp: 0.00110 | ACC: 0.99870\n",
      "  Task  3: n_3             | EER_mean: 0.00240 | EER_interp: 0.00220 | ACC: 0.99790\n",
      "  Task  4: n_4             | EER_mean: 0.00340 | EER_interp: 0.00270 | ACC: 0.99780\n",
      "  Task  5: n_5             | EER_mean: 0.00190 | EER_interp: 0.00160 | ACC: 0.99870\n",
      "  Task  6: n_6             | EER_mean: 0.00240 | EER_interp: 0.00240 | ACC: 0.99760\n",
      "  Task  7: n_7             | EER_mean: 0.00170 | EER_interp: 0.00160 | ACC: 0.99830\n",
      "  Task  8: n_8             | EER_mean: 0.00260 | EER_interp: 0.00220 | ACC: 0.99810\n",
      "  Task  9: n_9             | EER_mean: 0.00340 | EER_interp: 0.00340 | ACC: 0.99660\n",
      "final_EER_mean: 0.2% | final_EER_median: 0.22% | final_EER_std_dv: 0.08% | final_ACC: 99.81%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      " ..Training controller model...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ..Controller model trained!\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 11 | Feedback DNA: DNA([[2, 2, 2, 2], [1, 1, 1, 1]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 11: {'n_denses_0': 3, 'n_denses_1': 3, 'n_denses_2': 3, 'n_denses_3': 3, 'n_convs_0': 2, 'n_convs_1': 2, 'n_convs_2': 2, 'n_convs_3': 2}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,321,236\n",
      "  .. Trainable params: 4,063,252\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03291, saving model to training/training_ckpt/best_model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_loss improved from 0.03291 to 0.01073, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.01073\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01073 to 0.00834, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00834 to 0.00654, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 11s 54ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00170 | EER_interp: 0.00120 | ACC: 0.99920\n",
      "  Task  1: n_1             | EER_mean: 0.00200 | EER_interp: 0.00210 | ACC: 0.99800\n",
      "  Task  2: n_2             | EER_mean: 0.00060 | EER_interp: 0.00070 | ACC: 0.99930\n",
      "  Task  3: n_3             | EER_mean: 0.00240 | EER_interp: 0.00220 | ACC: 0.99790\n",
      "  Task  4: n_4             | EER_mean: 0.00340 | EER_interp: 0.00320 | ACC: 0.99680\n",
      "  Task  5: n_5             | EER_mean: 0.00410 | EER_interp: 0.00390 | ACC: 0.99590\n",
      "  Task  6: n_6             | EER_mean: 0.00250 | EER_interp: 0.00220 | ACC: 0.99820\n",
      "  Task  7: n_7             | EER_mean: 0.00480 | EER_interp: 0.00410 | ACC: 0.99640\n",
      "  Task  8: n_8             | EER_mean: 0.00510 | EER_interp: 0.00480 | ACC: 0.99540\n",
      "  Task  9: n_9             | EER_mean: 0.00350 | EER_interp: 0.00340 | ACC: 0.99650\n",
      "final_EER_mean: 0.28% | final_EER_median: 0.27% | final_EER_std_dv: 0.12% | final_ACC: 99.74%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 12 | Feedback DNA: DNA([[2, 2, 2, 2], [1, 1, 0, 1]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 12: {'n_denses_0': 3, 'n_denses_1': 3, 'n_denses_2': 3, 'n_denses_3': 3, 'n_convs_0': 2, 'n_convs_1': 2, 'n_convs_2': 1, 'n_convs_3': 2}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,311,988\n",
      "  .. Trainable params: 4,054,004\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02192, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02192 to 0.00690, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00690\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00690 to 0.00688, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00688 to 0.00653, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 11s 56ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00100 | EER_interp: 0.00140 | ACC: 0.99890\n",
      "  Task  1: n_1             | EER_mean: 0.00590 | EER_interp: 0.00510 | ACC: 0.99550\n",
      "  Task  2: n_2             | EER_mean: 0.00240 | EER_interp: 0.00240 | ACC: 0.99760\n",
      "  Task  3: n_3             | EER_mean: 0.00410 | EER_interp: 0.00340 | ACC: 0.99710\n",
      "  Task  4: n_4             | EER_mean: 0.00420 | EER_interp: 0.00320 | ACC: 0.99750\n",
      "  Task  5: n_5             | EER_mean: 0.00190 | EER_interp: 0.00140 | ACC: 0.99900\n",
      "  Task  6: n_6             | EER_mean: 0.00330 | EER_interp: 0.00310 | ACC: 0.99710\n",
      "  Task  7: n_7             | EER_mean: 0.00320 | EER_interp: 0.00320 | ACC: 0.99690\n",
      "  Task  8: n_8             | EER_mean: 0.00440 | EER_interp: 0.00440 | ACC: 0.99560\n",
      "  Task  9: n_9             | EER_mean: 0.00310 | EER_interp: 0.00320 | ACC: 0.99680\n",
      "final_EER_mean: 0.31% | final_EER_median: 0.32% | final_EER_std_dv: 0.11% | final_ACC: 99.72%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 13 | Feedback DNA: DNA([[2, 2, 2, 2], [1, 1, 1, 1]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 13: {'n_denses_0': 3, 'n_denses_1': 3, 'n_denses_2': 3, 'n_denses_3': 3, 'n_convs_0': 2, 'n_convs_1': 2, 'n_convs_2': 2, 'n_convs_3': 2}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,321,236\n",
      "  .. Trainable params: 4,063,252\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07151, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.07151 to 0.01197, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01197 to 0.00812, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00812\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00812 to 0.00696, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 11s 55ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00170 | EER_interp: 0.00160 | ACC: 0.99860\n",
      "  Task  1: n_1             | EER_mean: 0.00280 | EER_interp: 0.00290 | ACC: 0.99720\n",
      "  Task  2: n_2             | EER_mean: 0.00340 | EER_interp: 0.00340 | ACC: 0.99670\n",
      "  Task  3: n_3             | EER_mean: 0.00240 | EER_interp: 0.00190 | ACC: 0.99850\n",
      "  Task  4: n_4             | EER_mean: 0.00350 | EER_interp: 0.00340 | ACC: 0.99650\n",
      "  Task  5: n_5             | EER_mean: 0.00190 | EER_interp: 0.00190 | ACC: 0.99810\n",
      "  Task  6: n_6             | EER_mean: 0.00280 | EER_interp: 0.00260 | ACC: 0.99720\n",
      "  Task  7: n_7             | EER_mean: 0.00370 | EER_interp: 0.00380 | ACC: 0.99620\n",
      "  Task  8: n_8             | EER_mean: 0.00260 | EER_interp: 0.00240 | ACC: 0.99770\n",
      "  Task  9: n_9             | EER_mean: 0.00420 | EER_interp: 0.00420 | ACC: 0.99580\n",
      "final_EER_mean: 0.28% | final_EER_median: 0.27% | final_EER_std_dv: 0.08% | final_ACC: 99.72%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 14 | Feedback DNA: DNA([[2, 1, 2, 1], [1, 1, 1, 1]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 14: {'n_denses_0': 3, 'n_denses_1': 2, 'n_denses_2': 3, 'n_denses_3': 2, 'n_convs_0': 2, 'n_convs_1': 2, 'n_convs_2': 2, 'n_convs_3': 2}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,292,116\n",
      "  .. Trainable params: 4,034,132\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02517, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02517 to 0.01045, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.01045\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01045 to 0.00858, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00858 to 0.00680, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 10s 51ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00120 | EER_interp: 0.00100 | ACC: 0.99880\n",
      "  Task  1: n_1             | EER_mean: 0.00220 | EER_interp: 0.00180 | ACC: 0.99840\n",
      "  Task  2: n_2             | EER_mean: 0.00250 | EER_interp: 0.00240 | ACC: 0.99760\n",
      "  Task  3: n_3             | EER_mean: 0.00400 | EER_interp: 0.00400 | ACC: 0.99600\n",
      "  Task  4: n_4             | EER_mean: 0.00360 | EER_interp: 0.00350 | ACC: 0.99640\n",
      "  Task  5: n_5             | EER_mean: 0.00170 | EER_interp: 0.00180 | ACC: 0.99820\n",
      "  Task  6: n_6             | EER_mean: 0.00330 | EER_interp: 0.00240 | ACC: 0.99840\n",
      "  Task  7: n_7             | EER_mean: 0.00310 | EER_interp: 0.00320 | ACC: 0.99690\n",
      "  Task  8: n_8             | EER_mean: 0.00420 | EER_interp: 0.00420 | ACC: 0.99580\n",
      "  Task  9: n_9             | EER_mean: 0.00500 | EER_interp: 0.00510 | ACC: 0.99500\n",
      "final_EER_mean: 0.29% | final_EER_median: 0.28% | final_EER_std_dv: 0.12% | final_ACC: 99.71%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 15 | Feedback DNA: DNA([[2, 2, 2, 2], [1, 1, 1, 1]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 15: {'n_denses_0': 3, 'n_denses_1': 3, 'n_denses_2': 3, 'n_denses_3': 3, 'n_convs_0': 2, 'n_convs_1': 2, 'n_convs_2': 2, 'n_convs_3': 2}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,321,236\n",
      "  .. Trainable params: 4,063,252\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04413, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04413 to 0.01037, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.01037\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.01037\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01037 to 0.00657, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 11s 56ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00090 | EER_interp: 0.00070 | ACC: 0.99950\n",
      "  Task  1: n_1             | EER_mean: 0.00220 | EER_interp: 0.00170 | ACC: 0.99870\n",
      "  Task  2: n_2             | EER_mean: 0.00250 | EER_interp: 0.00200 | ACC: 0.99840\n",
      "  Task  3: n_3             | EER_mean: 0.00240 | EER_interp: 0.00180 | ACC: 0.99870\n",
      "  Task  4: n_4             | EER_mean: 0.00340 | EER_interp: 0.00250 | ACC: 0.99820\n",
      "  Task  5: n_5             | EER_mean: 0.00370 | EER_interp: 0.00300 | ACC: 0.99750\n",
      "  Task  6: n_6             | EER_mean: 0.00330 | EER_interp: 0.00290 | ACC: 0.99740\n",
      "  Task  7: n_7             | EER_mean: 0.00160 | EER_interp: 0.00160 | ACC: 0.99840\n",
      "  Task  8: n_8             | EER_mean: 0.00430 | EER_interp: 0.00420 | ACC: 0.99600\n",
      "  Task  9: n_9             | EER_mean: 0.00340 | EER_interp: 0.00340 | ACC: 0.99650\n",
      "final_EER_mean: 0.24% | final_EER_median: 0.23% | final_EER_std_dv: 0.1% | final_ACC: 99.79%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 16 | Feedback DNA: DNA([[2, 2, 1, 2], [1, 1, 1, 1]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 16: {'n_denses_0': 3, 'n_denses_1': 3, 'n_denses_2': 2, 'n_denses_3': 3, 'n_convs_0': 2, 'n_convs_1': 2, 'n_convs_2': 2, 'n_convs_3': 2}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,312,916\n",
      "  .. Trainable params: 4,054,932\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04650, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04650 to 0.02088, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02088 to 0.01111, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01111 to 0.00836, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00836\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 11s 55ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00200 | EER_interp: 0.00180 | ACC: 0.99800\n",
      "  Task  1: n_1             | EER_mean: 0.00300 | EER_interp: 0.00250 | ACC: 0.99790\n",
      "  Task  2: n_2             | EER_mean: 0.00170 | EER_interp: 0.00160 | ACC: 0.99840\n",
      "  Task  3: n_3             | EER_mean: 0.00240 | EER_interp: 0.00200 | ACC: 0.99830\n",
      "  Task  4: n_4             | EER_mean: 0.00510 | EER_interp: 0.00510 | ACC: 0.99490\n",
      "  Task  5: n_5             | EER_mean: 0.00280 | EER_interp: 0.00280 | ACC: 0.99720\n",
      "  Task  6: n_6             | EER_mean: 0.00420 | EER_interp: 0.00360 | ACC: 0.99680\n",
      "  Task  7: n_7             | EER_mean: 0.00300 | EER_interp: 0.00310 | ACC: 0.99700\n",
      "  Task  8: n_8             | EER_mean: 0.00330 | EER_interp: 0.00300 | ACC: 0.99680\n",
      "  Task  9: n_9             | EER_mean: 0.00750 | EER_interp: 0.00760 | ACC: 0.99250\n",
      "final_EER_mean: 0.33% | final_EER_median: 0.29% | final_EER_std_dv: 0.17% | final_ACC: 99.68%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 17 | Feedback DNA: DNA([[2, 2, 2, 2], [1, 1, 1, 1]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 17: {'n_denses_0': 3, 'n_denses_1': 3, 'n_denses_2': 3, 'n_denses_3': 3, 'n_convs_0': 2, 'n_convs_1': 2, 'n_convs_2': 2, 'n_convs_3': 2}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,321,236\n",
      "  .. Trainable params: 4,063,252\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05785, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05785 to 0.01197, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01197 to 0.00967, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00967 to 0.00669, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00669\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 12s 58ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00090 | EER_interp: 0.00080 | ACC: 0.99920\n",
      "  Task  1: n_1             | EER_mean: 0.00480 | EER_interp: 0.00460 | ACC: 0.99520\n",
      "  Task  2: n_2             | EER_mean: 0.00680 | EER_interp: 0.00660 | ACC: 0.99360\n",
      "  Task  3: n_3             | EER_mean: 0.00260 | EER_interp: 0.00250 | ACC: 0.99740\n",
      "  Task  4: n_4             | EER_mean: 0.00250 | EER_interp: 0.00220 | ACC: 0.99820\n",
      "  Task  5: n_5             | EER_mean: 0.00100 | EER_interp: 0.00100 | ACC: 0.99900\n",
      "  Task  6: n_6             | EER_mean: 0.00330 | EER_interp: 0.00240 | ACC: 0.99820\n",
      "  Task  7: n_7             | EER_mean: 0.00210 | EER_interp: 0.00180 | ACC: 0.99790\n",
      "  Task  8: n_8             | EER_mean: 0.00180 | EER_interp: 0.00170 | ACC: 0.99820\n",
      "  Task  9: n_9             | EER_mean: 0.00340 | EER_interp: 0.00340 | ACC: 0.99670\n",
      "final_EER_mean: 0.27% | final_EER_median: 0.23% | final_EER_std_dv: 0.17% | final_ACC: 99.74%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 18 | Feedback DNA: DNA([[2, 2, 2, 2], [1, 1, 1, 1]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 18: {'n_denses_0': 3, 'n_denses_1': 3, 'n_denses_2': 3, 'n_denses_3': 3, 'n_convs_0': 2, 'n_convs_1': 2, 'n_convs_2': 2, 'n_convs_3': 2}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,321,236\n",
      "  .. Trainable params: 4,063,252\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02395, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02395 to 0.01710, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01710 to 0.00710, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00710\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00710 to 0.00642, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 12s 57ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00150 | EER_interp: 0.00160 | ACC: 0.99850\n",
      "  Task  1: n_1             | EER_mean: 0.00160 | EER_interp: 0.00160 | ACC: 0.99840\n",
      "  Task  2: n_2             | EER_mean: 0.00250 | EER_interp: 0.00180 | ACC: 0.99870\n",
      "  Task  3: n_3             | EER_mean: 0.00240 | EER_interp: 0.00220 | ACC: 0.99790\n",
      "  Task  4: n_4             | EER_mean: 0.00420 | EER_interp: 0.00370 | ACC: 0.99670\n",
      "  Task  5: n_5             | EER_mean: 0.00190 | EER_interp: 0.00190 | ACC: 0.99810\n",
      "  Task  6: n_6             | EER_mean: 0.00420 | EER_interp: 0.00390 | ACC: 0.99630\n",
      "  Task  7: n_7             | EER_mean: 0.00320 | EER_interp: 0.00280 | ACC: 0.99750\n",
      "  Task  8: n_8             | EER_mean: 0.00260 | EER_interp: 0.00190 | ACC: 0.99870\n",
      "  Task  9: n_9             | EER_mean: 0.00510 | EER_interp: 0.00510 | ACC: 0.99500\n",
      "final_EER_mean: 0.26% | final_EER_median: 0.2% | final_EER_std_dv: 0.11% | final_ACC: 99.76%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 19 | Feedback DNA: DNA([[2, 2, 2, 2], [1, 0, 1, 1]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 19: {'n_denses_0': 3, 'n_denses_1': 3, 'n_denses_2': 3, 'n_denses_3': 3, 'n_convs_0': 2, 'n_convs_1': 1, 'n_convs_2': 2, 'n_convs_3': 2}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,311,988\n",
      "  .. Trainable params: 4,054,004\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02181, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02181 to 0.01966, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01966 to 0.00715, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00715 to 0.00652, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00652\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 12s 60ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00130 | EER_interp: 0.00150 | ACC: 0.99870\n",
      "  Task  1: n_1             | EER_mean: 0.00360 | EER_interp: 0.00360 | ACC: 0.99640\n",
      "  Task  2: n_2             | EER_mean: 0.00480 | EER_interp: 0.00490 | ACC: 0.99520\n",
      "  Task  3: n_3             | EER_mean: 0.00330 | EER_interp: 0.00320 | ACC: 0.99700\n",
      "  Task  4: n_4             | EER_mean: 0.00260 | EER_interp: 0.00260 | ACC: 0.99740\n",
      "  Task  5: n_5             | EER_mean: 0.00190 | EER_interp: 0.00190 | ACC: 0.99810\n",
      "  Task  6: n_6             | EER_mean: 0.00330 | EER_interp: 0.00340 | ACC: 0.99660\n",
      "  Task  7: n_7             | EER_mean: 0.00160 | EER_interp: 0.00160 | ACC: 0.99840\n",
      "  Task  8: n_8             | EER_mean: 0.00200 | EER_interp: 0.00180 | ACC: 0.99800\n",
      "  Task  9: n_9             | EER_mean: 0.00420 | EER_interp: 0.00420 | ACC: 0.99580\n",
      "final_EER_mean: 0.29% | final_EER_median: 0.29% | final_EER_std_dv: 0.11% | final_ACC: 99.72%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 20 | Feedback DNA: DNA([[2, 2, 2, 2], [1, 1, 1, 1]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 20: {'n_denses_0': 3, 'n_denses_1': 3, 'n_denses_2': 3, 'n_denses_3': 3, 'n_convs_0': 2, 'n_convs_1': 2, 'n_convs_2': 2, 'n_convs_3': 2}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,321,236\n",
      "  .. Trainable params: 4,063,252\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.01368, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.01368 to 0.01141, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01141 to 0.00999, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00999 to 0.00594, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00594\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 11s 54ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00090 | EER_interp: 0.00070 | ACC: 0.99950\n",
      "  Task  1: n_1             | EER_mean: 0.00300 | EER_interp: 0.00220 | ACC: 0.99840\n",
      "  Task  2: n_2             | EER_mean: 0.00150 | EER_interp: 0.00120 | ACC: 0.99860\n",
      "  Task  3: n_3             | EER_mean: 0.00290 | EER_interp: 0.00300 | ACC: 0.99720\n",
      "  Task  4: n_4             | EER_mean: 0.00340 | EER_interp: 0.00260 | ACC: 0.99790\n",
      "  Task  5: n_5             | EER_mean: 0.00160 | EER_interp: 0.00180 | ACC: 0.99840\n",
      "  Task  6: n_6             | EER_mean: 0.00170 | EER_interp: 0.00150 | ACC: 0.99870\n",
      "  Task  7: n_7             | EER_mean: 0.00320 | EER_interp: 0.00280 | ACC: 0.99750\n",
      "  Task  8: n_8             | EER_mean: 0.00170 | EER_interp: 0.00160 | ACC: 0.99850\n",
      "  Task  9: n_9             | EER_mean: 0.00490 | EER_interp: 0.00490 | ACC: 0.99520\n",
      "final_EER_mean: 0.22% | final_EER_median: 0.2% | final_EER_std_dv: 0.11% | final_ACC: 99.8%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      " ..Training controller model...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ..Controller model trained!\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 21 | Feedback DNA: DNA([[4, 4, 3, 4], [2, 2, 2, 0]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 21: {'n_denses_0': 5, 'n_denses_1': 5, 'n_denses_2': 4, 'n_denses_3': 5, 'n_convs_0': 3, 'n_convs_1': 3, 'n_convs_2': 3, 'n_convs_3': 1}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,414,612\n",
      "  .. Trainable params: 4,156,628\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05615, saving model to training/training_ckpt/best_model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_loss improved from 0.05615 to 0.01421, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01421 to 0.00727, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00727 to 0.00630, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00630 to 0.00579, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 10s 50ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00020 | EER_interp: 0.00000 | ACC: 0.99980\n",
      "  Task  1: n_1             | EER_mean: 0.00180 | EER_interp: 0.00200 | ACC: 0.99820\n",
      "  Task  2: n_2             | EER_mean: 0.00080 | EER_interp: 0.00080 | ACC: 0.99920\n",
      "  Task  3: n_3             | EER_mean: 0.00330 | EER_interp: 0.00280 | ACC: 0.99770\n",
      "  Task  4: n_4             | EER_mean: 0.00510 | EER_interp: 0.00480 | ACC: 0.99530\n",
      "  Task  5: n_5             | EER_mean: 0.00190 | EER_interp: 0.00180 | ACC: 0.99820\n",
      "  Task  6: n_6             | EER_mean: 0.00170 | EER_interp: 0.00150 | ACC: 0.99870\n",
      "  Task  7: n_7             | EER_mean: 0.00160 | EER_interp: 0.00160 | ACC: 0.99840\n",
      "  Task  8: n_8             | EER_mean: 0.00480 | EER_interp: 0.00490 | ACC: 0.99520\n",
      "  Task  9: n_9             | EER_mean: 0.00300 | EER_interp: 0.00320 | ACC: 0.99690\n",
      "final_EER_mean: 0.23% | final_EER_median: 0.19% | final_EER_std_dv: 0.15% | final_ACC: 99.78%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 22 | Feedback DNA: DNA([[3, 4, 4, 3], [0, 0, 0, 2]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 22: {'n_denses_0': 4, 'n_denses_1': 5, 'n_denses_2': 5, 'n_denses_3': 4, 'n_convs_0': 1, 'n_convs_1': 1, 'n_convs_2': 1, 'n_convs_3': 3}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,365,140\n",
      "  .. Trainable params: 4,107,156\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06076, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.06076 to 0.00805, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00805\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00805 to 0.00710, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00710 to 0.00550, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 10s 48ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00120 | EER_interp: 0.00100 | ACC: 0.99880\n",
      "  Task  1: n_1             | EER_mean: 0.00130 | EER_interp: 0.00140 | ACC: 0.99870\n",
      "  Task  2: n_2             | EER_mean: 0.00120 | EER_interp: 0.00100 | ACC: 0.99880\n",
      "  Task  3: n_3             | EER_mean: 0.00330 | EER_interp: 0.00320 | ACC: 0.99690\n",
      "  Task  4: n_4             | EER_mean: 0.00250 | EER_interp: 0.00250 | ACC: 0.99750\n",
      "  Task  5: n_5             | EER_mean: 0.00370 | EER_interp: 0.00350 | ACC: 0.99670\n",
      "  Task  6: n_6             | EER_mean: 0.00170 | EER_interp: 0.00140 | ACC: 0.99890\n",
      "  Task  7: n_7             | EER_mean: 0.00160 | EER_interp: 0.00160 | ACC: 0.99840\n",
      "  Task  8: n_8             | EER_mean: 0.00430 | EER_interp: 0.00410 | ACC: 0.99610\n",
      "  Task  9: n_9             | EER_mean: 0.00420 | EER_interp: 0.00400 | ACC: 0.99620\n",
      "final_EER_mean: 0.24% | final_EER_median: 0.2% | final_EER_std_dv: 0.12% | final_ACC: 99.77%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 23 | Feedback DNA: DNA([[4, 3, 4, 3], [2, 2, 0, 2]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 23: {'n_denses_0': 5, 'n_denses_1': 4, 'n_denses_2': 5, 'n_denses_3': 4, 'n_convs_0': 3, 'n_convs_1': 3, 'n_convs_2': 1, 'n_convs_3': 3}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,393,812\n",
      "  .. Trainable params: 4,135,828\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05588, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05588 to 0.01406, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01406 to 0.01215, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01215 to 0.00674, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00674 to 0.00597, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 11s 54ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00060 | EER_interp: 0.00080 | ACC: 0.99940\n",
      "  Task  1: n_1             | EER_mean: 0.00220 | EER_interp: 0.00220 | ACC: 0.99780\n",
      "  Task  2: n_2             | EER_mean: 0.00230 | EER_interp: 0.00240 | ACC: 0.99770\n",
      "  Task  3: n_3             | EER_mean: 0.00160 | EER_interp: 0.00160 | ACC: 0.99850\n",
      "  Task  4: n_4             | EER_mean: 0.00310 | EER_interp: 0.00320 | ACC: 0.99690\n",
      "  Task  5: n_5             | EER_mean: 0.00170 | EER_interp: 0.00180 | ACC: 0.99820\n",
      "  Task  6: n_6             | EER_mean: 0.00420 | EER_interp: 0.00420 | ACC: 0.99590\n",
      "  Task  7: n_7             | EER_mean: 0.00160 | EER_interp: 0.00160 | ACC: 0.99840\n",
      "  Task  8: n_8             | EER_mean: 0.00210 | EER_interp: 0.00190 | ACC: 0.99790\n",
      "  Task  9: n_9             | EER_mean: 0.00460 | EER_interp: 0.00440 | ACC: 0.99540\n",
      "final_EER_mean: 0.24% | final_EER_median: 0.2% | final_EER_std_dv: 0.11% | final_ACC: 99.76%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 24 | Feedback DNA: DNA([[4, 4, 4, 4], [2, 2, 2, 2]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 24: {'n_denses_0': 5, 'n_denses_1': 5, 'n_denses_2': 5, 'n_denses_3': 5, 'n_convs_0': 3, 'n_convs_1': 3, 'n_convs_2': 3, 'n_convs_3': 3}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,441,428\n",
      "  .. Trainable params: 4,183,444\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02553, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02553 to 0.02350, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02350 to 0.00755, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00755\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00755 to 0.00691, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 10s 49ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00080 | EER_interp: 0.00080 | ACC: 0.99920\n",
      "  Task  1: n_1             | EER_mean: 0.00120 | EER_interp: 0.00140 | ACC: 0.99880\n",
      "  Task  2: n_2             | EER_mean: 0.00170 | EER_interp: 0.00170 | ACC: 0.99820\n",
      "  Task  3: n_3             | EER_mean: 0.00260 | EER_interp: 0.00250 | ACC: 0.99740\n",
      "  Task  4: n_4             | EER_mean: 0.00260 | EER_interp: 0.00260 | ACC: 0.99740\n",
      "  Task  5: n_5             | EER_mean: 0.00280 | EER_interp: 0.00220 | ACC: 0.99820\n",
      "  Task  6: n_6             | EER_mean: 0.00330 | EER_interp: 0.00270 | ACC: 0.99780\n",
      "  Task  7: n_7             | EER_mean: 0.00310 | EER_interp: 0.00310 | ACC: 0.99700\n",
      "  Task  8: n_8             | EER_mean: 0.00430 | EER_interp: 0.00410 | ACC: 0.99610\n",
      "  Task  9: n_9             | EER_mean: 0.00430 | EER_interp: 0.00420 | ACC: 0.99580\n",
      "final_EER_mean: 0.25% | final_EER_median: 0.26% | final_EER_std_dv: 0.1% | final_ACC: 99.76%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 25 | Feedback DNA: DNA([[4, 4, 3, 4], [2, 2, 2, 2]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 25: {'n_denses_0': 5, 'n_denses_1': 5, 'n_denses_2': 4, 'n_denses_3': 5, 'n_convs_0': 3, 'n_convs_1': 3, 'n_convs_2': 3, 'n_convs_3': 3}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,433,108\n",
      "  .. Trainable params: 4,175,124\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04266, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04266 to 0.01542, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01542 to 0.00648, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00648\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00648 to 0.00605, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 10s 51ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00120 | EER_interp: 0.00100 | ACC: 0.99880\n",
      "  Task  1: n_1             | EER_mean: 0.00370 | EER_interp: 0.00350 | ACC: 0.99670\n",
      "  Task  2: n_2             | EER_mean: 0.00190 | EER_interp: 0.00180 | ACC: 0.99810\n",
      "  Task  3: n_3             | EER_mean: 0.00330 | EER_interp: 0.00320 | ACC: 0.99700\n",
      "  Task  4: n_4             | EER_mean: 0.00250 | EER_interp: 0.00250 | ACC: 0.99750\n",
      "  Task  5: n_5             | EER_mean: 0.00140 | EER_interp: 0.00120 | ACC: 0.99870\n",
      "  Task  6: n_6             | EER_mean: 0.00170 | EER_interp: 0.00160 | ACC: 0.99840\n",
      "  Task  7: n_7             | EER_mean: 0.00100 | EER_interp: 0.00090 | ACC: 0.99900\n",
      "  Task  8: n_8             | EER_mean: 0.00440 | EER_interp: 0.00440 | ACC: 0.99560\n",
      "  Task  9: n_9             | EER_mean: 0.00330 | EER_interp: 0.00340 | ACC: 0.99670\n",
      "final_EER_mean: 0.24% | final_EER_median: 0.22% | final_EER_std_dv: 0.12% | final_ACC: 99.76%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 26 | Feedback DNA: DNA([[3, 4, 3, 3], [2, 0, 2, 2]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 26: {'n_denses_0': 4, 'n_denses_1': 5, 'n_denses_2': 4, 'n_denses_3': 4, 'n_convs_0': 3, 'n_convs_1': 1, 'n_convs_2': 3, 'n_convs_3': 3}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,393,812\n",
      "  .. Trainable params: 4,135,828\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08019, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08019 to 0.01003, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01003 to 0.00801, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00801\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00801 to 0.00774, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 10s 51ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00090 | EER_interp: 0.00080 | ACC: 0.99920\n",
      "  Task  1: n_1             | EER_mean: 0.00230 | EER_interp: 0.00230 | ACC: 0.99780\n",
      "  Task  2: n_2             | EER_mean: 0.00250 | EER_interp: 0.00260 | ACC: 0.99740\n",
      "  Task  3: n_3             | EER_mean: 0.00240 | EER_interp: 0.00240 | ACC: 0.99760\n",
      "  Task  4: n_4             | EER_mean: 0.00420 | EER_interp: 0.00420 | ACC: 0.99570\n",
      "  Task  5: n_5             | EER_mean: 0.00470 | EER_interp: 0.00420 | ACC: 0.99610\n",
      "  Task  6: n_6             | EER_mean: 0.00170 | EER_interp: 0.00140 | ACC: 0.99880\n",
      "  Task  7: n_7             | EER_mean: 0.00160 | EER_interp: 0.00160 | ACC: 0.99840\n",
      "  Task  8: n_8             | EER_mean: 0.00590 | EER_interp: 0.00600 | ACC: 0.99410\n",
      "  Task  9: n_9             | EER_mean: 0.00680 | EER_interp: 0.00580 | ACC: 0.99490\n",
      "final_EER_mean: 0.31% | final_EER_median: 0.25% | final_EER_std_dv: 0.17% | final_ACC: 99.7%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 27 | Feedback DNA: DNA([[3, 4, 3, 4], [2, 2, 2, 2]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 27: {'n_denses_0': 4, 'n_denses_1': 5, 'n_denses_2': 4, 'n_denses_3': 5, 'n_convs_0': 3, 'n_convs_1': 3, 'n_convs_2': 3, 'n_convs_3': 3}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,428,948\n",
      "  .. Trainable params: 4,170,964\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04751, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04751 to 0.01598, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01598 to 0.01078, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01078 to 0.00739, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00739 to 0.00701, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 12s 57ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00110 | EER_interp: 0.00100 | ACC: 0.99890\n",
      "  Task  1: n_1             | EER_mean: 0.00230 | EER_interp: 0.00230 | ACC: 0.99770\n",
      "  Task  2: n_2             | EER_mean: 0.00340 | EER_interp: 0.00280 | ACC: 0.99760\n",
      "  Task  3: n_3             | EER_mean: 0.00230 | EER_interp: 0.00230 | ACC: 0.99770\n",
      "  Task  4: n_4             | EER_mean: 0.00340 | EER_interp: 0.00260 | ACC: 0.99790\n",
      "  Task  5: n_5             | EER_mean: 0.00120 | EER_interp: 0.00100 | ACC: 0.99880\n",
      "  Task  6: n_6             | EER_mean: 0.00290 | EER_interp: 0.00270 | ACC: 0.99720\n",
      "  Task  7: n_7             | EER_mean: 0.00160 | EER_interp: 0.00160 | ACC: 0.99840\n",
      "  Task  8: n_8             | EER_mean: 0.00430 | EER_interp: 0.00260 | ACC: 0.99870\n",
      "  Task  9: n_9             | EER_mean: 0.00590 | EER_interp: 0.00520 | ACC: 0.99520\n",
      "final_EER_mean: 0.24% | final_EER_median: 0.24% | final_EER_std_dv: 0.11% | final_ACC: 99.78%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 28 | Feedback DNA: DNA([[4, 4, 3, 3], [2, 2, 2, 2]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 28: {'n_denses_0': 5, 'n_denses_1': 5, 'n_denses_2': 4, 'n_denses_3': 4, 'n_convs_0': 3, 'n_convs_1': 3, 'n_convs_2': 3, 'n_convs_3': 3}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,416,468\n",
      "  .. Trainable params: 4,158,484\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03042, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03042 to 0.01561, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01561 to 0.00850, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00850\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00850 to 0.00579, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 11s 55ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00060 | EER_interp: 0.00080 | ACC: 0.99940\n",
      "  Task  1: n_1             | EER_mean: 0.00150 | EER_interp: 0.00120 | ACC: 0.99910\n",
      "  Task  2: n_2             | EER_mean: 0.00340 | EER_interp: 0.00320 | ACC: 0.99690\n",
      "  Task  3: n_3             | EER_mean: 0.00410 | EER_interp: 0.00390 | ACC: 0.99620\n",
      "  Task  4: n_4             | EER_mean: 0.00290 | EER_interp: 0.00270 | ACC: 0.99720\n",
      "  Task  5: n_5             | EER_mean: 0.00200 | EER_interp: 0.00200 | ACC: 0.99800\n",
      "  Task  6: n_6             | EER_mean: 0.00250 | EER_interp: 0.00240 | ACC: 0.99780\n",
      "  Task  7: n_7             | EER_mean: 0.00240 | EER_interp: 0.00220 | ACC: 0.99780\n",
      "  Task  8: n_8             | EER_mean: 0.00430 | EER_interp: 0.00420 | ACC: 0.99590\n",
      "  Task  9: n_9             | EER_mean: 0.00340 | EER_interp: 0.00320 | ACC: 0.99680\n",
      "final_EER_mean: 0.26% | final_EER_median: 0.26% | final_EER_std_dv: 0.1% | final_ACC: 99.75%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 29 | Feedback DNA: DNA([[4, 3, 4, 3], [2, 2, 2, 0]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 29: {'n_denses_0': 5, 'n_denses_1': 4, 'n_denses_2': 5, 'n_denses_3': 4, 'n_convs_0': 3, 'n_convs_1': 3, 'n_convs_2': 3, 'n_convs_3': 1}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,393,812\n",
      "  .. Trainable params: 4,135,828\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09367, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09367 to 0.01335, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01335 to 0.00792, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00792 to 0.00582, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00582 to 0.00540, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 11s 54ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00170 | EER_interp: 0.00130 | ACC: 0.99900\n",
      "  Task  1: n_1             | EER_mean: 0.00220 | EER_interp: 0.00200 | ACC: 0.99820\n",
      "  Task  2: n_2             | EER_mean: 0.00210 | EER_interp: 0.00230 | ACC: 0.99780\n",
      "  Task  3: n_3             | EER_mean: 0.00330 | EER_interp: 0.00320 | ACC: 0.99700\n",
      "  Task  4: n_4             | EER_mean: 0.00250 | EER_interp: 0.00230 | ACC: 0.99790\n",
      "  Task  5: n_5             | EER_mean: 0.00370 | EER_interp: 0.00340 | ACC: 0.99690\n",
      "  Task  6: n_6             | EER_mean: 0.00330 | EER_interp: 0.00250 | ACC: 0.99820\n",
      "  Task  7: n_7             | EER_mean: 0.00240 | EER_interp: 0.00200 | ACC: 0.99820\n",
      "  Task  8: n_8             | EER_mean: 0.00340 | EER_interp: 0.00330 | ACC: 0.99680\n",
      "  Task  9: n_9             | EER_mean: 0.00340 | EER_interp: 0.00340 | ACC: 0.99670\n",
      "final_EER_mean: 0.26% | final_EER_median: 0.24% | final_EER_std_dv: 0.07% | final_ACC: 99.77%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 30 | Feedback DNA: DNA([[3, 3, 4, 4], [2, 2, 2, 2]])\n",
      "----------------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      " -- Architecture 30: {'n_denses_0': 4, 'n_denses_1': 4, 'n_denses_2': 5, 'n_denses_3': 5, 'n_convs_0': 3, 'n_convs_1': 3, 'n_convs_2': 3, 'n_convs_3': 3}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,424,788\n",
      "  .. Trainable params: 4,166,804\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06296, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.06296 to 0.02332, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02332 to 0.01099, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.01099\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01099 to 0.00792, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 11s 53ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00090 | EER_interp: 0.00060 | ACC: 0.99960\n",
      "  Task  1: n_1             | EER_mean: 0.00520 | EER_interp: 0.00360 | ACC: 0.99780\n",
      "  Task  2: n_2             | EER_mean: 0.00190 | EER_interp: 0.00180 | ACC: 0.99810\n",
      "  Task  3: n_3             | EER_mean: 0.00410 | EER_interp: 0.00360 | ACC: 0.99690\n",
      "  Task  4: n_4             | EER_mean: 0.00590 | EER_interp: 0.00570 | ACC: 0.99460\n",
      "  Task  5: n_5             | EER_mean: 0.00120 | EER_interp: 0.00100 | ACC: 0.99880\n",
      "  Task  6: n_6             | EER_mean: 0.00220 | EER_interp: 0.00240 | ACC: 0.99780\n",
      "  Task  7: n_7             | EER_mean: 0.00250 | EER_interp: 0.00240 | ACC: 0.99750\n",
      "  Task  8: n_8             | EER_mean: 0.00260 | EER_interp: 0.00230 | ACC: 0.99780\n",
      "  Task  9: n_9             | EER_mean: 0.00340 | EER_interp: 0.00330 | ACC: 0.99680\n",
      "final_EER_mean: 0.27% | final_EER_median: 0.24% | final_EER_std_dv: 0.14% | final_ACC: 99.76%\n",
      "------------------------------------------------------------\n",
      "======================================================================\n",
      "\n",
      "\n",
      "------------------ TOP ARCHITECTURES FOUND --------------------\n",
      " . Architecture 9: {'n_denses_0': 3, 'n_denses_1': 1, 'n_denses_2': 3, 'n_denses_3': 2, 'n_convs_0': 3, 'n_convs_1': 3, 'n_convs_2': 3, 'n_convs_3': 2} | Validation accuracy: 99.81%\n",
      " . Architecture 19: {'n_denses_0': 3, 'n_denses_1': 3, 'n_denses_2': 3, 'n_denses_3': 3, 'n_convs_0': 2, 'n_convs_1': 2, 'n_convs_2': 2, 'n_convs_3': 2} | Validation accuracy: 99.8%\n",
      " . Architecture 7: {'n_denses_0': 3, 'n_denses_1': 1, 'n_denses_2': 1, 'n_denses_3': 1, 'n_convs_0': 3, 'n_convs_1': 2, 'n_convs_2': 3, 'n_convs_3': 2} | Validation accuracy: 99.8%\n",
      " . Architecture 2: {'n_denses_0': 3, 'n_denses_1': 3, 'n_denses_2': 2, 'n_denses_3': 3, 'n_convs_0': 3, 'n_convs_1': 2, 'n_convs_2': 2, 'n_convs_3': 2} | Validation accuracy: 99.8%\n",
      " . Architecture 14: {'n_denses_0': 3, 'n_denses_1': 3, 'n_denses_2': 3, 'n_denses_3': 3, 'n_convs_0': 2, 'n_convs_1': 2, 'n_convs_2': 2, 'n_convs_3': 2} | Validation accuracy: 99.79%\n",
      "------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_arch = runner.run_neural_architecture_search_v3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create Model with Best Architecture Found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- create model -------------------\n",
      "Creating model...\n",
      "Model created\n"
     ]
    }
   ],
   "source": [
    "runner.create_model(best_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "runner.visualize_model(outfile_path=f\"training/figs/nas/nas_model_{APPROACH.name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "runner.model_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- train model -------------------\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 6,324,020\n",
      "  .. Trainable params: 4,066,036\n",
      "  .. Non-trainable params: 2,257,984\n",
      "Epoch 1/50\n",
      "750/750 [==============================] - 225s 293ms/step - loss: 0.0254 - n_0_loss: 0.0256 - n_1_loss: 0.0158 - n_7_loss: 0.0244 - n_4_loss: 0.0211 - n_2_loss: 0.0252 - n_3_loss: 0.0292 - n_5_loss: 0.0236 - n_6_loss: 0.0271 - n_8_loss: 0.0264 - n_9_loss: 0.0355 - n_0_accuracy: 0.9885 - n_1_accuracy: 0.9943 - n_7_accuracy: 0.9913 - n_4_accuracy: 0.9927 - n_2_accuracy: 0.9906 - n_3_accuracy: 0.9892 - n_5_accuracy: 0.9920 - n_6_accuracy: 0.9895 - n_8_accuracy: 0.9902 - n_9_accuracy: 0.9872 - val_loss: 0.0315 - val_n_0_loss: 0.0105 - val_n_1_loss: 0.0101 - val_n_7_loss: 0.0393 - val_n_4_loss: 0.0137 - val_n_2_loss: 0.0725 - val_n_3_loss: 0.0552 - val_n_5_loss: 0.0248 - val_n_6_loss: 0.0218 - val_n_8_loss: 0.0237 - val_n_9_loss: 0.0433 - val_n_0_accuracy: 0.9972 - val_n_1_accuracy: 0.9975 - val_n_7_accuracy: 0.9902 - val_n_4_accuracy: 0.9969 - val_n_2_accuracy: 0.9878 - val_n_3_accuracy: 0.9841 - val_n_5_accuracy: 0.9948 - val_n_6_accuracy: 0.9943 - val_n_8_accuracy: 0.9953 - val_n_9_accuracy: 0.9904\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03150, saving model to training/training_ckpt/best_model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "750/750 [==============================] - 220s 294ms/step - loss: 0.0060 - n_0_loss: 0.0033 - n_1_loss: 0.0048 - n_7_loss: 0.0060 - n_4_loss: 0.0060 - n_2_loss: 0.0063 - n_3_loss: 0.0059 - n_5_loss: 0.0058 - n_6_loss: 0.0069 - n_8_loss: 0.0064 - n_9_loss: 0.0087 - n_0_accuracy: 0.9990 - n_1_accuracy: 0.9987 - n_7_accuracy: 0.9983 - n_4_accuracy: 0.9983 - n_2_accuracy: 0.9981 - n_3_accuracy: 0.9984 - n_5_accuracy: 0.9982 - n_6_accuracy: 0.9979 - n_8_accuracy: 0.9983 - n_9_accuracy: 0.9976 - val_loss: 0.0181 - val_n_0_loss: 0.0175 - val_n_1_loss: 0.0117 - val_n_7_loss: 0.0039 - val_n_4_loss: 0.0258 - val_n_2_loss: 0.0106 - val_n_3_loss: 0.0202 - val_n_5_loss: 0.0152 - val_n_6_loss: 0.0081 - val_n_8_loss: 0.0543 - val_n_9_loss: 0.0138 - val_n_0_accuracy: 0.9950 - val_n_1_accuracy: 0.9975 - val_n_7_accuracy: 0.9987 - val_n_4_accuracy: 0.9916 - val_n_2_accuracy: 0.9975 - val_n_3_accuracy: 0.9957 - val_n_5_accuracy: 0.9968 - val_n_6_accuracy: 0.9977 - val_n_8_accuracy: 0.9886 - val_n_9_accuracy: 0.9962\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03150 to 0.01811, saving model to training/training_ckpt/best_model.hdf5\n",
      "Epoch 3/50\n",
      "750/750 [==============================] - 219s 291ms/step - loss: 0.0041 - n_0_loss: 0.0027 - n_1_loss: 0.0032 - n_7_loss: 0.0036 - n_4_loss: 0.0036 - n_2_loss: 0.0050 - n_3_loss: 0.0042 - n_5_loss: 0.0036 - n_6_loss: 0.0053 - n_8_loss: 0.0038 - n_9_loss: 0.0060 - n_0_accuracy: 0.9992 - n_1_accuracy: 0.9991 - n_7_accuracy: 0.9988 - n_4_accuracy: 0.9989 - n_2_accuracy: 0.9986 - n_3_accuracy: 0.9988 - n_5_accuracy: 0.9989 - n_6_accuracy: 0.9986 - n_8_accuracy: 0.9988 - n_9_accuracy: 0.9983 - val_loss: 0.0063 - val_n_0_loss: 0.0015 - val_n_1_loss: 0.0030 - val_n_7_loss: 0.0079 - val_n_4_loss: 0.0037 - val_n_2_loss: 0.0088 - val_n_3_loss: 0.0067 - val_n_5_loss: 0.0056 - val_n_6_loss: 0.0044 - val_n_8_loss: 0.0099 - val_n_9_loss: 0.0112 - val_n_0_accuracy: 0.9997 - val_n_1_accuracy: 0.9992 - val_n_7_accuracy: 0.9976 - val_n_4_accuracy: 0.9993 - val_n_2_accuracy: 0.9977 - val_n_3_accuracy: 0.9978 - val_n_5_accuracy: 0.9987 - val_n_6_accuracy: 0.9987 - val_n_8_accuracy: 0.9978 - val_n_9_accuracy: 0.9973\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01811 to 0.00627, saving model to training/training_ckpt/best_model.hdf5\n",
      "Epoch 4/50\n",
      "750/750 [==============================] - 218s 291ms/step - loss: 0.0033 - n_0_loss: 0.0011 - n_1_loss: 0.0026 - n_7_loss: 0.0033 - n_4_loss: 0.0032 - n_2_loss: 0.0035 - n_3_loss: 0.0033 - n_5_loss: 0.0031 - n_6_loss: 0.0038 - n_8_loss: 0.0039 - n_9_loss: 0.0049 - n_0_accuracy: 0.9996 - n_1_accuracy: 0.9990 - n_7_accuracy: 0.9991 - n_4_accuracy: 0.9992 - n_2_accuracy: 0.9991 - n_3_accuracy: 0.9990 - n_5_accuracy: 0.9991 - n_6_accuracy: 0.9991 - n_8_accuracy: 0.9989 - n_9_accuracy: 0.9987 - val_loss: 0.0095 - val_n_0_loss: 0.0046 - val_n_1_loss: 0.0161 - val_n_7_loss: 0.0137 - val_n_4_loss: 0.0040 - val_n_2_loss: 0.0080 - val_n_3_loss: 0.0071 - val_n_5_loss: 0.0066 - val_n_6_loss: 0.0067 - val_n_8_loss: 0.0121 - val_n_9_loss: 0.0166 - val_n_0_accuracy: 0.9986 - val_n_1_accuracy: 0.9966 - val_n_7_accuracy: 0.9969 - val_n_4_accuracy: 0.9993 - val_n_2_accuracy: 0.9981 - val_n_3_accuracy: 0.9983 - val_n_5_accuracy: 0.9985 - val_n_6_accuracy: 0.9977 - val_n_8_accuracy: 0.9973 - val_n_9_accuracy: 0.9961\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00627\n",
      "Epoch 5/50\n",
      "750/750 [==============================] - 218s 290ms/step - loss: 0.0027 - n_0_loss: 0.0011 - n_1_loss: 0.0022 - n_7_loss: 0.0025 - n_4_loss: 0.0028 - n_2_loss: 0.0035 - n_3_loss: 0.0027 - n_5_loss: 0.0019 - n_6_loss: 0.0040 - n_8_loss: 0.0025 - n_9_loss: 0.0035 - n_0_accuracy: 0.9998 - n_1_accuracy: 0.9993 - n_7_accuracy: 0.9992 - n_4_accuracy: 0.9993 - n_2_accuracy: 0.9991 - n_3_accuracy: 0.9994 - n_5_accuracy: 0.9995 - n_6_accuracy: 0.9989 - n_8_accuracy: 0.9992 - n_9_accuracy: 0.9991 - val_loss: 0.0053 - val_n_0_loss: 0.0014 - val_n_1_loss: 0.0052 - val_n_7_loss: 0.0035 - val_n_4_loss: 0.0037 - val_n_2_loss: 0.0068 - val_n_3_loss: 0.0036 - val_n_5_loss: 0.0042 - val_n_6_loss: 0.0053 - val_n_8_loss: 0.0110 - val_n_9_loss: 0.0088 - val_n_0_accuracy: 0.9996 - val_n_1_accuracy: 0.9989 - val_n_7_accuracy: 0.9993 - val_n_4_accuracy: 0.9992 - val_n_2_accuracy: 0.9982 - val_n_3_accuracy: 0.9992 - val_n_5_accuracy: 0.9992 - val_n_6_accuracy: 0.9987 - val_n_8_accuracy: 0.9976 - val_n_9_accuracy: 0.9982\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00627 to 0.00535, saving model to training/training_ckpt/best_model.hdf5\n",
      "Epoch 6/50\n",
      "750/750 [==============================] - 219s 292ms/step - loss: 0.0023 - n_0_loss: 0.0013 - n_1_loss: 0.0020 - n_7_loss: 0.0016 - n_4_loss: 0.0017 - n_2_loss: 0.0030 - n_3_loss: 0.0023 - n_5_loss: 0.0027 - n_6_loss: 0.0025 - n_8_loss: 0.0020 - n_9_loss: 0.0042 - n_0_accuracy: 0.9996 - n_1_accuracy: 0.9994 - n_7_accuracy: 0.9994 - n_4_accuracy: 0.9995 - n_2_accuracy: 0.9991 - n_3_accuracy: 0.9994 - n_5_accuracy: 0.9992 - n_6_accuracy: 0.9992 - n_8_accuracy: 0.9994 - n_9_accuracy: 0.9987 - val_loss: 0.0053 - val_n_0_loss: 0.0022 - val_n_1_loss: 0.0042 - val_n_7_loss: 0.0053 - val_n_4_loss: 0.0046 - val_n_2_loss: 0.0055 - val_n_3_loss: 0.0075 - val_n_5_loss: 0.0064 - val_n_6_loss: 0.0043 - val_n_8_loss: 0.0058 - val_n_9_loss: 0.0071 - val_n_0_accuracy: 0.9993 - val_n_1_accuracy: 0.9987 - val_n_7_accuracy: 0.9987 - val_n_4_accuracy: 0.9991 - val_n_2_accuracy: 0.9989 - val_n_3_accuracy: 0.9987 - val_n_5_accuracy: 0.9983 - val_n_6_accuracy: 0.9984 - val_n_8_accuracy: 0.9989 - val_n_9_accuracy: 0.9977\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00535 to 0.00529, saving model to training/training_ckpt/best_model.hdf5\n",
      "Epoch 7/50\n",
      "750/750 [==============================] - 218s 291ms/step - loss: 0.0018 - n_0_loss: 0.0011 - n_1_loss: 0.0015 - n_7_loss: 0.0015 - n_4_loss: 0.0017 - n_2_loss: 0.0024 - n_3_loss: 0.0022 - n_5_loss: 0.0016 - n_6_loss: 0.0019 - n_8_loss: 0.0020 - n_9_loss: 0.0026 - n_0_accuracy: 0.9996 - n_1_accuracy: 0.9996 - n_7_accuracy: 0.9997 - n_4_accuracy: 0.9996 - n_2_accuracy: 0.9993 - n_3_accuracy: 0.9994 - n_5_accuracy: 0.9996 - n_6_accuracy: 0.9996 - n_8_accuracy: 0.9995 - n_9_accuracy: 0.9992 - val_loss: 0.0049 - val_n_0_loss: 0.0020 - val_n_1_loss: 0.0034 - val_n_7_loss: 0.0053 - val_n_4_loss: 0.0042 - val_n_2_loss: 0.0055 - val_n_3_loss: 0.0033 - val_n_5_loss: 0.0043 - val_n_6_loss: 0.0074 - val_n_8_loss: 0.0047 - val_n_9_loss: 0.0087 - val_n_0_accuracy: 0.9992 - val_n_1_accuracy: 0.9992 - val_n_7_accuracy: 0.9989 - val_n_4_accuracy: 0.9991 - val_n_2_accuracy: 0.9984 - val_n_3_accuracy: 0.9994 - val_n_5_accuracy: 0.9993 - val_n_6_accuracy: 0.9984 - val_n_8_accuracy: 0.9989 - val_n_9_accuracy: 0.9980\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00529 to 0.00489, saving model to training/training_ckpt/best_model.hdf5\n",
      "Epoch 8/50\n",
      "750/750 [==============================] - 220s 293ms/step - loss: 0.0013 - n_0_loss: 1.9439e-04 - n_1_loss: 0.0013 - n_7_loss: 0.0010 - n_4_loss: 8.4772e-04 - n_2_loss: 0.0021 - n_3_loss: 9.4344e-04 - n_5_loss: 9.9210e-04 - n_6_loss: 0.0018 - n_8_loss: 0.0014 - n_9_loss: 0.0026 - n_0_accuracy: 0.9999 - n_1_accuracy: 0.9995 - n_7_accuracy: 0.9998 - n_4_accuracy: 0.9998 - n_2_accuracy: 0.9994 - n_3_accuracy: 0.9996 - n_5_accuracy: 0.9997 - n_6_accuracy: 0.9995 - n_8_accuracy: 0.9996 - n_9_accuracy: 0.9992 - val_loss: 0.0082 - val_n_0_loss: 0.0028 - val_n_1_loss: 0.0097 - val_n_7_loss: 0.0061 - val_n_4_loss: 0.0054 - val_n_2_loss: 0.0256 - val_n_3_loss: 0.0039 - val_n_5_loss: 0.0057 - val_n_6_loss: 0.0042 - val_n_8_loss: 0.0062 - val_n_9_loss: 0.0119 - val_n_0_accuracy: 0.9992 - val_n_1_accuracy: 0.9968 - val_n_7_accuracy: 0.9986 - val_n_4_accuracy: 0.9991 - val_n_2_accuracy: 0.9947 - val_n_3_accuracy: 0.9991 - val_n_5_accuracy: 0.9991 - val_n_6_accuracy: 0.9989 - val_n_8_accuracy: 0.9990 - val_n_9_accuracy: 0.9972\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00489\n",
      "Epoch 9/50\n",
      "750/750 [==============================] - 219s 291ms/step - loss: 0.0012 - n_0_loss: 8.1774e-04 - n_1_loss: 0.0014 - n_7_loss: 0.0012 - n_4_loss: 0.0017 - n_2_loss: 0.0017 - n_3_loss: 0.0011 - n_5_loss: 0.0011 - n_6_loss: 0.0015 - n_8_loss: 3.8258e-04 - n_9_loss: 0.0012 - n_0_accuracy: 0.9998 - n_1_accuracy: 0.9996 - n_7_accuracy: 0.9997 - n_4_accuracy: 0.9996 - n_2_accuracy: 0.9995 - n_3_accuracy: 0.9997 - n_5_accuracy: 0.9997 - n_6_accuracy: 0.9995 - n_8_accuracy: 0.9998 - n_9_accuracy: 0.9997 - val_loss: 0.0061 - val_n_0_loss: 0.0044 - val_n_1_loss: 0.0057 - val_n_7_loss: 0.0076 - val_n_4_loss: 0.0079 - val_n_2_loss: 0.0051 - val_n_3_loss: 0.0062 - val_n_5_loss: 0.0044 - val_n_6_loss: 0.0063 - val_n_8_loss: 0.0060 - val_n_9_loss: 0.0076 - val_n_0_accuracy: 0.9991 - val_n_1_accuracy: 0.9991 - val_n_7_accuracy: 0.9986 - val_n_4_accuracy: 0.9988 - val_n_2_accuracy: 0.9993 - val_n_3_accuracy: 0.9989 - val_n_5_accuracy: 0.9989 - val_n_6_accuracy: 0.9986 - val_n_8_accuracy: 0.9991 - val_n_9_accuracy: 0.9985\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00489\n",
      "Epoch 10/50\n",
      "750/750 [==============================] - 220s 293ms/step - loss: 0.0011 - n_0_loss: 8.1274e-04 - n_1_loss: 7.1348e-04 - n_7_loss: 4.6134e-04 - n_4_loss: 0.0011 - n_2_loss: 0.0016 - n_3_loss: 0.0012 - n_5_loss: 9.4432e-04 - n_6_loss: 0.0014 - n_8_loss: 9.5559e-04 - n_9_loss: 0.0017 - n_0_accuracy: 0.9998 - n_1_accuracy: 0.9998 - n_7_accuracy: 0.9999 - n_4_accuracy: 0.9996 - n_2_accuracy: 0.9995 - n_3_accuracy: 0.9996 - n_5_accuracy: 0.9998 - n_6_accuracy: 0.9996 - n_8_accuracy: 0.9998 - n_9_accuracy: 0.9995 - val_loss: 0.0068 - val_n_0_loss: 0.0019 - val_n_1_loss: 0.0053 - val_n_7_loss: 0.0129 - val_n_4_loss: 0.0120 - val_n_2_loss: 0.0064 - val_n_3_loss: 0.0038 - val_n_5_loss: 0.0066 - val_n_6_loss: 0.0063 - val_n_8_loss: 0.0058 - val_n_9_loss: 0.0075 - val_n_0_accuracy: 0.9996 - val_n_1_accuracy: 0.9987 - val_n_7_accuracy: 0.9976 - val_n_4_accuracy: 0.9973 - val_n_2_accuracy: 0.9990 - val_n_3_accuracy: 0.9992 - val_n_5_accuracy: 0.9988 - val_n_6_accuracy: 0.9982 - val_n_8_accuracy: 0.9987 - val_n_9_accuracy: 0.9982\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00489\n",
      "Epoch 11/50\n",
      "750/750 [==============================] - 222s 295ms/step - loss: 0.0011 - n_0_loss: 6.6605e-05 - n_1_loss: 7.6379e-04 - n_7_loss: 0.0021 - n_4_loss: 0.0015 - n_2_loss: 0.0013 - n_3_loss: 0.0012 - n_5_loss: 7.4748e-04 - n_6_loss: 8.8698e-04 - n_8_loss: 0.0010 - n_9_loss: 0.0012 - n_0_accuracy: 1.0000 - n_1_accuracy: 0.9997 - n_7_accuracy: 0.9995 - n_4_accuracy: 0.9996 - n_2_accuracy: 0.9996 - n_3_accuracy: 0.9995 - n_5_accuracy: 0.9998 - n_6_accuracy: 0.9998 - n_8_accuracy: 0.9998 - n_9_accuracy: 0.9996 - val_loss: 0.0053 - val_n_0_loss: 0.0024 - val_n_1_loss: 0.0043 - val_n_7_loss: 0.0049 - val_n_4_loss: 0.0049 - val_n_2_loss: 0.0071 - val_n_3_loss: 0.0032 - val_n_5_loss: 0.0048 - val_n_6_loss: 0.0091 - val_n_8_loss: 0.0047 - val_n_9_loss: 0.0083 - val_n_0_accuracy: 0.9995 - val_n_1_accuracy: 0.9988 - val_n_7_accuracy: 0.9987 - val_n_4_accuracy: 0.9992 - val_n_2_accuracy: 0.9985 - val_n_3_accuracy: 0.9993 - val_n_5_accuracy: 0.9991 - val_n_6_accuracy: 0.9978 - val_n_8_accuracy: 0.9989 - val_n_9_accuracy: 0.9986\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00489\n",
      "Epoch 12/50\n",
      "750/750 [==============================] - 220s 294ms/step - loss: 9.3557e-04 - n_0_loss: 6.7793e-04 - n_1_loss: 0.0012 - n_7_loss: 0.0013 - n_4_loss: 5.1755e-04 - n_2_loss: 0.0011 - n_3_loss: 4.5463e-04 - n_5_loss: 4.2022e-04 - n_6_loss: 0.0013 - n_8_loss: 9.2419e-04 - n_9_loss: 0.0014 - n_0_accuracy: 0.9998 - n_1_accuracy: 0.9997 - n_7_accuracy: 0.9996 - n_4_accuracy: 0.9998 - n_2_accuracy: 0.9996 - n_3_accuracy: 0.9998 - n_5_accuracy: 0.9999 - n_6_accuracy: 0.9996 - n_8_accuracy: 0.9998 - n_9_accuracy: 0.9995 - val_loss: 0.0062 - val_n_0_loss: 0.0027 - val_n_1_loss: 0.0046 - val_n_7_loss: 0.0066 - val_n_4_loss: 0.0049 - val_n_2_loss: 0.0078 - val_n_3_loss: 0.0055 - val_n_5_loss: 0.0069 - val_n_6_loss: 0.0090 - val_n_8_loss: 0.0067 - val_n_9_loss: 0.0073 - val_n_0_accuracy: 0.9994 - val_n_1_accuracy: 0.9985 - val_n_7_accuracy: 0.9983 - val_n_4_accuracy: 0.9992 - val_n_2_accuracy: 0.9984 - val_n_3_accuracy: 0.9991 - val_n_5_accuracy: 0.9989 - val_n_6_accuracy: 0.9977 - val_n_8_accuracy: 0.9986 - val_n_9_accuracy: 0.9985\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00489\n",
      "Epoch 13/50\n",
      "750/750 [==============================] - 218s 291ms/step - loss: 7.8003e-04 - n_0_loss: 6.5438e-04 - n_1_loss: 6.7535e-04 - n_7_loss: 0.0012 - n_4_loss: 6.2383e-04 - n_2_loss: 4.6910e-04 - n_3_loss: 6.7041e-04 - n_5_loss: 8.5866e-04 - n_6_loss: 9.2412e-04 - n_8_loss: 5.3818e-04 - n_9_loss: 0.0011 - n_0_accuracy: 0.9998 - n_1_accuracy: 0.9999 - n_7_accuracy: 0.9996 - n_4_accuracy: 0.9998 - n_2_accuracy: 0.9999 - n_3_accuracy: 0.9997 - n_5_accuracy: 0.9997 - n_6_accuracy: 0.9997 - n_8_accuracy: 0.9998 - n_9_accuracy: 0.9997 - val_loss: 0.0056 - val_n_0_loss: 0.0025 - val_n_1_loss: 0.0054 - val_n_7_loss: 0.0036 - val_n_4_loss: 0.0034 - val_n_2_loss: 0.0076 - val_n_3_loss: 0.0065 - val_n_5_loss: 0.0078 - val_n_6_loss: 0.0083 - val_n_8_loss: 0.0050 - val_n_9_loss: 0.0056 - val_n_0_accuracy: 0.9992 - val_n_1_accuracy: 0.9992 - val_n_7_accuracy: 0.9993 - val_n_4_accuracy: 0.9994 - val_n_2_accuracy: 0.9986 - val_n_3_accuracy: 0.9991 - val_n_5_accuracy: 0.9987 - val_n_6_accuracy: 0.9986 - val_n_8_accuracy: 0.9992 - val_n_9_accuracy: 0.9986\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00489\n",
      "Epoch 14/50\n",
      "750/750 [==============================] - 231s 308ms/step - loss: 7.9062e-04 - n_0_loss: 4.6289e-04 - n_1_loss: 9.4536e-04 - n_7_loss: 6.6649e-04 - n_4_loss: 8.3389e-04 - n_2_loss: 0.0012 - n_3_loss: 7.0557e-04 - n_5_loss: 7.6611e-04 - n_6_loss: 9.4302e-04 - n_8_loss: 6.8967e-04 - n_9_loss: 6.8129e-04 - n_0_accuracy: 0.9999 - n_1_accuracy: 0.9997 - n_7_accuracy: 0.9999 - n_4_accuracy: 0.9998 - n_2_accuracy: 0.9997 - n_3_accuracy: 0.9998 - n_5_accuracy: 0.9998 - n_6_accuracy: 0.9997 - n_8_accuracy: 0.9999 - n_9_accuracy: 0.9998 - val_loss: 0.0066 - val_n_0_loss: 0.0020 - val_n_1_loss: 0.0052 - val_n_7_loss: 0.0042 - val_n_4_loss: 0.0041 - val_n_2_loss: 0.0067 - val_n_3_loss: 0.0088 - val_n_5_loss: 0.0066 - val_n_6_loss: 0.0065 - val_n_8_loss: 0.0123 - val_n_9_loss: 0.0099 - val_n_0_accuracy: 0.9993 - val_n_1_accuracy: 0.9989 - val_n_7_accuracy: 0.9991 - val_n_4_accuracy: 0.9991 - val_n_2_accuracy: 0.9985 - val_n_3_accuracy: 0.9982 - val_n_5_accuracy: 0.9986 - val_n_6_accuracy: 0.9990 - val_n_8_accuracy: 0.9977 - val_n_9_accuracy: 0.9978\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00489\n",
      "Epoch 15/50\n",
      "750/750 [==============================] - 231s 307ms/step - loss: 7.8194e-04 - n_0_loss: 4.5839e-04 - n_1_loss: 4.4050e-04 - n_7_loss: 7.9708e-04 - n_4_loss: 2.1768e-04 - n_2_loss: 0.0011 - n_3_loss: 8.6722e-04 - n_5_loss: 7.0549e-04 - n_6_loss: 7.5446e-04 - n_8_loss: 9.0462e-04 - n_9_loss: 0.0015 - n_0_accuracy: 0.9998 - n_1_accuracy: 0.9998 - n_7_accuracy: 0.9998 - n_4_accuracy: 0.9999 - n_2_accuracy: 0.9996 - n_3_accuracy: 0.9998 - n_5_accuracy: 0.9999 - n_6_accuracy: 0.9998 - n_8_accuracy: 0.9997 - n_9_accuracy: 0.9995 - val_loss: 0.0057 - val_n_0_loss: 0.0021 - val_n_1_loss: 0.0061 - val_n_7_loss: 0.0064 - val_n_4_loss: 0.0075 - val_n_2_loss: 0.0074 - val_n_3_loss: 0.0040 - val_n_5_loss: 0.0068 - val_n_6_loss: 0.0053 - val_n_8_loss: 0.0058 - val_n_9_loss: 0.0060 - val_n_0_accuracy: 0.9994 - val_n_1_accuracy: 0.9989 - val_n_7_accuracy: 0.9988 - val_n_4_accuracy: 0.9994 - val_n_2_accuracy: 0.9986 - val_n_3_accuracy: 0.9996 - val_n_5_accuracy: 0.9989 - val_n_6_accuracy: 0.9989 - val_n_8_accuracy: 0.9990 - val_n_9_accuracy: 0.9985\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00489\n",
      "Epoch 16/50\n",
      "750/750 [==============================] - 220s 294ms/step - loss: 7.4260e-04 - n_0_loss: 4.9907e-04 - n_1_loss: 9.9136e-04 - n_7_loss: 6.0581e-04 - n_4_loss: 0.0010 - n_2_loss: 5.1448e-04 - n_3_loss: 5.0949e-04 - n_5_loss: 6.0568e-04 - n_6_loss: 0.0013 - n_8_loss: 6.5368e-04 - n_9_loss: 7.3321e-04 - n_0_accuracy: 0.9998 - n_1_accuracy: 0.9998 - n_7_accuracy: 0.9999 - n_4_accuracy: 0.9998 - n_2_accuracy: 0.9998 - n_3_accuracy: 0.9999 - n_5_accuracy: 0.9997 - n_6_accuracy: 0.9996 - n_8_accuracy: 0.9998 - n_9_accuracy: 0.9998 - val_loss: 0.0051 - val_n_0_loss: 0.0015 - val_n_1_loss: 0.0031 - val_n_7_loss: 0.0029 - val_n_4_loss: 0.0032 - val_n_2_loss: 0.0083 - val_n_3_loss: 0.0039 - val_n_5_loss: 0.0096 - val_n_6_loss: 0.0053 - val_n_8_loss: 0.0043 - val_n_9_loss: 0.0088 - val_n_0_accuracy: 0.9995 - val_n_1_accuracy: 0.9992 - val_n_7_accuracy: 0.9993 - val_n_4_accuracy: 0.9993 - val_n_2_accuracy: 0.9982 - val_n_3_accuracy: 0.9994 - val_n_5_accuracy: 0.9986 - val_n_6_accuracy: 0.9987 - val_n_8_accuracy: 0.9990 - val_n_9_accuracy: 0.9983\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00489\n",
      "Epoch 17/50\n",
      "750/750 [==============================] - 225s 300ms/step - loss: 7.0015e-04 - n_0_loss: 1.4620e-04 - n_1_loss: 1.4239e-04 - n_7_loss: 6.2358e-04 - n_4_loss: 5.9243e-04 - n_2_loss: 0.0012 - n_3_loss: 2.6874e-04 - n_5_loss: 7.2471e-04 - n_6_loss: 4.3399e-04 - n_8_loss: 0.0011 - n_9_loss: 0.0018 - n_0_accuracy: 1.0000 - n_1_accuracy: 1.0000 - n_7_accuracy: 0.9999 - n_4_accuracy: 0.9998 - n_2_accuracy: 0.9997 - n_3_accuracy: 0.9999 - n_5_accuracy: 0.9998 - n_6_accuracy: 0.9999 - n_8_accuracy: 0.9997 - n_9_accuracy: 0.9995 - val_loss: 0.0054 - val_n_0_loss: 0.0034 - val_n_1_loss: 0.0043 - val_n_7_loss: 0.0042 - val_n_4_loss: 0.0043 - val_n_2_loss: 0.0058 - val_n_3_loss: 0.0061 - val_n_5_loss: 0.0066 - val_n_6_loss: 0.0049 - val_n_8_loss: 0.0076 - val_n_9_loss: 0.0073 - val_n_0_accuracy: 0.9993 - val_n_1_accuracy: 0.9995 - val_n_7_accuracy: 0.9991 - val_n_4_accuracy: 0.9993 - val_n_2_accuracy: 0.9990 - val_n_3_accuracy: 0.9988 - val_n_5_accuracy: 0.9991 - val_n_6_accuracy: 0.9987 - val_n_8_accuracy: 0.9986 - val_n_9_accuracy: 0.9976\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00489\n",
      "Epoch 18/50\n",
      "750/750 [==============================] - 227s 302ms/step - loss: 4.3422e-04 - n_0_loss: 3.4646e-04 - n_1_loss: 4.1846e-04 - n_7_loss: 6.0734e-05 - n_4_loss: 3.1932e-04 - n_2_loss: 2.1833e-04 - n_3_loss: 8.2402e-04 - n_5_loss: 9.0956e-04 - n_6_loss: 4.6142e-04 - n_8_loss: 2.1610e-04 - n_9_loss: 5.6778e-04 - n_0_accuracy: 0.9999 - n_1_accuracy: 0.9999 - n_7_accuracy: 1.0000 - n_4_accuracy: 0.9999 - n_2_accuracy: 0.9999 - n_3_accuracy: 0.9998 - n_5_accuracy: 0.9999 - n_6_accuracy: 0.9999 - n_8_accuracy: 0.9999 - n_9_accuracy: 0.9998 - val_loss: 0.0043 - val_n_0_loss: 9.7682e-04 - val_n_1_loss: 0.0032 - val_n_7_loss: 0.0028 - val_n_4_loss: 0.0026 - val_n_2_loss: 0.0054 - val_n_3_loss: 0.0033 - val_n_5_loss: 0.0060 - val_n_6_loss: 0.0041 - val_n_8_loss: 0.0074 - val_n_9_loss: 0.0069 - val_n_0_accuracy: 0.9996 - val_n_1_accuracy: 0.9992 - val_n_7_accuracy: 0.9994 - val_n_4_accuracy: 0.9995 - val_n_2_accuracy: 0.9991 - val_n_3_accuracy: 0.9996 - val_n_5_accuracy: 0.9991 - val_n_6_accuracy: 0.9992 - val_n_8_accuracy: 0.9991 - val_n_9_accuracy: 0.9985\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00489 to 0.00428, saving model to training/training_ckpt/best_model.hdf5\n",
      "Epoch 19/50\n",
      "750/750 [==============================] - 230s 307ms/step - loss: 3.9886e-04 - n_0_loss: 1.1805e-04 - n_1_loss: 5.3916e-04 - n_7_loss: 6.6133e-04 - n_4_loss: 2.0995e-04 - n_2_loss: 6.9355e-04 - n_3_loss: 1.1997e-04 - n_5_loss: 2.1078e-04 - n_6_loss: 2.1290e-04 - n_8_loss: 3.0828e-04 - n_9_loss: 9.1458e-04 - n_0_accuracy: 1.0000 - n_1_accuracy: 0.9999 - n_7_accuracy: 0.9998 - n_4_accuracy: 0.9999 - n_2_accuracy: 0.9997 - n_3_accuracy: 1.0000 - n_5_accuracy: 1.0000 - n_6_accuracy: 0.9999 - n_8_accuracy: 0.9999 - n_9_accuracy: 0.9997 - val_loss: 0.0056 - val_n_0_loss: 0.0025 - val_n_1_loss: 0.0056 - val_n_7_loss: 0.0055 - val_n_4_loss: 0.0064 - val_n_2_loss: 0.0050 - val_n_3_loss: 0.0042 - val_n_5_loss: 0.0059 - val_n_6_loss: 0.0060 - val_n_8_loss: 0.0077 - val_n_9_loss: 0.0073 - val_n_0_accuracy: 0.9997 - val_n_1_accuracy: 0.9989 - val_n_7_accuracy: 0.9990 - val_n_4_accuracy: 0.9987 - val_n_2_accuracy: 0.9990 - val_n_3_accuracy: 0.9995 - val_n_5_accuracy: 0.9991 - val_n_6_accuracy: 0.9989 - val_n_8_accuracy: 0.9990 - val_n_9_accuracy: 0.9977\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00428\n",
      "Epoch 20/50\n",
      "750/750 [==============================] - 230s 306ms/step - loss: 5.7006e-04 - n_0_loss: 1.8186e-04 - n_1_loss: 3.7123e-04 - n_7_loss: 0.0011 - n_4_loss: 0.0010 - n_2_loss: 4.4872e-04 - n_3_loss: 2.0410e-04 - n_5_loss: 2.0935e-04 - n_6_loss: 8.7456e-04 - n_8_loss: 6.8147e-04 - n_9_loss: 5.7743e-04 - n_0_accuracy: 1.0000 - n_1_accuracy: 0.9999 - n_7_accuracy: 0.9997 - n_4_accuracy: 0.9997 - n_2_accuracy: 0.9999 - n_3_accuracy: 0.9999 - n_5_accuracy: 0.9999 - n_6_accuracy: 0.9999 - n_8_accuracy: 0.9998 - n_9_accuracy: 0.9998 - val_loss: 0.0065 - val_n_0_loss: 0.0022 - val_n_1_loss: 0.0038 - val_n_7_loss: 0.0064 - val_n_4_loss: 0.0149 - val_n_2_loss: 0.0065 - val_n_3_loss: 0.0074 - val_n_5_loss: 0.0090 - val_n_6_loss: 0.0037 - val_n_8_loss: 0.0070 - val_n_9_loss: 0.0041 - val_n_0_accuracy: 0.9996 - val_n_1_accuracy: 0.9992 - val_n_7_accuracy: 0.9990 - val_n_4_accuracy: 0.9979 - val_n_2_accuracy: 0.9990 - val_n_3_accuracy: 0.9985 - val_n_5_accuracy: 0.9987 - val_n_6_accuracy: 0.9991 - val_n_8_accuracy: 0.9987 - val_n_9_accuracy: 0.9987\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00428\n",
      "Epoch 21/50\n",
      "750/750 [==============================] - 228s 303ms/step - loss: 4.4320e-04 - n_0_loss: 1.3534e-04 - n_1_loss: 4.9255e-04 - n_7_loss: 2.3351e-04 - n_4_loss: 5.2417e-04 - n_2_loss: 1.9172e-04 - n_3_loss: 0.0010 - n_5_loss: 3.3092e-04 - n_6_loss: 1.6726e-04 - n_8_loss: 8.3519e-04 - n_9_loss: 4.9044e-04 - n_0_accuracy: 1.0000 - n_1_accuracy: 0.9999 - n_7_accuracy: 0.9999 - n_4_accuracy: 0.9998 - n_2_accuracy: 1.0000 - n_3_accuracy: 0.9998 - n_5_accuracy: 0.9999 - n_6_accuracy: 0.9999 - n_8_accuracy: 0.9998 - n_9_accuracy: 0.9998 - val_loss: 0.0059 - val_n_0_loss: 0.0027 - val_n_1_loss: 0.0082 - val_n_7_loss: 0.0040 - val_n_4_loss: 0.0040 - val_n_2_loss: 0.0099 - val_n_3_loss: 0.0035 - val_n_5_loss: 0.0069 - val_n_6_loss: 0.0057 - val_n_8_loss: 0.0053 - val_n_9_loss: 0.0086 - val_n_0_accuracy: 0.9995 - val_n_1_accuracy: 0.9984 - val_n_7_accuracy: 0.9990 - val_n_4_accuracy: 0.9996 - val_n_2_accuracy: 0.9982 - val_n_3_accuracy: 0.9995 - val_n_5_accuracy: 0.9992 - val_n_6_accuracy: 0.9986 - val_n_8_accuracy: 0.9990 - val_n_9_accuracy: 0.9980\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00428\n",
      "Epoch 22/50\n",
      "750/750 [==============================] - 220s 293ms/step - loss: 3.4593e-04 - n_0_loss: 1.7288e-04 - n_1_loss: 2.8525e-04 - n_7_loss: 4.3671e-04 - n_4_loss: 3.5347e-05 - n_2_loss: 4.5639e-04 - n_3_loss: 1.0715e-04 - n_5_loss: 3.3421e-04 - n_6_loss: 6.3294e-04 - n_8_loss: 2.8432e-04 - n_9_loss: 7.1414e-04 - n_0_accuracy: 1.0000 - n_1_accuracy: 0.9999 - n_7_accuracy: 0.9999 - n_4_accuracy: 1.0000 - n_2_accuracy: 0.9999 - n_3_accuracy: 1.0000 - n_5_accuracy: 0.9999 - n_6_accuracy: 0.9998 - n_8_accuracy: 0.9999 - n_9_accuracy: 0.9998 - val_loss: 0.0071 - val_n_0_loss: 0.0084 - val_n_1_loss: 0.0043 - val_n_7_loss: 0.0058 - val_n_4_loss: 0.0089 - val_n_2_loss: 0.0078 - val_n_3_loss: 0.0066 - val_n_5_loss: 0.0100 - val_n_6_loss: 0.0076 - val_n_8_loss: 0.0049 - val_n_9_loss: 0.0069 - val_n_0_accuracy: 0.9987 - val_n_1_accuracy: 0.9988 - val_n_7_accuracy: 0.9987 - val_n_4_accuracy: 0.9981 - val_n_2_accuracy: 0.9983 - val_n_3_accuracy: 0.9987 - val_n_5_accuracy: 0.9984 - val_n_6_accuracy: 0.9980 - val_n_8_accuracy: 0.9990 - val_n_9_accuracy: 0.9982\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00428\n",
      "Epoch 23/50\n",
      "750/750 [==============================] - 220s 293ms/step - loss: 5.9564e-04 - n_0_loss: 1.7005e-04 - n_1_loss: 7.1675e-04 - n_7_loss: 6.2587e-04 - n_4_loss: 2.5892e-04 - n_2_loss: 7.2467e-04 - n_3_loss: 8.4745e-04 - n_5_loss: 3.1959e-04 - n_6_loss: 5.7705e-04 - n_8_loss: 0.0011 - n_9_loss: 5.8686e-04 - n_0_accuracy: 0.9999 - n_1_accuracy: 0.9998 - n_7_accuracy: 0.9998 - n_4_accuracy: 0.9999 - n_2_accuracy: 0.9997 - n_3_accuracy: 0.9998 - n_5_accuracy: 0.9999 - n_6_accuracy: 0.9998 - n_8_accuracy: 0.9996 - n_9_accuracy: 0.9999 - val_loss: 0.0055 - val_n_0_loss: 0.0035 - val_n_1_loss: 0.0053 - val_n_7_loss: 0.0050 - val_n_4_loss: 0.0067 - val_n_2_loss: 0.0071 - val_n_3_loss: 0.0035 - val_n_5_loss: 0.0082 - val_n_6_loss: 0.0035 - val_n_8_loss: 0.0040 - val_n_9_loss: 0.0077 - val_n_0_accuracy: 0.9997 - val_n_1_accuracy: 0.9989 - val_n_7_accuracy: 0.9987 - val_n_4_accuracy: 0.9992 - val_n_2_accuracy: 0.9990 - val_n_3_accuracy: 0.9994 - val_n_5_accuracy: 0.9991 - val_n_6_accuracy: 0.9988 - val_n_8_accuracy: 0.9992 - val_n_9_accuracy: 0.9983\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00428\n",
      "Epoch 24/50\n",
      "750/750 [==============================] - 219s 292ms/step - loss: 4.1487e-04 - n_0_loss: 6.6234e-04 - n_1_loss: 3.8874e-04 - n_7_loss: 5.0415e-04 - n_4_loss: 1.7528e-04 - n_2_loss: 3.8697e-04 - n_3_loss: 3.2195e-04 - n_5_loss: 4.3304e-04 - n_6_loss: 5.5882e-04 - n_8_loss: 3.0017e-04 - n_9_loss: 4.1727e-04 - n_0_accuracy: 0.9999 - n_1_accuracy: 0.9999 - n_7_accuracy: 0.9999 - n_4_accuracy: 0.9999 - n_2_accuracy: 0.9999 - n_3_accuracy: 0.9999 - n_5_accuracy: 0.9998 - n_6_accuracy: 0.9998 - n_8_accuracy: 0.9999 - n_9_accuracy: 0.9999 - val_loss: 0.0068 - val_n_0_loss: 0.0031 - val_n_1_loss: 0.0056 - val_n_7_loss: 0.0036 - val_n_4_loss: 0.0080 - val_n_2_loss: 0.0086 - val_n_3_loss: 0.0068 - val_n_5_loss: 0.0117 - val_n_6_loss: 0.0048 - val_n_8_loss: 0.0065 - val_n_9_loss: 0.0094 - val_n_0_accuracy: 0.9993 - val_n_1_accuracy: 0.9992 - val_n_7_accuracy: 0.9992 - val_n_4_accuracy: 0.9992 - val_n_2_accuracy: 0.9987 - val_n_3_accuracy: 0.9992 - val_n_5_accuracy: 0.9987 - val_n_6_accuracy: 0.9991 - val_n_8_accuracy: 0.9988 - val_n_9_accuracy: 0.9983\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00428\n",
      "Epoch 25/50\n",
      "750/750 [==============================] - 219s 293ms/step - loss: 2.5944e-04 - n_0_loss: 7.2208e-05 - n_1_loss: 1.7360e-04 - n_7_loss: 1.5004e-04 - n_4_loss: 1.1959e-04 - n_2_loss: 4.8098e-04 - n_3_loss: 1.3371e-04 - n_5_loss: 2.4486e-04 - n_6_loss: 3.7456e-04 - n_8_loss: 2.6247e-04 - n_9_loss: 5.8240e-04 - n_0_accuracy: 1.0000 - n_1_accuracy: 0.9999 - n_7_accuracy: 1.0000 - n_4_accuracy: 1.0000 - n_2_accuracy: 0.9999 - n_3_accuracy: 1.0000 - n_5_accuracy: 1.0000 - n_6_accuracy: 0.9998 - n_8_accuracy: 0.9999 - n_9_accuracy: 0.9998 - val_loss: 0.0069 - val_n_0_loss: 0.0023 - val_n_1_loss: 0.0076 - val_n_7_loss: 0.0046 - val_n_4_loss: 0.0056 - val_n_2_loss: 0.0092 - val_n_3_loss: 0.0101 - val_n_5_loss: 0.0083 - val_n_6_loss: 0.0047 - val_n_8_loss: 0.0083 - val_n_9_loss: 0.0080 - val_n_0_accuracy: 0.9996 - val_n_1_accuracy: 0.9986 - val_n_7_accuracy: 0.9991 - val_n_4_accuracy: 0.9994 - val_n_2_accuracy: 0.9986 - val_n_3_accuracy: 0.9990 - val_n_5_accuracy: 0.9989 - val_n_6_accuracy: 0.9988 - val_n_8_accuracy: 0.9989 - val_n_9_accuracy: 0.9984\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00428\n",
      "Epoch 26/50\n",
      "750/750 [==============================] - 219s 292ms/step - loss: 4.6184e-04 - n_0_loss: 1.3160e-05 - n_1_loss: 2.6396e-04 - n_7_loss: 2.4423e-04 - n_4_loss: 6.4324e-04 - n_2_loss: 2.4137e-04 - n_3_loss: 0.0012 - n_5_loss: 3.1848e-04 - n_6_loss: 6.7358e-04 - n_8_loss: 4.8611e-04 - n_9_loss: 5.3282e-04 - n_0_accuracy: 1.0000 - n_1_accuracy: 0.9999 - n_7_accuracy: 0.9999 - n_4_accuracy: 0.9999 - n_2_accuracy: 1.0000 - n_3_accuracy: 0.9998 - n_5_accuracy: 0.9999 - n_6_accuracy: 0.9997 - n_8_accuracy: 0.9999 - n_9_accuracy: 0.9998 - val_loss: 0.0071 - val_n_0_loss: 0.0027 - val_n_1_loss: 0.0055 - val_n_7_loss: 0.0061 - val_n_4_loss: 0.0082 - val_n_2_loss: 0.0121 - val_n_3_loss: 0.0033 - val_n_5_loss: 0.0059 - val_n_6_loss: 0.0095 - val_n_8_loss: 0.0078 - val_n_9_loss: 0.0097 - val_n_0_accuracy: 0.9997 - val_n_1_accuracy: 0.9990 - val_n_7_accuracy: 0.9988 - val_n_4_accuracy: 0.9989 - val_n_2_accuracy: 0.9984 - val_n_3_accuracy: 0.9992 - val_n_5_accuracy: 0.9992 - val_n_6_accuracy: 0.9983 - val_n_8_accuracy: 0.9991 - val_n_9_accuracy: 0.9982\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00428\n",
      "Epoch 27/50\n",
      "750/750 [==============================] - 218s 291ms/step - loss: 3.7111e-04 - n_0_loss: 5.2113e-04 - n_1_loss: 3.0603e-04 - n_7_loss: 6.6845e-05 - n_4_loss: 1.2994e-04 - n_2_loss: 5.9515e-04 - n_3_loss: 2.0714e-04 - n_5_loss: 2.5494e-04 - n_6_loss: 5.6401e-04 - n_8_loss: 2.8660e-04 - n_9_loss: 7.7935e-04 - n_0_accuracy: 0.9999 - n_1_accuracy: 0.9999 - n_7_accuracy: 1.0000 - n_4_accuracy: 1.0000 - n_2_accuracy: 0.9999 - n_3_accuracy: 0.9999 - n_5_accuracy: 0.9999 - n_6_accuracy: 0.9998 - n_8_accuracy: 1.0000 - n_9_accuracy: 0.9998 - val_loss: 0.0068 - val_n_0_loss: 0.0030 - val_n_1_loss: 0.0047 - val_n_7_loss: 0.0046 - val_n_4_loss: 0.0074 - val_n_2_loss: 0.0112 - val_n_3_loss: 0.0036 - val_n_5_loss: 0.0070 - val_n_6_loss: 0.0071 - val_n_8_loss: 0.0068 - val_n_9_loss: 0.0129 - val_n_0_accuracy: 0.9994 - val_n_1_accuracy: 0.9992 - val_n_7_accuracy: 0.9991 - val_n_4_accuracy: 0.9992 - val_n_2_accuracy: 0.9972 - val_n_3_accuracy: 0.9995 - val_n_5_accuracy: 0.9992 - val_n_6_accuracy: 0.9987 - val_n_8_accuracy: 0.9993 - val_n_9_accuracy: 0.9967\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00428\n",
      "Epoch 28/50\n",
      "750/750 [==============================] - 219s 291ms/step - loss: 3.8370e-04 - n_0_loss: 1.4159e-04 - n_1_loss: 3.1615e-04 - n_7_loss: 3.3017e-04 - n_4_loss: 7.2485e-04 - n_2_loss: 5.6150e-04 - n_3_loss: 3.8707e-04 - n_5_loss: 3.6369e-04 - n_6_loss: 2.7163e-04 - n_8_loss: 1.9447e-04 - n_9_loss: 5.4588e-04 - n_0_accuracy: 1.0000 - n_1_accuracy: 0.9999 - n_7_accuracy: 0.9999 - n_4_accuracy: 0.9998 - n_2_accuracy: 0.9999 - n_3_accuracy: 0.9999 - n_5_accuracy: 0.9999 - n_6_accuracy: 1.0000 - n_8_accuracy: 1.0000 - n_9_accuracy: 0.9999 - val_loss: 0.0060 - val_n_0_loss: 0.0022 - val_n_1_loss: 0.0042 - val_n_7_loss: 0.0060 - val_n_4_loss: 0.0068 - val_n_2_loss: 0.0070 - val_n_3_loss: 0.0035 - val_n_5_loss: 0.0083 - val_n_6_loss: 0.0091 - val_n_8_loss: 0.0063 - val_n_9_loss: 0.0066 - val_n_0_accuracy: 0.9996 - val_n_1_accuracy: 0.9991 - val_n_7_accuracy: 0.9988 - val_n_4_accuracy: 0.9990 - val_n_2_accuracy: 0.9988 - val_n_3_accuracy: 0.9995 - val_n_5_accuracy: 0.9991 - val_n_6_accuracy: 0.9988 - val_n_8_accuracy: 0.9993 - val_n_9_accuracy: 0.9987\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00428\n",
      "Epoch 29/50\n",
      "750/750 [==============================] - 219s 291ms/step - loss: 2.8373e-04 - n_0_loss: 2.0328e-05 - n_1_loss: 4.4063e-04 - n_7_loss: 4.4375e-04 - n_4_loss: 2.3384e-04 - n_2_loss: 4.6269e-04 - n_3_loss: 1.8438e-05 - n_5_loss: 5.3347e-04 - n_6_loss: 5.1495e-04 - n_8_loss: 6.8327e-05 - n_9_loss: 1.0092e-04 - n_0_accuracy: 1.0000 - n_1_accuracy: 0.9999 - n_7_accuracy: 0.9999 - n_4_accuracy: 0.9999 - n_2_accuracy: 0.9999 - n_3_accuracy: 1.0000 - n_5_accuracy: 1.0000 - n_6_accuracy: 0.9999 - n_8_accuracy: 1.0000 - n_9_accuracy: 1.0000 - val_loss: 0.0072 - val_n_0_loss: 0.0032 - val_n_1_loss: 0.0036 - val_n_7_loss: 0.0054 - val_n_4_loss: 0.0052 - val_n_2_loss: 0.0133 - val_n_3_loss: 0.0049 - val_n_5_loss: 0.0072 - val_n_6_loss: 0.0058 - val_n_8_loss: 0.0076 - val_n_9_loss: 0.0154 - val_n_0_accuracy: 0.9997 - val_n_1_accuracy: 0.9993 - val_n_7_accuracy: 0.9991 - val_n_4_accuracy: 0.9991 - val_n_2_accuracy: 0.9983 - val_n_3_accuracy: 0.9994 - val_n_5_accuracy: 0.9994 - val_n_6_accuracy: 0.9989 - val_n_8_accuracy: 0.9988 - val_n_9_accuracy: 0.9980\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00428\n",
      "Epoch 30/50\n",
      "750/750 [==============================] - 219s 292ms/step - loss: 4.1387e-04 - n_0_loss: 3.8021e-04 - n_1_loss: 8.4137e-05 - n_7_loss: 7.1430e-04 - n_4_loss: 3.9598e-04 - n_2_loss: 7.2755e-04 - n_3_loss: 3.1635e-04 - n_5_loss: 3.9214e-04 - n_6_loss: 1.0900e-04 - n_8_loss: 5.7817e-04 - n_9_loss: 4.4084e-04 - n_0_accuracy: 1.0000 - n_1_accuracy: 1.0000 - n_7_accuracy: 0.9998 - n_4_accuracy: 0.9999 - n_2_accuracy: 0.9999 - n_3_accuracy: 1.0000 - n_5_accuracy: 0.9999 - n_6_accuracy: 1.0000 - n_8_accuracy: 0.9998 - n_9_accuracy: 1.0000 - val_loss: 0.0058 - val_n_0_loss: 0.0055 - val_n_1_loss: 0.0051 - val_n_7_loss: 0.0036 - val_n_4_loss: 0.0039 - val_n_2_loss: 0.0064 - val_n_3_loss: 0.0067 - val_n_5_loss: 0.0080 - val_n_6_loss: 0.0065 - val_n_8_loss: 0.0050 - val_n_9_loss: 0.0076 - val_n_0_accuracy: 0.9993 - val_n_1_accuracy: 0.9993 - val_n_7_accuracy: 0.9994 - val_n_4_accuracy: 0.9995 - val_n_2_accuracy: 0.9991 - val_n_3_accuracy: 0.9993 - val_n_5_accuracy: 0.9992 - val_n_6_accuracy: 0.9990 - val_n_8_accuracy: 0.9992 - val_n_9_accuracy: 0.9987\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00428\n",
      "Epoch 31/50\n",
      "750/750 [==============================] - 220s 293ms/step - loss: 2.5484e-04 - n_0_loss: 3.5788e-06 - n_1_loss: 1.5834e-04 - n_7_loss: 1.0072e-04 - n_4_loss: 2.1763e-04 - n_2_loss: 2.5826e-04 - n_3_loss: 5.7666e-04 - n_5_loss: 5.0459e-04 - n_6_loss: 2.3526e-04 - n_8_loss: 2.7844e-04 - n_9_loss: 2.1492e-04 - n_0_accuracy: 1.0000 - n_1_accuracy: 1.0000 - n_7_accuracy: 1.0000 - n_4_accuracy: 0.9999 - n_2_accuracy: 1.0000 - n_3_accuracy: 0.9998 - n_5_accuracy: 0.9998 - n_6_accuracy: 0.9999 - n_8_accuracy: 0.9999 - n_9_accuracy: 0.9999 - val_loss: 0.0053 - val_n_0_loss: 0.0041 - val_n_1_loss: 0.0060 - val_n_7_loss: 0.0035 - val_n_4_loss: 0.0043 - val_n_2_loss: 0.0061 - val_n_3_loss: 0.0035 - val_n_5_loss: 0.0073 - val_n_6_loss: 0.0060 - val_n_8_loss: 0.0041 - val_n_9_loss: 0.0084 - val_n_0_accuracy: 0.9994 - val_n_1_accuracy: 0.9991 - val_n_7_accuracy: 0.9992 - val_n_4_accuracy: 0.9994 - val_n_2_accuracy: 0.9988 - val_n_3_accuracy: 0.9994 - val_n_5_accuracy: 0.9989 - val_n_6_accuracy: 0.9986 - val_n_8_accuracy: 0.9993 - val_n_9_accuracy: 0.9983\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00428\n",
      "Epoch 32/50\n",
      "750/750 [==============================] - 227s 303ms/step - loss: 1.6350e-04 - n_0_loss: 7.5385e-04 - n_1_loss: 3.0703e-05 - n_7_loss: 7.7281e-05 - n_4_loss: 2.8659e-05 - n_2_loss: 3.8050e-05 - n_3_loss: 4.9844e-05 - n_5_loss: 4.3336e-04 - n_6_loss: 3.2105e-05 - n_8_loss: 1.6813e-04 - n_9_loss: 2.3028e-05 - n_0_accuracy: 0.9998 - n_1_accuracy: 1.0000 - n_7_accuracy: 1.0000 - n_4_accuracy: 1.0000 - n_2_accuracy: 1.0000 - n_3_accuracy: 1.0000 - n_5_accuracy: 0.9999 - n_6_accuracy: 1.0000 - n_8_accuracy: 1.0000 - n_9_accuracy: 1.0000 - val_loss: 0.0073 - val_n_0_loss: 9.6537e-04 - val_n_1_loss: 0.0099 - val_n_7_loss: 0.0100 - val_n_4_loss: 0.0087 - val_n_2_loss: 0.0080 - val_n_3_loss: 0.0041 - val_n_5_loss: 0.0077 - val_n_6_loss: 0.0086 - val_n_8_loss: 0.0050 - val_n_9_loss: 0.0104 - val_n_0_accuracy: 0.9997 - val_n_1_accuracy: 0.9992 - val_n_7_accuracy: 0.9992 - val_n_4_accuracy: 0.9989 - val_n_2_accuracy: 0.9991 - val_n_3_accuracy: 0.9996 - val_n_5_accuracy: 0.9992 - val_n_6_accuracy: 0.9987 - val_n_8_accuracy: 0.9992 - val_n_9_accuracy: 0.9987\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00428\n",
      "Epoch 33/50\n",
      "750/750 [==============================] - 228s 304ms/step - loss: 2.5333e-04 - n_0_loss: 4.6404e-05 - n_1_loss: 6.1048e-04 - n_7_loss: 4.3566e-04 - n_4_loss: 5.2208e-05 - n_2_loss: 3.3404e-04 - n_3_loss: 1.3590e-04 - n_5_loss: 7.4228e-05 - n_6_loss: 7.0842e-04 - n_8_loss: 1.3106e-04 - n_9_loss: 4.9293e-06 - n_0_accuracy: 1.0000 - n_1_accuracy: 0.9999 - n_7_accuracy: 0.9999 - n_4_accuracy: 1.0000 - n_2_accuracy: 1.0000 - n_3_accuracy: 1.0000 - n_5_accuracy: 1.0000 - n_6_accuracy: 0.9998 - n_8_accuracy: 1.0000 - n_9_accuracy: 1.0000 - val_loss: 0.0074 - val_n_0_loss: 0.0015 - val_n_1_loss: 0.0069 - val_n_7_loss: 0.0067 - val_n_4_loss: 0.0124 - val_n_2_loss: 0.0065 - val_n_3_loss: 0.0059 - val_n_5_loss: 0.0088 - val_n_6_loss: 0.0063 - val_n_8_loss: 0.0067 - val_n_9_loss: 0.0126 - val_n_0_accuracy: 0.9996 - val_n_1_accuracy: 0.9990 - val_n_7_accuracy: 0.9989 - val_n_4_accuracy: 0.9989 - val_n_2_accuracy: 0.9990 - val_n_3_accuracy: 0.9992 - val_n_5_accuracy: 0.9992 - val_n_6_accuracy: 0.9985 - val_n_8_accuracy: 0.9988 - val_n_9_accuracy: 0.9985\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00428\n",
      "Epoch 34/50\n",
      "750/750 [==============================] - 223s 298ms/step - loss: 3.0945e-04 - n_0_loss: 1.2399e-04 - n_1_loss: 2.2107e-04 - n_7_loss: 5.8688e-04 - n_4_loss: 6.3763e-04 - n_2_loss: 3.6897e-05 - n_3_loss: 3.7558e-04 - n_5_loss: 8.2154e-05 - n_6_loss: 2.5150e-04 - n_8_loss: 5.6164e-04 - n_9_loss: 2.1720e-04 - n_0_accuracy: 1.0000 - n_1_accuracy: 0.9999 - n_7_accuracy: 0.9998 - n_4_accuracy: 0.9999 - n_2_accuracy: 1.0000 - n_3_accuracy: 0.9999 - n_5_accuracy: 1.0000 - n_6_accuracy: 0.9999 - n_8_accuracy: 0.9999 - n_9_accuracy: 0.9999 - val_loss: 0.0077 - val_n_0_loss: 0.0051 - val_n_1_loss: 0.0058 - val_n_7_loss: 0.0054 - val_n_4_loss: 0.0067 - val_n_2_loss: 0.0115 - val_n_3_loss: 0.0059 - val_n_5_loss: 0.0098 - val_n_6_loss: 0.0069 - val_n_8_loss: 0.0057 - val_n_9_loss: 0.0147 - val_n_0_accuracy: 0.9994 - val_n_1_accuracy: 0.9992 - val_n_7_accuracy: 0.9990 - val_n_4_accuracy: 0.9991 - val_n_2_accuracy: 0.9990 - val_n_3_accuracy: 0.9993 - val_n_5_accuracy: 0.9994 - val_n_6_accuracy: 0.9987 - val_n_8_accuracy: 0.9993 - val_n_9_accuracy: 0.9982\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00428\n",
      "Epoch 35/50\n",
      "750/750 [==============================] - 221s 295ms/step - loss: 4.7771e-04 - n_0_loss: 2.4557e-04 - n_1_loss: 7.0871e-04 - n_7_loss: 1.5441e-04 - n_4_loss: 1.7592e-04 - n_2_loss: 0.0012 - n_3_loss: 1.5071e-04 - n_5_loss: 3.0786e-04 - n_6_loss: 1.6610e-04 - n_8_loss: 5.7270e-04 - n_9_loss: 0.0011 - n_0_accuracy: 0.9999 - n_1_accuracy: 0.9999 - n_7_accuracy: 1.0000 - n_4_accuracy: 0.9999 - n_2_accuracy: 0.9998 - n_3_accuracy: 0.9999 - n_5_accuracy: 0.9999 - n_6_accuracy: 1.0000 - n_8_accuracy: 0.9999 - n_9_accuracy: 0.9999 - val_loss: 0.0070 - val_n_0_loss: 0.0036 - val_n_1_loss: 0.0028 - val_n_7_loss: 0.0042 - val_n_4_loss: 0.0081 - val_n_2_loss: 0.0075 - val_n_3_loss: 0.0129 - val_n_5_loss: 0.0102 - val_n_6_loss: 0.0061 - val_n_8_loss: 0.0050 - val_n_9_loss: 0.0095 - val_n_0_accuracy: 0.9993 - val_n_1_accuracy: 0.9993 - val_n_7_accuracy: 0.9993 - val_n_4_accuracy: 0.9989 - val_n_2_accuracy: 0.9988 - val_n_3_accuracy: 0.9986 - val_n_5_accuracy: 0.9993 - val_n_6_accuracy: 0.9986 - val_n_8_accuracy: 0.9991 - val_n_9_accuracy: 0.9981\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00428\n",
      "Epoch 36/50\n",
      "750/750 [==============================] - 222s 296ms/step - loss: 2.7717e-04 - n_0_loss: 4.5934e-04 - n_1_loss: 8.8665e-05 - n_7_loss: 1.7470e-04 - n_4_loss: 4.5641e-04 - n_2_loss: 4.0774e-04 - n_3_loss: 4.0226e-04 - n_5_loss: 5.2835e-04 - n_6_loss: 4.4087e-05 - n_8_loss: 7.9674e-05 - n_9_loss: 1.3048e-04 - n_0_accuracy: 0.9998 - n_1_accuracy: 1.0000 - n_7_accuracy: 0.9999 - n_4_accuracy: 0.9998 - n_2_accuracy: 0.9999 - n_3_accuracy: 0.9999 - n_5_accuracy: 0.9999 - n_6_accuracy: 1.0000 - n_8_accuracy: 1.0000 - n_9_accuracy: 1.0000 - val_loss: 0.0075 - val_n_0_loss: 0.0033 - val_n_1_loss: 0.0031 - val_n_7_loss: 0.0048 - val_n_4_loss: 0.0074 - val_n_2_loss: 0.0070 - val_n_3_loss: 0.0096 - val_n_5_loss: 0.0103 - val_n_6_loss: 0.0082 - val_n_8_loss: 0.0108 - val_n_9_loss: 0.0107 - val_n_0_accuracy: 0.9993 - val_n_1_accuracy: 0.9992 - val_n_7_accuracy: 0.9992 - val_n_4_accuracy: 0.9991 - val_n_2_accuracy: 0.9988 - val_n_3_accuracy: 0.9991 - val_n_5_accuracy: 0.9992 - val_n_6_accuracy: 0.9989 - val_n_8_accuracy: 0.9987 - val_n_9_accuracy: 0.9982\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00428\n",
      "Epoch 37/50\n",
      "750/750 [==============================] - 222s 296ms/step - loss: 3.4743e-04 - n_0_loss: 2.8698e-05 - n_1_loss: 4.9796e-04 - n_7_loss: 2.7530e-04 - n_4_loss: 4.0773e-04 - n_2_loss: 2.6858e-04 - n_3_loss: 4.5145e-04 - n_5_loss: 2.1327e-04 - n_6_loss: 3.7055e-04 - n_8_loss: 2.9696e-04 - n_9_loss: 6.6381e-04 - n_0_accuracy: 1.0000 - n_1_accuracy: 0.9999 - n_7_accuracy: 0.9999 - n_4_accuracy: 0.9999 - n_2_accuracy: 1.0000 - n_3_accuracy: 0.9999 - n_5_accuracy: 0.9999 - n_6_accuracy: 0.9999 - n_8_accuracy: 0.9999 - n_9_accuracy: 0.9998 - val_loss: 0.0064 - val_n_0_loss: 0.0041 - val_n_1_loss: 0.0053 - val_n_7_loss: 0.0086 - val_n_4_loss: 0.0060 - val_n_2_loss: 0.0059 - val_n_3_loss: 0.0046 - val_n_5_loss: 0.0090 - val_n_6_loss: 0.0100 - val_n_8_loss: 0.0035 - val_n_9_loss: 0.0068 - val_n_0_accuracy: 0.9992 - val_n_1_accuracy: 0.9988 - val_n_7_accuracy: 0.9991 - val_n_4_accuracy: 0.9992 - val_n_2_accuracy: 0.9990 - val_n_3_accuracy: 0.9993 - val_n_5_accuracy: 0.9995 - val_n_6_accuracy: 0.9983 - val_n_8_accuracy: 0.9992 - val_n_9_accuracy: 0.9987\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00428\n",
      "Epoch 38/50\n",
      "750/750 [==============================] - 223s 297ms/step - loss: 4.2132e-04 - n_0_loss: 4.3460e-04 - n_1_loss: 2.5252e-04 - n_7_loss: 6.4960e-04 - n_4_loss: 3.6267e-04 - n_2_loss: 7.3497e-04 - n_3_loss: 3.0736e-04 - n_5_loss: 2.1867e-04 - n_6_loss: 3.9483e-04 - n_8_loss: 1.1589e-04 - n_9_loss: 7.4207e-04 - n_0_accuracy: 0.9999 - n_1_accuracy: 0.9999 - n_7_accuracy: 0.9998 - n_4_accuracy: 0.9999 - n_2_accuracy: 0.9998 - n_3_accuracy: 0.9999 - n_5_accuracy: 1.0000 - n_6_accuracy: 0.9999 - n_8_accuracy: 0.9999 - n_9_accuracy: 0.9998 - val_loss: 0.0054 - val_n_0_loss: 0.0039 - val_n_1_loss: 0.0028 - val_n_7_loss: 0.0043 - val_n_4_loss: 0.0084 - val_n_2_loss: 0.0054 - val_n_3_loss: 0.0050 - val_n_5_loss: 0.0081 - val_n_6_loss: 0.0042 - val_n_8_loss: 0.0048 - val_n_9_loss: 0.0069 - val_n_0_accuracy: 0.9992 - val_n_1_accuracy: 0.9993 - val_n_7_accuracy: 0.9987 - val_n_4_accuracy: 0.9987 - val_n_2_accuracy: 0.9989 - val_n_3_accuracy: 0.9989 - val_n_5_accuracy: 0.9990 - val_n_6_accuracy: 0.9988 - val_n_8_accuracy: 0.9992 - val_n_9_accuracy: 0.9982\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00428\n",
      "Epoch 39/50\n",
      "750/750 [==============================] - 223s 297ms/step - loss: 1.9036e-04 - n_0_loss: 3.0162e-04 - n_1_loss: 1.8481e-05 - n_7_loss: 1.2838e-04 - n_4_loss: 1.8343e-05 - n_2_loss: 2.2569e-04 - n_3_loss: 4.1244e-05 - n_5_loss: 4.5816e-04 - n_6_loss: 3.1228e-04 - n_8_loss: 3.2027e-04 - n_9_loss: 7.9143e-05 - n_0_accuracy: 0.9999 - n_1_accuracy: 1.0000 - n_7_accuracy: 1.0000 - n_4_accuracy: 1.0000 - n_2_accuracy: 0.9999 - n_3_accuracy: 1.0000 - n_5_accuracy: 0.9999 - n_6_accuracy: 1.0000 - n_8_accuracy: 1.0000 - n_9_accuracy: 1.0000 - val_loss: 0.0084 - val_n_0_loss: 0.0086 - val_n_1_loss: 0.0138 - val_n_7_loss: 0.0126 - val_n_4_loss: 0.0079 - val_n_2_loss: 0.0076 - val_n_3_loss: 0.0051 - val_n_5_loss: 0.0072 - val_n_6_loss: 0.0058 - val_n_8_loss: 0.0061 - val_n_9_loss: 0.0096 - val_n_0_accuracy: 0.9986 - val_n_1_accuracy: 0.9981 - val_n_7_accuracy: 0.9987 - val_n_4_accuracy: 0.9992 - val_n_2_accuracy: 0.9989 - val_n_3_accuracy: 0.9993 - val_n_5_accuracy: 0.9989 - val_n_6_accuracy: 0.9990 - val_n_8_accuracy: 0.9990 - val_n_9_accuracy: 0.9983\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00428\n",
      "Epoch 40/50\n",
      "750/750 [==============================] - 220s 293ms/step - loss: 2.9748e-04 - n_0_loss: 2.1831e-05 - n_1_loss: 4.8031e-04 - n_7_loss: 3.3686e-04 - n_4_loss: 3.4960e-05 - n_2_loss: 2.2156e-04 - n_3_loss: 1.9550e-04 - n_5_loss: 5.0301e-04 - n_6_loss: 4.3744e-04 - n_8_loss: 1.3467e-04 - n_9_loss: 6.0863e-04 - n_0_accuracy: 1.0000 - n_1_accuracy: 0.9999 - n_7_accuracy: 0.9999 - n_4_accuracy: 1.0000 - n_2_accuracy: 0.9999 - n_3_accuracy: 1.0000 - n_5_accuracy: 0.9999 - n_6_accuracy: 0.9999 - n_8_accuracy: 1.0000 - n_9_accuracy: 0.9998 - val_loss: 0.0072 - val_n_0_loss: 0.0020 - val_n_1_loss: 0.0063 - val_n_7_loss: 0.0063 - val_n_4_loss: 0.0070 - val_n_2_loss: 0.0075 - val_n_3_loss: 0.0050 - val_n_5_loss: 0.0085 - val_n_6_loss: 0.0108 - val_n_8_loss: 0.0057 - val_n_9_loss: 0.0123 - val_n_0_accuracy: 0.9997 - val_n_1_accuracy: 0.9989 - val_n_7_accuracy: 0.9991 - val_n_4_accuracy: 0.9992 - val_n_2_accuracy: 0.9988 - val_n_3_accuracy: 0.9996 - val_n_5_accuracy: 0.9992 - val_n_6_accuracy: 0.9982 - val_n_8_accuracy: 0.9989 - val_n_9_accuracy: 0.9978\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00428\n",
      "Epoch 41/50\n",
      "750/750 [==============================] - 222s 295ms/step - loss: 1.8493e-04 - n_0_loss: 1.1612e-04 - n_1_loss: 8.4053e-05 - n_7_loss: 7.1248e-05 - n_4_loss: 3.2443e-04 - n_2_loss: 1.0535e-05 - n_3_loss: 2.0210e-05 - n_5_loss: 2.2331e-05 - n_6_loss: 2.9284e-04 - n_8_loss: 7.2385e-04 - n_9_loss: 1.8368e-04 - n_0_accuracy: 1.0000 - n_1_accuracy: 1.0000 - n_7_accuracy: 1.0000 - n_4_accuracy: 0.9999 - n_2_accuracy: 1.0000 - n_3_accuracy: 1.0000 - n_5_accuracy: 1.0000 - n_6_accuracy: 0.9999 - n_8_accuracy: 0.9998 - n_9_accuracy: 0.9999 - val_loss: 0.0061 - val_n_0_loss: 0.0010 - val_n_1_loss: 0.0028 - val_n_7_loss: 0.0053 - val_n_4_loss: 0.0051 - val_n_2_loss: 0.0107 - val_n_3_loss: 0.0074 - val_n_5_loss: 0.0080 - val_n_6_loss: 0.0066 - val_n_8_loss: 0.0049 - val_n_9_loss: 0.0087 - val_n_0_accuracy: 0.9997 - val_n_1_accuracy: 0.9993 - val_n_7_accuracy: 0.9992 - val_n_4_accuracy: 0.9992 - val_n_2_accuracy: 0.9988 - val_n_3_accuracy: 0.9993 - val_n_5_accuracy: 0.9991 - val_n_6_accuracy: 0.9984 - val_n_8_accuracy: 0.9990 - val_n_9_accuracy: 0.9982\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00428\n",
      "Epoch 42/50\n",
      "750/750 [==============================] - 220s 293ms/step - loss: 2.4972e-04 - n_0_loss: 1.6899e-05 - n_1_loss: 3.6116e-04 - n_7_loss: 9.8034e-05 - n_4_loss: 2.3205e-05 - n_2_loss: 4.4587e-04 - n_3_loss: 4.4139e-04 - n_5_loss: 3.0533e-04 - n_6_loss: 1.7161e-04 - n_8_loss: 1.9181e-04 - n_9_loss: 4.4189e-04 - n_0_accuracy: 1.0000 - n_1_accuracy: 0.9999 - n_7_accuracy: 1.0000 - n_4_accuracy: 1.0000 - n_2_accuracy: 0.9999 - n_3_accuracy: 0.9999 - n_5_accuracy: 0.9999 - n_6_accuracy: 1.0000 - n_8_accuracy: 1.0000 - n_9_accuracy: 0.9999 - val_loss: 0.0081 - val_n_0_loss: 0.0017 - val_n_1_loss: 0.0131 - val_n_7_loss: 0.0042 - val_n_4_loss: 0.0052 - val_n_2_loss: 0.0083 - val_n_3_loss: 0.0044 - val_n_5_loss: 0.0093 - val_n_6_loss: 0.0199 - val_n_8_loss: 0.0043 - val_n_9_loss: 0.0106 - val_n_0_accuracy: 0.9996 - val_n_1_accuracy: 0.9974 - val_n_7_accuracy: 0.9993 - val_n_4_accuracy: 0.9992 - val_n_2_accuracy: 0.9988 - val_n_3_accuracy: 0.9994 - val_n_5_accuracy: 0.9992 - val_n_6_accuracy: 0.9964 - val_n_8_accuracy: 0.9990 - val_n_9_accuracy: 0.9985\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00428\n",
      "Epoch 43/50\n",
      "750/750 [==============================] - 223s 297ms/step - loss: 2.4191e-04 - n_0_loss: 3.0758e-06 - n_1_loss: 2.8866e-04 - n_7_loss: 6.0305e-04 - n_4_loss: 3.7434e-05 - n_2_loss: 7.5696e-05 - n_3_loss: 5.5698e-06 - n_5_loss: 1.2945e-05 - n_6_loss: 0.0013 - n_8_loss: 2.8727e-05 - n_9_loss: 7.0741e-05 - n_0_accuracy: 1.0000 - n_1_accuracy: 1.0000 - n_7_accuracy: 0.9999 - n_4_accuracy: 1.0000 - n_2_accuracy: 1.0000 - n_3_accuracy: 1.0000 - n_5_accuracy: 1.0000 - n_6_accuracy: 0.9998 - n_8_accuracy: 1.0000 - n_9_accuracy: 1.0000 - val_loss: 0.0066 - val_n_0_loss: 0.0036 - val_n_1_loss: 0.0017 - val_n_7_loss: 0.0037 - val_n_4_loss: 0.0075 - val_n_2_loss: 0.0112 - val_n_3_loss: 0.0065 - val_n_5_loss: 0.0101 - val_n_6_loss: 0.0050 - val_n_8_loss: 0.0049 - val_n_9_loss: 0.0120 - val_n_0_accuracy: 0.9997 - val_n_1_accuracy: 0.9994 - val_n_7_accuracy: 0.9992 - val_n_4_accuracy: 0.9991 - val_n_2_accuracy: 0.9987 - val_n_3_accuracy: 0.9993 - val_n_5_accuracy: 0.9992 - val_n_6_accuracy: 0.9987 - val_n_8_accuracy: 0.9990 - val_n_9_accuracy: 0.9976\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00428\n",
      "Epoch 44/50\n",
      "750/750 [==============================] - 222s 296ms/step - loss: 4.2008e-04 - n_0_loss: 2.0200e-04 - n_1_loss: 1.0562e-04 - n_7_loss: 2.2031e-04 - n_4_loss: 4.8113e-04 - n_2_loss: 7.9894e-04 - n_3_loss: 2.0131e-04 - n_5_loss: 3.9632e-05 - n_6_loss: 6.2820e-04 - n_8_loss: 7.0769e-05 - n_9_loss: 0.0015 - n_0_accuracy: 0.9999 - n_1_accuracy: 0.9999 - n_7_accuracy: 1.0000 - n_4_accuracy: 0.9999 - n_2_accuracy: 0.9999 - n_3_accuracy: 1.0000 - n_5_accuracy: 1.0000 - n_6_accuracy: 0.9999 - n_8_accuracy: 1.0000 - n_9_accuracy: 0.9998 - val_loss: 0.0067 - val_n_0_loss: 0.0032 - val_n_1_loss: 0.0044 - val_n_7_loss: 0.0049 - val_n_4_loss: 0.0073 - val_n_2_loss: 0.0088 - val_n_3_loss: 0.0055 - val_n_5_loss: 0.0149 - val_n_6_loss: 0.0043 - val_n_8_loss: 0.0054 - val_n_9_loss: 0.0083 - val_n_0_accuracy: 0.9995 - val_n_1_accuracy: 0.9994 - val_n_7_accuracy: 0.9992 - val_n_4_accuracy: 0.9994 - val_n_2_accuracy: 0.9988 - val_n_3_accuracy: 0.9994 - val_n_5_accuracy: 0.9989 - val_n_6_accuracy: 0.9988 - val_n_8_accuracy: 0.9992 - val_n_9_accuracy: 0.9979\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00428\n",
      "Epoch 45/50\n",
      "750/750 [==============================] - 222s 296ms/step - loss: 3.1567e-04 - n_0_loss: 1.4958e-04 - n_1_loss: 8.3454e-05 - n_7_loss: 1.6936e-04 - n_4_loss: 3.7093e-04 - n_2_loss: 3.8821e-04 - n_3_loss: 8.2850e-04 - n_5_loss: 2.9055e-04 - n_6_loss: 1.3347e-04 - n_8_loss: 5.8879e-04 - n_9_loss: 1.5386e-04 - n_0_accuracy: 1.0000 - n_1_accuracy: 1.0000 - n_7_accuracy: 0.9999 - n_4_accuracy: 0.9999 - n_2_accuracy: 0.9999 - n_3_accuracy: 0.9997 - n_5_accuracy: 0.9999 - n_6_accuracy: 1.0000 - n_8_accuracy: 0.9999 - n_9_accuracy: 1.0000 - val_loss: 0.0068 - val_n_0_loss: 0.0041 - val_n_1_loss: 0.0050 - val_n_7_loss: 0.0061 - val_n_4_loss: 0.0080 - val_n_2_loss: 0.0067 - val_n_3_loss: 0.0058 - val_n_5_loss: 0.0120 - val_n_6_loss: 0.0078 - val_n_8_loss: 0.0052 - val_n_9_loss: 0.0070 - val_n_0_accuracy: 0.9995 - val_n_1_accuracy: 0.9991 - val_n_7_accuracy: 0.9988 - val_n_4_accuracy: 0.9987 - val_n_2_accuracy: 0.9991 - val_n_3_accuracy: 0.9983 - val_n_5_accuracy: 0.9987 - val_n_6_accuracy: 0.9985 - val_n_8_accuracy: 0.9987 - val_n_9_accuracy: 0.9985\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00428\n",
      "Epoch 46/50\n",
      "750/750 [==============================] - 226s 301ms/step - loss: 1.7158e-04 - n_0_loss: 4.1471e-04 - n_1_loss: 8.6997e-06 - n_7_loss: 1.1805e-04 - n_4_loss: 4.1352e-05 - n_2_loss: 3.3058e-05 - n_3_loss: 2.9975e-04 - n_5_loss: 6.0334e-04 - n_6_loss: 1.5550e-05 - n_8_loss: 1.5976e-04 - n_9_loss: 2.1488e-05 - n_0_accuracy: 0.9999 - n_1_accuracy: 1.0000 - n_7_accuracy: 1.0000 - n_4_accuracy: 1.0000 - n_2_accuracy: 1.0000 - n_3_accuracy: 0.9999 - n_5_accuracy: 0.9999 - n_6_accuracy: 1.0000 - n_8_accuracy: 1.0000 - n_9_accuracy: 1.0000 - val_loss: 0.0065 - val_n_0_loss: 0.0010 - val_n_1_loss: 0.0073 - val_n_7_loss: 0.0062 - val_n_4_loss: 0.0099 - val_n_2_loss: 0.0091 - val_n_3_loss: 0.0048 - val_n_5_loss: 0.0064 - val_n_6_loss: 0.0073 - val_n_8_loss: 0.0050 - val_n_9_loss: 0.0084 - val_n_0_accuracy: 0.9997 - val_n_1_accuracy: 0.9991 - val_n_7_accuracy: 0.9992 - val_n_4_accuracy: 0.9992 - val_n_2_accuracy: 0.9989 - val_n_3_accuracy: 0.9992 - val_n_5_accuracy: 0.9994 - val_n_6_accuracy: 0.9988 - val_n_8_accuracy: 0.9992 - val_n_9_accuracy: 0.9983\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00428\n",
      "Epoch 47/50\n",
      "750/750 [==============================] - 223s 297ms/step - loss: 2.5483e-04 - n_0_loss: 6.6671e-05 - n_1_loss: 9.8368e-05 - n_7_loss: 5.1468e-04 - n_4_loss: 1.5424e-04 - n_2_loss: 3.8265e-04 - n_3_loss: 1.2559e-05 - n_5_loss: 4.4610e-05 - n_6_loss: 3.6739e-04 - n_8_loss: 5.2321e-04 - n_9_loss: 3.8390e-04 - n_0_accuracy: 1.0000 - n_1_accuracy: 1.0000 - n_7_accuracy: 0.9998 - n_4_accuracy: 1.0000 - n_2_accuracy: 1.0000 - n_3_accuracy: 1.0000 - n_5_accuracy: 1.0000 - n_6_accuracy: 0.9999 - n_8_accuracy: 0.9998 - n_9_accuracy: 0.9999 - val_loss: 0.0061 - val_n_0_loss: 0.0024 - val_n_1_loss: 0.0036 - val_n_7_loss: 0.0047 - val_n_4_loss: 0.0098 - val_n_2_loss: 0.0101 - val_n_3_loss: 0.0066 - val_n_5_loss: 0.0056 - val_n_6_loss: 0.0053 - val_n_8_loss: 0.0039 - val_n_9_loss: 0.0095 - val_n_0_accuracy: 0.9996 - val_n_1_accuracy: 0.9994 - val_n_7_accuracy: 0.9992 - val_n_4_accuracy: 0.9990 - val_n_2_accuracy: 0.9987 - val_n_3_accuracy: 0.9987 - val_n_5_accuracy: 0.9992 - val_n_6_accuracy: 0.9987 - val_n_8_accuracy: 0.9992 - val_n_9_accuracy: 0.9983\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00428\n",
      "Epoch 48/50\n",
      "750/750 [==============================] - 225s 300ms/step - loss: 3.1003e-04 - n_0_loss: 5.3916e-06 - n_1_loss: 4.5967e-04 - n_7_loss: 5.6975e-04 - n_4_loss: 5.6545e-05 - n_2_loss: 4.7480e-04 - n_3_loss: 1.1702e-05 - n_5_loss: 1.6363e-05 - n_6_loss: 5.9586e-04 - n_8_loss: 1.4480e-04 - n_9_loss: 7.6538e-04 - n_0_accuracy: 1.0000 - n_1_accuracy: 0.9999 - n_7_accuracy: 0.9998 - n_4_accuracy: 1.0000 - n_2_accuracy: 0.9999 - n_3_accuracy: 1.0000 - n_5_accuracy: 1.0000 - n_6_accuracy: 0.9998 - n_8_accuracy: 1.0000 - n_9_accuracy: 0.9998 - val_loss: 0.0064 - val_n_0_loss: 0.0043 - val_n_1_loss: 0.0041 - val_n_7_loss: 0.0052 - val_n_4_loss: 0.0067 - val_n_2_loss: 0.0091 - val_n_3_loss: 0.0089 - val_n_5_loss: 0.0081 - val_n_6_loss: 0.0042 - val_n_8_loss: 0.0052 - val_n_9_loss: 0.0078 - val_n_0_accuracy: 0.9997 - val_n_1_accuracy: 0.9992 - val_n_7_accuracy: 0.9987 - val_n_4_accuracy: 0.9991 - val_n_2_accuracy: 0.9987 - val_n_3_accuracy: 0.9987 - val_n_5_accuracy: 0.9992 - val_n_6_accuracy: 0.9986 - val_n_8_accuracy: 0.9991 - val_n_9_accuracy: 0.9986\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00428\n",
      "Epoch 49/50\n",
      "750/750 [==============================] - 219s 292ms/step - loss: 1.2213e-04 - n_0_loss: 2.7709e-06 - n_1_loss: 2.1523e-04 - n_7_loss: 8.8544e-05 - n_4_loss: 2.0041e-04 - n_2_loss: 1.9767e-05 - n_3_loss: 2.6566e-05 - n_5_loss: 1.8348e-06 - n_6_loss: 3.4484e-04 - n_8_loss: 5.5614e-06 - n_9_loss: 3.1583e-04 - n_0_accuracy: 1.0000 - n_1_accuracy: 0.9999 - n_7_accuracy: 1.0000 - n_4_accuracy: 1.0000 - n_2_accuracy: 1.0000 - n_3_accuracy: 1.0000 - n_5_accuracy: 1.0000 - n_6_accuracy: 0.9999 - n_8_accuracy: 1.0000 - n_9_accuracy: 0.9999 - val_loss: 0.0059 - val_n_0_loss: 0.0032 - val_n_1_loss: 0.0029 - val_n_7_loss: 0.0024 - val_n_4_loss: 0.0057 - val_n_2_loss: 0.0111 - val_n_3_loss: 0.0082 - val_n_5_loss: 0.0092 - val_n_6_loss: 0.0040 - val_n_8_loss: 0.0051 - val_n_9_loss: 0.0074 - val_n_0_accuracy: 0.9996 - val_n_1_accuracy: 0.9993 - val_n_7_accuracy: 0.9994 - val_n_4_accuracy: 0.9992 - val_n_2_accuracy: 0.9987 - val_n_3_accuracy: 0.9991 - val_n_5_accuracy: 0.9994 - val_n_6_accuracy: 0.9987 - val_n_8_accuracy: 0.9994 - val_n_9_accuracy: 0.9987\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00428\n",
      "Epoch 50/50\n",
      "750/750 [==============================] - 218s 291ms/step - loss: 2.5254e-04 - n_0_loss: 9.9559e-05 - n_1_loss: 6.2801e-05 - n_7_loss: 2.0598e-04 - n_4_loss: 5.3006e-05 - n_2_loss: 7.0295e-04 - n_3_loss: 1.3253e-04 - n_5_loss: 3.1828e-06 - n_6_loss: 1.0102e-04 - n_8_loss: 2.3925e-04 - n_9_loss: 9.2513e-04 - n_0_accuracy: 1.0000 - n_1_accuracy: 1.0000 - n_7_accuracy: 0.9999 - n_4_accuracy: 1.0000 - n_2_accuracy: 0.9999 - n_3_accuracy: 1.0000 - n_5_accuracy: 1.0000 - n_6_accuracy: 0.9999 - n_8_accuracy: 0.9999 - n_9_accuracy: 0.9998 - val_loss: 0.0059 - val_n_0_loss: 0.0058 - val_n_1_loss: 0.0035 - val_n_7_loss: 0.0027 - val_n_4_loss: 0.0068 - val_n_2_loss: 0.0070 - val_n_3_loss: 0.0078 - val_n_5_loss: 0.0082 - val_n_6_loss: 0.0040 - val_n_8_loss: 0.0050 - val_n_9_loss: 0.0079 - val_n_0_accuracy: 0.9992 - val_n_1_accuracy: 0.9993 - val_n_7_accuracy: 0.9994 - val_n_4_accuracy: 0.9994 - val_n_2_accuracy: 0.9989 - val_n_3_accuracy: 0.9993 - val_n_5_accuracy: 0.9994 - val_n_6_accuracy: 0.9990 - val_n_8_accuracy: 0.9992 - val_n_9_accuracy: 0.9983\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00428\n"
     ]
    }
   ],
   "source": [
    "runner.train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- draw training history -------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1800 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "runner.draw_training_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- load best model -------------------\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n"
     ]
    }
   ],
   "source": [
    "runner.load_best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- save model -------------------\n",
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained_model/assets\n",
      "..Model saved\n",
      "...Model path: trained_model\n",
      "Saving model to neptune\n",
      " ..Uploading file trained_model.zip\n",
      "Model saved into Neptune\n",
      "Saving process finished\n"
     ]
    }
   ],
   "source": [
    "runner.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "188/188 [==============================] - 10s 51ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00080 | EER_interp: 0.00080 | ACC: 0.99920\n",
      "  Task  1: n_1             | EER_mean: 0.00150 | EER_interp: 0.00110 | ACC: 0.99920\n",
      "  Task  2: n_2             | EER_mean: 0.00130 | EER_interp: 0.00150 | ACC: 0.99870\n",
      "  Task  3: n_3             | EER_mean: 0.00080 | EER_interp: 0.00070 | ACC: 0.99940\n",
      "  Task  4: n_4             | EER_mean: 0.00170 | EER_interp: 0.00150 | ACC: 0.99870\n",
      "  Task  5: n_5             | EER_mean: 0.00090 | EER_interp: 0.00080 | ACC: 0.99920\n",
      "  Task  6: n_6             | EER_mean: 0.00330 | EER_interp: 0.00240 | ACC: 0.99840\n",
      "  Task  7: n_7             | EER_mean: 0.00120 | EER_interp: 0.00140 | ACC: 0.99880\n",
      "  Task  8: n_8             | EER_mean: 0.00340 | EER_interp: 0.00240 | ACC: 0.99840\n",
      "  Task  9: n_9             | EER_mean: 0.00250 | EER_interp: 0.00230 | ACC: 0.99780\n",
      "final_EER_mean: 0.15% | final_EER_median: 0.14% | final_EER_std_dv: 0.06% | final_ACC: 99.88%\n"
     ]
    }
   ],
   "source": [
    "runner.set_model_evaluator_data_src(DataSource.VALIDATION)\n",
    "runner.test_model(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "157/157 [==============================] - 9s 56ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00010 | EER_interp: 0.00000 | ACC: 0.99990\n",
      "  Task  1: n_1             | EER_mean: 0.00090 | EER_interp: 0.00080 | ACC: 0.99930\n",
      "  Task  2: n_2             | EER_mean: 0.00190 | EER_interp: 0.00190 | ACC: 0.99810\n",
      "  Task  3: n_3             | EER_mean: 0.00040 | EER_interp: 0.00000 | ACC: 0.99960\n",
      "  Task  4: n_4             | EER_mean: 0.00100 | EER_interp: 0.00100 | ACC: 0.99900\n",
      "  Task  5: n_5             | EER_mean: 0.00110 | EER_interp: 0.00110 | ACC: 0.99900\n",
      "  Task  6: n_6             | EER_mean: 0.00310 | EER_interp: 0.00310 | ACC: 0.99690\n",
      "  Task  7: n_7             | EER_mean: 0.00290 | EER_interp: 0.00280 | ACC: 0.99730\n",
      "  Task  8: n_8             | EER_mean: 0.00100 | EER_interp: 0.00100 | ACC: 0.99900\n",
      "  Task  9: n_9             | EER_mean: 0.00320 | EER_interp: 0.00310 | ACC: 0.99680\n",
      "final_EER_mean: 0.15% | final_EER_median: 0.11% | final_EER_std_dv: 0.11% | final_ACC: 99.85%\n"
     ]
    }
   ],
   "source": [
    "runner.set_model_evaluator_data_src(DataSource.TEST)\n",
    "runner.test_model(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Model Classification"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "runner.visualize_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finishing Experiment Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- finish experiment -------------------\n",
      "Finishing Neptune\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "Waiting for the remaining 14 operations to synchronize with Neptune. Do not kill this process.\n",
      "All 14 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/guilhermemg/icao-nets-training-2/e/ICAO-492/metadata\n"
     ]
    }
   ],
   "source": [
    "runner.finish_experiment()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "85f5044ba23e75135dc4c908fd4d7609c1c80b195047fdb4d16ee0e66a953254"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "neptune": {
   "notebookId": "98a3967a-428e-4576-add1-6bd753600673",
   "projectVersion": 2
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
