{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['NEPTUNE_API_TOKEN']=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI5NDc0ZmNhNi0wODFlLTRhYTktYjgwZS01MWJkMDMxNWJhNTAifQ==\"\n",
    "os.environ['NEPTUNE_PROJECT']=\"guilhermemg/icao-nets-training-2\"\n",
    "os.environ['NEPTUNE_NOTEBOOK_ID']=\"98a391a1-c710-40bd-aaf4-42c31862cbbe\"\n",
    "os.environ['NEPTUNE_NOTEBOOK_PATH']=\"training/exec_nas_experiment.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# disable tensorflow log level infos\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # show only errors\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> Restrict GPU memory growth: True\n"
     ]
    }
   ],
   "source": [
    "from src.m_utils import constants as cts\n",
    "from src.base.data_loaders.data_loader import DLName\n",
    "from src.base.gt_loaders.gt_names import GTName\n",
    "from src.exp_runner import ExperimentRunner\n",
    "\n",
    "from src.base.experiment.dataset.dataset import Dataset\n",
    "from src.base.experiment.evaluation.model_evaluator import DataSource, DataPredSelection\n",
    "from src.base.experiment.training.base_models import BaseModel\n",
    "from src.base.experiment.training.optimizers import Optimizer\n",
    "\n",
    "from src.m_utils.stl_approach import STLApproach\n",
    "from src.m_utils.mtl_approach import MTLApproach\n",
    "from src.m_utils.nas_mtl_approach import NAS_MTLApproach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Network runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Init ExperimentRunner -------------------\n",
      "---------------------------\n",
      "Parent Process ID: 169832\n",
      "Process ID: 190110\n",
      "---------------------------\n",
      "-----\n",
      "Use Neptune:  False\n",
      "-----\n",
      "-------------------\n",
      "Args: \n",
      "{'controller_params': {'controller_decay': 0.1,\n",
      "                       'controller_learning_rate': 0.01,\n",
      "                       'controller_loss_alpha': 0.9,\n",
      "                       'controller_lstm_dim': 100,\n",
      "                       'controller_momentum': 0.0,\n",
      "                       'controller_optimizer': <Optimizer.ADAM: 'Adam'>,\n",
      "                       'controller_sampling_epochs': 6,\n",
      "                       'controller_training_epochs': 5,\n",
      "                       'controller_use_predictor': False},\n",
      " 'exp_params': {'description': 'NAS with Approach 3',\n",
      "                'name': 'NAS experiment',\n",
      "                'src_files': ['../src/**/*.py'],\n",
      "                'tags': ['mnist', 'nas', 'nas_approach_3']},\n",
      " 'mlp_params': {'max_architecture_length': 5,\n",
      "                'min_task_group_size': 3,\n",
      "                'mlp_base_model': <BaseModel.MOBILENET_V2: {'name': 'mobilnet_v2', 'target_size': (224, 224), 'prep_function': <function preprocess_input at 0x7f988a0aff70>}>,\n",
      "                'mlp_batch_size': 64,\n",
      "                'mlp_decay': 0.0,\n",
      "                'mlp_dropout': 0.3,\n",
      "                'mlp_early_stopping': 50,\n",
      "                'mlp_learning_rate': 0.001,\n",
      "                'mlp_loss_function': 'sparse_categorical_crossentropy',\n",
      "                'mlp_momentum': 0.0,\n",
      "                'mlp_n_epochs': 50,\n",
      "                'mlp_one_shot': True,\n",
      "                'mlp_optimizer': <Optimizer.ADAMAX: 'Adamax'>},\n",
      " 'nas_params': {'architecture_training_epochs': 2,\n",
      "                'nas_algorithm': 'rl',\n",
      "                'nas_search_space': 'ss_1',\n",
      "                'samples_per_controller_epoch': 2,\n",
      "                'total_num_proposed_architectures': 10},\n",
      " 'properties': {'approach': <NAS_MTLApproach.APPROACH_3: 'approach_3'>,\n",
      "                'balance_input_data': False,\n",
      "                'dataset': <Dataset.MNIST: {'name': 'mnist', 'target_cols': ['n_0', 'n_1', 'n_2', 'n_3', 'n_4', 'n_5', 'n_6', 'n_7', 'n_8', 'n_9'], 'tasks': [<MNIST_TASK.N_0: 'n_0'>, <MNIST_TASK.N_1: 'n_1'>, <MNIST_TASK.N_2: 'n_2'>, <MNIST_TASK.N_3: 'n_3'>, <MNIST_TASK.N_4: 'n_4'>, <MNIST_TASK.N_5: 'n_5'>, <MNIST_TASK.N_6: 'n_6'>, <MNIST_TASK.N_7: 'n_7'>, <MNIST_TASK.N_8: 'n_8'>, <MNIST_TASK.N_9: 'n_9'>]}>,\n",
      "                'exec_nas': True,\n",
      "                'orig_model_experiment_id': '',\n",
      "                'sample_prop': 0.03,\n",
      "                'sample_training_data': True,\n",
      "                'save_trained_model': True,\n",
      "                'tasks': [<MNIST_TASK.N_0: 'n_0'>,\n",
      "                          <MNIST_TASK.N_1: 'n_1'>,\n",
      "                          <MNIST_TASK.N_2: 'n_2'>,\n",
      "                          <MNIST_TASK.N_3: 'n_3'>,\n",
      "                          <MNIST_TASK.N_4: 'n_4'>,\n",
      "                          <MNIST_TASK.N_5: 'n_5'>,\n",
      "                          <MNIST_TASK.N_6: 'n_6'>,\n",
      "                          <MNIST_TASK.N_7: 'n_7'>,\n",
      "                          <MNIST_TASK.N_8: 'n_8'>,\n",
      "                          <MNIST_TASK.N_9: 'n_9'>],\n",
      "                'train_model': True},\n",
      " 'use_neptune': False}\n",
      "-------------------\n",
      "----\n",
      "Base Model Name:  BaseModel.MOBILENET_V2\n",
      "----\n",
      "MTL Model: True\n",
      "Approach: NAS_MTLApproach.APPROACH_3\n",
      "NAS MTL Model: True\n",
      "----\n",
      "--------------------  starting neptune  -------------------\n",
      "Not using Neptune to record Experiment Metadata\n",
      "Model path:  trained_model\n",
      "----\n",
      "Checking model existence locally...\n",
      "Training a new model! Not checking model existence\n",
      "----\n",
      "------------------------------\n",
      "Checking GPU availability\n",
      " ..GPU is available!\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "DATASET = Dataset.MNIST\n",
    "APPROACH = NAS_MTLApproach.APPROACH_3\n",
    "\n",
    "kwargs = { \n",
    "    'use_neptune': False,\n",
    "    'exp_params' : {\n",
    "        'name': 'NAS experiment',\n",
    "        'description': 'NAS with Approach 3',\n",
    "        'tags': [f'{DATASET.value[\"name\"]}', 'nas', 'nas_approach_3'],\n",
    "        'src_files': [\"../src/**/*.py\"]\n",
    "    },\n",
    "    'properties': {\n",
    "        'approach': APPROACH,\n",
    "        'dataset': DATASET,\n",
    "        'tasks': DATASET.value['tasks'],\n",
    "        'balance_input_data': False,\n",
    "        'train_model': True,\n",
    "        'save_trained_model': True,\n",
    "        'exec_nas': True,\n",
    "        'orig_model_experiment_id': '',\n",
    "        'sample_training_data': True,\n",
    "        'sample_prop': 0.03\n",
    "    },\n",
    "    'nas_params': {\n",
    "        'samples_per_controller_epoch': 2,    # nas batch size (#architectures proposed per controller epoch)\n",
    "        'architecture_training_epochs': 2,     # n_epochs for training proposed architecture\n",
    "        'total_num_proposed_architectures': 10,\n",
    "        'nas_algorithm': 'rl',\n",
    "        'nas_search_space': 'ss_1'\n",
    "    },\n",
    "    'controller_params': {\n",
    "        'controller_lstm_dim': 100,\n",
    "        'controller_optimizer': Optimizer.ADAM,\n",
    "        'controller_learning_rate': 0.01,\n",
    "        'controller_decay': 0.1,\n",
    "        'controller_momentum': 0.0,\n",
    "        'controller_use_predictor': False,\n",
    "        'controller_loss_alpha': 0.9,\n",
    "        'controller_training_epochs': 5,\n",
    "        'controller_sampling_epochs': 6\n",
    "    },\n",
    "    'mlp_params': {\n",
    "        'max_architecture_length': 5,\n",
    "        'min_task_group_size': 3,\n",
    "        'mlp_base_model': BaseModel.MOBILENET_V2,\n",
    "        'mlp_n_epochs': 50,\n",
    "        'mlp_batch_size': 64,\n",
    "        'mlp_early_stopping': 50,\n",
    "        'mlp_optimizer': Optimizer.ADAMAX,\n",
    "        'mlp_learning_rate': 1e-3,\n",
    "        'mlp_decay': 0.0,\n",
    "        'mlp_momentum': 0.0,\n",
    "        'mlp_dropout': 0.3,\n",
    "        'mlp_loss_function': 'sparse_categorical_crossentropy',\n",
    "        'mlp_one_shot': True\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "runner = ExperimentRunner(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- load training data -------------------\n",
      "Loading data\n",
      "TrainData.shape: (48000, 11)\n",
      "ValidationData.shape: (12000, 11)\n",
      "TestData.shape: (10000, 11)\n",
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "runner.load_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- sample training data -------------------\n",
      "Applying subsampling in training data\n",
      "..Sampling proportion: 0.03 (1440/48000)\n",
      "(1440, 11)\n",
      "Applying subsampling in validation data\n",
      "..Sampling proportion: 0.03 (360/12000)\n",
      "(360, 11)\n"
     ]
    }
   ],
   "source": [
    "runner.sample_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>n_0</th>\n",
       "      <th>n_1</th>\n",
       "      <th>n_2</th>\n",
       "      <th>n_3</th>\n",
       "      <th>n_4</th>\n",
       "      <th>n_5</th>\n",
       "      <th>n_6</th>\n",
       "      <th>n_7</th>\n",
       "      <th>n_8</th>\n",
       "      <th>n_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32771</th>\n",
       "      <td>/home/guilherme/data1/Dropbox/Link to Desktop/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39512</th>\n",
       "      <td>/home/guilherme/data1/Dropbox/Link to Desktop/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43581</th>\n",
       "      <td>/home/guilherme/data1/Dropbox/Link to Desktop/...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>/home/guilherme/data1/Dropbox/Link to Desktop/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3377</th>\n",
       "      <td>/home/guilherme/data1/Dropbox/Link to Desktop/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                img_name  n_0  n_1  n_2  n_3  \\\n",
       "32771  /home/guilherme/data1/Dropbox/Link to Desktop/...  0.0  0.0  0.0  0.0   \n",
       "39512  /home/guilherme/data1/Dropbox/Link to Desktop/...  0.0  0.0  0.0  0.0   \n",
       "43581  /home/guilherme/data1/Dropbox/Link to Desktop/...  1.0  0.0  0.0  0.0   \n",
       "2975   /home/guilherme/data1/Dropbox/Link to Desktop/...  0.0  0.0  0.0  0.0   \n",
       "3377   /home/guilherme/data1/Dropbox/Link to Desktop/...  0.0  0.0  0.0  1.0   \n",
       "\n",
       "       n_4  n_5  n_6  n_7  n_8  n_9  \n",
       "32771  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "39512  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "43581  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2975   0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "3377   0.0  0.0  0.0  0.0  0.0  0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.train_data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# <font color='red'>Producing Fake Data</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "runner.produce_fake_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- setup data generators -------------------\n",
      "Starting data generators\n",
      "Found 1440 validated image filenames.\n",
      "Found 360 validated image filenames.\n",
      "Found 10000 validated image filenames.\n",
      "TOTAL: 11800\n",
      "\n",
      "Logging class indices\n",
      " .. MTL model not logging class indices!\n",
      "\n",
      "Using benchmarking dataset. Not logging class labels!\n"
     ]
    }
   ],
   "source": [
    "runner.setup_data_generators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- create experiment -------------------\n",
      "Not using Neptune\n"
     ]
    }
   ],
   "source": [
    "runner.setup_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Labels Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "runner.summary_labels_dist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Architecture Search - v3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, RNN, LSTMCell, Input\n",
    "\n",
    "\n",
    "all_archs = [(i,j,p,q) for i in range(1,6) for j in range(1,6) for p in range(1,6) for q in range(1,6)]\n",
    "\n",
    "print(f'all_archs[:10]: {all_archs[:10]}')\n",
    "\n",
    "search_space_size = len(all_archs)\n",
    "print(f'search_space_size: {search_space_size}')\n",
    "\n",
    "\n",
    "def __create_control_model(controller_input_shape):\n",
    "        main_input = Input(shape=controller_input_shape, name='main_input')        \n",
    "        print(f'Controller model input shape: {main_input.shape}')\n",
    "        x = RNN(LSTMCell(100), return_sequences=True)(main_input)\n",
    "        main_output = Dense(search_space_size, activation='softmax', name='main_output')(x)\n",
    "        print(f'Controller model output shape: {main_output.shape}')\n",
    "        model = Model(inputs=[main_input], outputs=[main_output])\n",
    "        return model\n",
    "    \n",
    "model = __create_control_model((1,4))    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "history = []\n",
    "for i in range(5):\n",
    "    print(10*'-')\n",
    "    if i == 0:\n",
    "        inp = np.zeros((1,1,4))\n",
    "    else:\n",
    "        inp = np.array(history[-1]).reshape(1,1,4)\n",
    "    \n",
    "    print(f'input: {inp}')\n",
    "    \n",
    "    prob_list = model.predict(inp)\n",
    "    \n",
    "    prob_list = prob_list[0][0]\n",
    "    print(f'prob_list[:5]: {prob_list[:5]}')\n",
    "    \n",
    "    chose_idx = np.random.choice(range(search_space_size), size=1, replace=False, p=prob_list)[0]\n",
    "    print(f'chose_idx: {chose_idx}')\n",
    "    \n",
    "    new_arch = all_archs[chose_idx]\n",
    "    print(f'new_arch: {new_arch}')\n",
    "    \n",
    "    history.append(new_arch)\n",
    "    print(f'history: {history}')\n",
    "    \n",
    "    print(10*'-')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- run neural architecture search -------------------\n",
      "all_archs[:10]: [[0, 0, 0, 0], [0, 0, 0, 1], [0, 0, 0, 2], [0, 0, 0, 3], [0, 0, 0, 4], [0, 0, 1, 0], [0, 0, 1, 1], [0, 0, 1, 2], [0, 0, 1, 3], [0, 0, 1, 4]]\n",
      "search_space_size: 625\n",
      "Controller model input shape: (None, 1, 4)\n",
      "Controller model output shape: (None, 1, 625)\n",
      "Model path:  trained_model\n",
      "----\n",
      "Checking model existence locally...\n",
      "Training a new model! Not checking model existence\n",
      "----\n",
      "------------------------------\n",
      "Checking GPU availability\n",
      " ..GPU is available!\n",
      "------------------------------\n",
      " ..prev_arch: [[[0 0 0 0]]]\n",
      " ..prev_arch.shape: (1, 1, 4)\n",
      "input: [[[0 0 0 0]]]\n",
      "prob_list[:5]: [0.0016 0.0016 0.0016 0.0016 0.0016]\n",
      "chose_idx: 579\n",
      "new_arch: [4, 3, 0, 4]\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 1 | Feedback DNA: DNA([4, 3, 0, 4])\n",
      "----------------------------------------------------------------------\n",
      " -- Architecture 1: {'n_denses_0': 5, 'n_denses_1': 4, 'n_denses_2': 1, 'n_denses_3': 5}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 3,199,764\n",
      "  .. Trainable params: 941,780\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.71365, saving model to training/training_ckpt/best_model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_loss did not improve from 0.71365\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "6/6 [==============================] - 1s 110ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.11350 | EER_interp: 0.11560 | ACC: 0.88610\n",
      "  Task  1: n_1             | EER_mean: 0.02080 | EER_interp: 0.02000 | ACC: 0.98060\n",
      "  Task  2: n_2             | EER_mean: 0.23080 | EER_interp: 0.23060 | ACC: 0.76940\n",
      "  Task  3: n_3             | EER_mean: 0.23080 | EER_interp: 0.22920 | ACC: 0.77220\n",
      "  Task  4: n_4             | EER_mean: 0.11630 | EER_interp: 0.10700 | ACC: 0.90000\n",
      "  Task  5: n_5             | EER_mean: 0.34480 | EER_interp: 0.34160 | ACC: 0.66110\n",
      "  Task  6: n_6             | EER_mean: 0.20630 | EER_interp: 0.20310 | ACC: 0.79440\n",
      "  Task  7: n_7             | EER_mean: 0.32120 | EER_interp: 0.32720 | ACC: 0.67780\n",
      "  Task  8: n_8             | EER_mean: 0.16220 | EER_interp: 0.16010 | ACC: 0.84170\n",
      "  Task  9: n_9             | EER_mean: 0.39260 | EER_interp: 0.40220 | ACC: 0.60560\n",
      "final_EER_mean: 21.37% | final_EER_median: 21.62% | final_EER_std_dv: 11.26% | final_ACC: 78.89%\n",
      "validation accuracy:  78.89\n",
      "======================================================================\n",
      " ..nas_history_data: [[DNA([4, 3, 0, 4]), 78.89]]\n",
      " ..len(self.nas_history_data): 1\n",
      "logging nas_history_data...\n",
      " ..self.nas_history_data: [[DNA([4, 3, 0, 4]), 78.89]]\n",
      " ..nas_data_log_path: LOGS/nas_data.pkl\n",
      " ..prev_arch: [[[4 3 0 4]]]\n",
      " ..prev_arch.shape: (1, 1, 4)\n",
      "input: [[[4 3 0 4]]]\n",
      "prob_list[:5]: [0.0015992  0.00145935 0.00179259 0.00156647 0.00138859]\n",
      "chose_idx: 61\n",
      "new_arch: [0, 2, 2, 1]\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 2 | Feedback DNA: DNA([0, 2, 2, 1])\n",
      "----------------------------------------------------------------------\n",
      " -- Architecture 2: {'n_denses_0': 1, 'n_denses_1': 3, 'n_denses_2': 3, 'n_denses_3': 2}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 3,137,364\n",
      "  .. Trainable params: 879,380\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.90099, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.90099\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "6/6 [==============================] - 1s 47ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.03680 | EER_interp: 0.03310 | ACC: 0.96390\n",
      "  Task  1: n_1             | EER_mean: 0.07690 | EER_interp: 0.08010 | ACC: 0.92220\n",
      "  Task  2: n_2             | EER_mean: 0.25230 | EER_interp: 0.25440 | ACC: 0.74720\n",
      "  Task  3: n_3             | EER_mean: 0.23080 | EER_interp: 0.23060 | ACC: 0.76940\n",
      "  Task  4: n_4             | EER_mean: 0.17350 | EER_interp: 0.16820 | ACC: 0.82780\n",
      "  Task  5: n_5             | EER_mean: 0.17240 | EER_interp: 0.17080 | ACC: 0.83060\n",
      "  Task  6: n_6             | EER_mean: 0.13130 | EER_interp: 0.12810 | ACC: 0.86940\n",
      "  Task  7: n_7             | EER_mean: 0.09090 | EER_interp: 0.09550 | ACC: 0.90830\n",
      "  Task  8: n_8             | EER_mean: 0.03100 | EER_interp: 0.02900 | ACC: 0.96940\n",
      "  Task  9: n_9             | EER_mean: 0.42020 | EER_interp: 0.43070 | ACC: 0.57780\n",
      "final_EER_mean: 16.2% | final_EER_median: 14.82% | final_EER_std_dv: 11.5% | final_ACC: 83.86%\n",
      "validation accuracy:  83.86\n",
      "======================================================================\n",
      " ..nas_history_data: [[DNA([4, 3, 0, 4]), 78.89], [DNA([0, 2, 2, 1]), 83.86]]\n",
      " ..len(self.nas_history_data): 2\n",
      "logging nas_history_data...\n",
      " ..self.nas_history_data: [[DNA([4, 3, 0, 4]), 78.89], [DNA([0, 2, 2, 1]), 83.86]]\n",
      " ..nas_data_log_path: LOGS/nas_data.pkl\n",
      "......................................................................\n",
      " ..New batch of architectures. Training controller model...\n",
      "Training controller model...\n",
      "Preparing controller data...\n",
      " ..nas_data_history: [[DNA([4, 3, 0, 4]), 78.89], [DNA([0, 2, 2, 1]), 83.86]]\n",
      " ..xc: [[[4 3 0 4]]\n",
      "\n",
      " [[0 2 2 1]]]\n",
      " ..xc.shape: (2, 1, 4)\n",
      " ..yc: [[[0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]]]\n",
      " ..yc.shape: (2, 1, 4)\n",
      " ..val_acc_target: [78.89, 83.86]\n",
      " ..val_acc_target.length: 2\n",
      "TRAINING CONTROLLER...\n",
      " ..Controller model trained!\n",
      "......................................................................\n",
      " ..prev_arch: [[[0 2 2 1]]]\n",
      " ..prev_arch.shape: (1, 1, 4)\n",
      "input: [[[0 2 2 1]]]\n",
      "prob_list[:5]: [0.00172518 0.00180781 0.00146669 0.00166232 0.00160653]\n",
      "chose_idx: 590\n",
      "new_arch: [4, 3, 3, 0]\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 3 | Feedback DNA: DNA([4, 3, 3, 0])\n",
      "----------------------------------------------------------------------\n",
      " -- Architecture 3: {'n_denses_0': 5, 'n_denses_1': 4, 'n_denses_2': 4, 'n_denses_3': 1}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 3,158,164\n",
      "  .. Trainable params: 900,180\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.91472, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.91472 to 0.88241, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "6/6 [==============================] - 1s 51ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.01230 | EER_interp: 0.00000 | ACC: 0.98890\n",
      "  Task  1: n_1             | EER_mean: 0.00320 | EER_interp: 0.00000 | ACC: 0.99720\n",
      "  Task  2: n_2             | EER_mean: 0.15580 | EER_interp: 0.15480 | ACC: 0.84440\n",
      "  Task  3: n_3             | EER_mean: 0.16170 | EER_interp: 0.15780 | ACC: 0.83890\n",
      "  Task  4: n_4             | EER_mean: 0.11990 | EER_interp: 0.11810 | ACC: 0.88060\n",
      "  Task  5: n_5             | EER_mean: 0.17520 | EER_interp: 0.17380 | ACC: 0.82500\n",
      "  Task  6: n_6             | EER_mean: 0.13750 | EER_interp: 0.14380 | ACC: 0.86110\n",
      "  Task  7: n_7             | EER_mean: 0.10000 | EER_interp: 0.09700 | ACC: 0.90560\n",
      "  Task  8: n_8             | EER_mean: 0.02700 | EER_interp: 0.02440 | ACC: 0.97780\n",
      "  Task  9: n_9             | EER_mean: 0.09510 | EER_interp: 0.09170 | ACC: 0.90560\n",
      "final_EER_mean: 9.61% | final_EER_median: 10.76% | final_EER_std_dv: 6.3% | final_ACC: 90.25%\n",
      "validation accuracy:  90.25\n",
      "======================================================================\n",
      " ..nas_history_data: [[DNA([4, 3, 0, 4]), 78.89], [DNA([0, 2, 2, 1]), 83.86], [DNA([4, 3, 3, 0]), 90.25]]\n",
      " ..len(self.nas_history_data): 3\n",
      "logging nas_history_data...\n",
      " ..self.nas_history_data: [[DNA([4, 3, 0, 4]), 78.89], [DNA([0, 2, 2, 1]), 83.86], [DNA([4, 3, 3, 0]), 90.25]]\n",
      " ..nas_data_log_path: LOGS/nas_data.pkl\n",
      " ..prev_arch: [[[4 3 3 0]]]\n",
      " ..prev_arch.shape: (1, 1, 4)\n",
      "input: [[[4 3 3 0]]]\n",
      "prob_list[:5]: [0.00164085 0.00181918 0.00142272 0.00159996 0.00166591]\n",
      "chose_idx: 585\n",
      "new_arch: [4, 3, 2, 0]\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 4 | Feedback DNA: DNA([4, 3, 2, 0])\n",
      "----------------------------------------------------------------------\n",
      " -- Architecture 4: {'n_denses_0': 5, 'n_denses_1': 4, 'n_denses_2': 3, 'n_denses_3': 1}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 3,149,844\n",
      "  .. Trainable params: 891,860\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.01080, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.01080\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "6/6 [==============================] - 1s 50ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.20590 | EER_interp: 0.20570 | ACC: 0.79440\n",
      "  Task  1: n_1             | EER_mean: 0.04170 | EER_interp: 0.04010 | ACC: 0.96110\n",
      "  Task  2: n_2             | EER_mean: 0.25640 | EER_interp: 0.25600 | ACC: 0.74440\n",
      "  Task  3: n_3             | EER_mean: 0.20060 | EER_interp: 0.19650 | ACC: 0.80000\n",
      "  Task  4: n_4             | EER_mean: 0.39750 | EER_interp: 0.38480 | ACC: 0.60560\n",
      "  Task  5: n_5             | EER_mean: 0.24140 | EER_interp: 0.24160 | ACC: 0.75830\n",
      "  Task  6: n_6             | EER_mean: 0.25310 | EER_interp: 0.26400 | ACC: 0.74440\n",
      "  Task  7: n_7             | EER_mean: 0.40000 | EER_interp: 0.40000 | ACC: 0.60000\n",
      "  Task  8: n_8             | EER_mean: 0.32430 | EER_interp: 0.32160 | ACC: 0.68060\n",
      "  Task  9: n_9             | EER_mean: 0.41180 | EER_interp: 0.41140 | ACC: 0.58890\n",
      "final_EER_mean: 27.22% | final_EER_median: 26.0% | final_EER_std_dv: 10.78% | final_ACC: 72.78%\n",
      "validation accuracy:  72.78\n",
      "======================================================================\n",
      " ..nas_history_data: [[DNA([4, 3, 0, 4]), 78.89], [DNA([0, 2, 2, 1]), 83.86], [DNA([4, 3, 3, 0]), 90.25], [DNA([4, 3, 2, 0]), 72.78]]\n",
      " ..len(self.nas_history_data): 4\n",
      "logging nas_history_data...\n",
      " ..self.nas_history_data: [[DNA([4, 3, 0, 4]), 78.89], [DNA([0, 2, 2, 1]), 83.86], [DNA([4, 3, 3, 0]), 90.25], [DNA([4, 3, 2, 0]), 72.78]]\n",
      " ..nas_data_log_path: LOGS/nas_data.pkl\n",
      "......................................................................\n",
      " ..New batch of architectures. Training controller model...\n",
      "Training controller model...\n",
      "Preparing controller data...\n",
      " ..nas_data_history: [[DNA([4, 3, 3, 0]), 90.25], [DNA([4, 3, 2, 0]), 72.78]]\n",
      " ..xc: [[[4 3 3 0]]\n",
      "\n",
      " [[4 3 2 0]]]\n",
      " ..xc.shape: (2, 1, 4)\n",
      " ..yc: [[[0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]]]\n",
      " ..yc.shape: (2, 1, 4)\n",
      " ..val_acc_target: [90.25, 72.78]\n",
      " ..val_acc_target.length: 2\n",
      "TRAINING CONTROLLER...\n",
      " ..Controller model trained!\n",
      "......................................................................\n",
      " ..prev_arch: [[[4 3 2 0]]]\n",
      " ..prev_arch.shape: (1, 1, 4)\n",
      "input: [[[4 3 2 0]]]\n",
      "prob_list[:5]: [0.00167829 0.00191043 0.00134753 0.00161911 0.00167597]\n",
      "chose_idx: 161\n",
      "new_arch: [1, 1, 2, 1]\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 5 | Feedback DNA: DNA([1, 1, 2, 1])\n",
      "----------------------------------------------------------------------\n",
      " -- Architecture 5: {'n_denses_0': 2, 'n_denses_1': 2, 'n_denses_2': 3, 'n_denses_3': 2}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 3,129,044\n",
      "  .. Trainable params: 871,060\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.05121, saving model to training/training_ckpt/best_model.hdf5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_190110/4157497771.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_archs_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_neural_architecture_search_v3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/doutorado/mteval-icao-reqs/submodules/icao_nets_training/project/src/exp_runner.py\u001b[0m in \u001b[0;36mrun_neural_architecture_search_v3\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnas_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNew_MLPNAS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_interp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneptune_utils\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnas_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnas_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n------------------ TOP ARCHITECTURES FOUND --------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/doutorado/mteval-icao-reqs/submodules/icao_nets_training/project/src/nas/v3/new_mlpnas.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_architecture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_architecture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mfinal_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_architecture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/doutorado/mteval-icao-reqs/submodules/icao_nets_training/project/src/nas/v3/new_mlpnas.py\u001b[0m in \u001b[0;36mtrain_architecture\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_architecture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marchitecture_train_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_nas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfine_tuned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/doutorado/mteval-icao-reqs/submodules/icao_nets_training/project/src/base/experiment/training/model_trainer.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, train_gen, validation_gen, fine_tuned, n_epochs, running_nas)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;31m#vrb = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             self.H = self.model.fit(\n\u001b[0m\u001b[1;32m    191\u001b[0m                     \u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_interp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mlp_batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_archs_list = runner.run_neural_architecture_search_v3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create Model with Best Architecture Found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_arch = {'n_denses_0':2,'n_denses_1':2,'n_denses_2':2,'n_denses_3':2}\n",
    "best_arch = best_archs_list[0]['Architecture'] if best_archs_list is not None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.create_model(best_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "runner.visualize_model(outfile_path=f\"training/figs/nas/nas_model_{APPROACH.name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "runner.model_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.draw_training_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.load_best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.set_model_evaluator_data_src(DataSource.VALIDATION)\n",
    "runner.test_model(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.set_model_evaluator_data_src(DataSource.TEST)\n",
    "runner.test_model(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Model Classification"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "runner.visualize_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finishing Experiment Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.finish_experiment()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "85f5044ba23e75135dc4c908fd4d7609c1c80b195047fdb4d16ee0e66a953254"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "neptune": {
   "notebookId": "98a3967a-428e-4576-add1-6bd753600673",
   "projectVersion": 2
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
