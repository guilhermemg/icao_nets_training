{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['NEPTUNE_API_TOKEN']=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI5NDc0ZmNhNi0wODFlLTRhYTktYjgwZS01MWJkMDMxNWJhNTAifQ==\"\n",
    "os.environ['NEPTUNE_PROJECT']=\"guilhermemg/icao-nets-training-2\"\n",
    "os.environ['NEPTUNE_NOTEBOOK_ID']=\"98a391a1-c710-40bd-aaf4-42c31862cbbe\"\n",
    "os.environ['NEPTUNE_NOTEBOOK_PATH']=\"training/exec_nas_experiment.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# disable tensorflow log level infos\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # show only errors\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "if '..' not in sys.path:\n",
    "    sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> Restrict GPU memory growth: True\n"
     ]
    }
   ],
   "source": [
    "from src.m_utils import constants as cts\n",
    "from src.base.data_loaders.data_loader import DLName\n",
    "from src.base.gt_loaders.gt_names import GTName\n",
    "from src.exp_runner import ExperimentRunner\n",
    "\n",
    "from src.base.experiment.dataset.dataset import Dataset\n",
    "from src.base.experiment.evaluation.model_evaluator import DataSource, DataPredSelection\n",
    "from src.base.experiment.training.base_models import BaseModel\n",
    "from src.base.experiment.training.optimizers import Optimizer\n",
    "\n",
    "from src.m_utils.stl_approach import STLApproach\n",
    "from src.m_utils.mtl_approach import MTLApproach\n",
    "from src.m_utils.nas_mtl_approach import NAS_MTLApproach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Network runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Init ExperimentRunner -------------------\n",
      "---------------------------\n",
      "Parent Process ID: 169832\n",
      "Process ID: 184069\n",
      "---------------------------\n",
      "-----\n",
      "Use Neptune:  False\n",
      "-----\n",
      "-------------------\n",
      "Args: \n",
      "{'controller_params': {'controller_decay': 0.1,\n",
      "                       'controller_learning_rate': 0.01,\n",
      "                       'controller_loss_alpha': 0.9,\n",
      "                       'controller_lstm_dim': 100,\n",
      "                       'controller_momentum': 0.0,\n",
      "                       'controller_optimizer': <Optimizer.ADAM: 'Adam'>,\n",
      "                       'controller_sampling_epochs': 6,\n",
      "                       'controller_training_epochs': 5,\n",
      "                       'controller_use_predictor': False},\n",
      " 'exp_params': {'description': 'NAS with Approach 3',\n",
      "                'name': 'NAS experiment',\n",
      "                'src_files': ['../src/**/*.py'],\n",
      "                'tags': ['mnist', 'nas', 'nas_approach_3']},\n",
      " 'mlp_params': {'max_architecture_length': 5,\n",
      "                'min_task_group_size': 3,\n",
      "                'mlp_base_model': <BaseModel.MOBILENET_V2: {'name': 'mobilnet_v2', 'target_size': (224, 224), 'prep_function': <function preprocess_input at 0x7f9c838f4f70>}>,\n",
      "                'mlp_batch_size': 64,\n",
      "                'mlp_decay': 0.0,\n",
      "                'mlp_dropout': 0.3,\n",
      "                'mlp_early_stopping': 50,\n",
      "                'mlp_learning_rate': 0.001,\n",
      "                'mlp_loss_function': 'sparse_categorical_crossentropy',\n",
      "                'mlp_momentum': 0.0,\n",
      "                'mlp_n_epochs': 50,\n",
      "                'mlp_one_shot': True,\n",
      "                'mlp_optimizer': <Optimizer.ADAMAX: 'Adamax'>},\n",
      " 'nas_params': {'architecture_training_epochs': 2,\n",
      "                'nas_algorithm': 'rl',\n",
      "                'nas_search_space': 'ss_1',\n",
      "                'samples_per_controller_epoch': 2,\n",
      "                'total_num_proposed_architectures': 10},\n",
      " 'properties': {'approach': <NAS_MTLApproach.APPROACH_3: 'approach_3'>,\n",
      "                'balance_input_data': False,\n",
      "                'dataset': <Dataset.MNIST: {'name': 'mnist', 'target_cols': ['n_0', 'n_1', 'n_2', 'n_3', 'n_4', 'n_5', 'n_6', 'n_7', 'n_8', 'n_9'], 'tasks': [<MNIST_TASK.N_0: 'n_0'>, <MNIST_TASK.N_1: 'n_1'>, <MNIST_TASK.N_2: 'n_2'>, <MNIST_TASK.N_3: 'n_3'>, <MNIST_TASK.N_4: 'n_4'>, <MNIST_TASK.N_5: 'n_5'>, <MNIST_TASK.N_6: 'n_6'>, <MNIST_TASK.N_7: 'n_7'>, <MNIST_TASK.N_8: 'n_8'>, <MNIST_TASK.N_9: 'n_9'>]}>,\n",
      "                'exec_nas': True,\n",
      "                'orig_model_experiment_id': '',\n",
      "                'sample_prop': 0.03,\n",
      "                'sample_training_data': True,\n",
      "                'save_trained_model': True,\n",
      "                'tasks': [<MNIST_TASK.N_0: 'n_0'>,\n",
      "                          <MNIST_TASK.N_1: 'n_1'>,\n",
      "                          <MNIST_TASK.N_2: 'n_2'>,\n",
      "                          <MNIST_TASK.N_3: 'n_3'>,\n",
      "                          <MNIST_TASK.N_4: 'n_4'>,\n",
      "                          <MNIST_TASK.N_5: 'n_5'>,\n",
      "                          <MNIST_TASK.N_6: 'n_6'>,\n",
      "                          <MNIST_TASK.N_7: 'n_7'>,\n",
      "                          <MNIST_TASK.N_8: 'n_8'>,\n",
      "                          <MNIST_TASK.N_9: 'n_9'>],\n",
      "                'train_model': True},\n",
      " 'use_neptune': False}\n",
      "-------------------\n",
      "----\n",
      "Base Model Name:  BaseModel.MOBILENET_V2\n",
      "----\n",
      "MTL Model: True\n",
      "Approach: NAS_MTLApproach.APPROACH_3\n",
      "NAS MTL Model: True\n",
      "----\n",
      "--------------------  starting neptune  -------------------\n",
      "Not using Neptune to record Experiment Metadata\n",
      "Model path:  trained_model\n",
      "----\n",
      "Checking model existence locally...\n",
      "Training a new model! Not checking model existence\n",
      "----\n",
      "------------------------------\n",
      "Checking GPU availability\n",
      " ..GPU is available!\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "DATASET = Dataset.MNIST\n",
    "APPROACH = NAS_MTLApproach.APPROACH_3\n",
    "\n",
    "kwargs = { \n",
    "    'use_neptune': False,\n",
    "    'exp_params' : {\n",
    "        'name': 'NAS experiment',\n",
    "        'description': 'NAS with Approach 3',\n",
    "        'tags': [f'{DATASET.value[\"name\"]}', 'nas', 'nas_approach_3'],\n",
    "        'src_files': [\"../src/**/*.py\"]\n",
    "    },\n",
    "    'properties': {\n",
    "        'approach': APPROACH,\n",
    "        'dataset': DATASET,\n",
    "        'tasks': DATASET.value['tasks'],\n",
    "        'balance_input_data': False,\n",
    "        'train_model': True,\n",
    "        'save_trained_model': True,\n",
    "        'exec_nas': True,\n",
    "        'orig_model_experiment_id': '',\n",
    "        'sample_training_data': True,\n",
    "        'sample_prop': 0.03\n",
    "    },\n",
    "    'nas_params': {\n",
    "        'samples_per_controller_epoch': 2,    # nas batch size (#architectures proposed per controller epoch)\n",
    "        'architecture_training_epochs': 2,     # n_epochs for training proposed architecture\n",
    "        'total_num_proposed_architectures': 10,\n",
    "        'nas_algorithm': 'rl',\n",
    "        'nas_search_space': 'ss_1'\n",
    "    },\n",
    "    'controller_params': {\n",
    "        'controller_lstm_dim': 100,\n",
    "        'controller_optimizer': Optimizer.ADAM,\n",
    "        'controller_learning_rate': 0.01,\n",
    "        'controller_decay': 0.1,\n",
    "        'controller_momentum': 0.0,\n",
    "        'controller_use_predictor': False,\n",
    "        'controller_loss_alpha': 0.9,\n",
    "        'controller_training_epochs': 5,\n",
    "        'controller_sampling_epochs': 6\n",
    "    },\n",
    "    'mlp_params': {\n",
    "        'max_architecture_length': 5,\n",
    "        'min_task_group_size': 3,\n",
    "        'mlp_base_model': BaseModel.MOBILENET_V2,\n",
    "        'mlp_n_epochs': 50,\n",
    "        'mlp_batch_size': 64,\n",
    "        'mlp_early_stopping': 50,\n",
    "        'mlp_optimizer': Optimizer.ADAMAX,\n",
    "        'mlp_learning_rate': 1e-3,\n",
    "        'mlp_decay': 0.0,\n",
    "        'mlp_momentum': 0.0,\n",
    "        'mlp_dropout': 0.3,\n",
    "        'mlp_loss_function': 'sparse_categorical_crossentropy',\n",
    "        'mlp_one_shot': True\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "runner = ExperimentRunner(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- load training data -------------------\n",
      "Loading data\n",
      "TrainData.shape: (48000, 11)\n",
      "ValidationData.shape: (12000, 11)\n",
      "TestData.shape: (10000, 11)\n",
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "runner.load_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- sample training data -------------------\n",
      "Applying subsampling in training data\n",
      "..Sampling proportion: 0.03 (1440/48000)\n",
      "(1440, 11)\n",
      "Applying subsampling in validation data\n",
      "..Sampling proportion: 0.03 (360/12000)\n",
      "(360, 11)\n"
     ]
    }
   ],
   "source": [
    "runner.sample_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>n_0</th>\n",
       "      <th>n_1</th>\n",
       "      <th>n_2</th>\n",
       "      <th>n_3</th>\n",
       "      <th>n_4</th>\n",
       "      <th>n_5</th>\n",
       "      <th>n_6</th>\n",
       "      <th>n_7</th>\n",
       "      <th>n_8</th>\n",
       "      <th>n_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32771</th>\n",
       "      <td>/home/guilherme/data1/Dropbox/Link to Desktop/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39512</th>\n",
       "      <td>/home/guilherme/data1/Dropbox/Link to Desktop/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43581</th>\n",
       "      <td>/home/guilherme/data1/Dropbox/Link to Desktop/...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>/home/guilherme/data1/Dropbox/Link to Desktop/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3377</th>\n",
       "      <td>/home/guilherme/data1/Dropbox/Link to Desktop/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                img_name  n_0  n_1  n_2  n_3  \\\n",
       "32771  /home/guilherme/data1/Dropbox/Link to Desktop/...  0.0  0.0  0.0  0.0   \n",
       "39512  /home/guilherme/data1/Dropbox/Link to Desktop/...  0.0  0.0  0.0  0.0   \n",
       "43581  /home/guilherme/data1/Dropbox/Link to Desktop/...  1.0  0.0  0.0  0.0   \n",
       "2975   /home/guilherme/data1/Dropbox/Link to Desktop/...  0.0  0.0  0.0  0.0   \n",
       "3377   /home/guilherme/data1/Dropbox/Link to Desktop/...  0.0  0.0  0.0  1.0   \n",
       "\n",
       "       n_4  n_5  n_6  n_7  n_8  n_9  \n",
       "32771  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "39512  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "43581  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2975   0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "3377   0.0  0.0  0.0  0.0  0.0  0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.train_data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# <font color='red'>Producing Fake Data</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "runner.produce_fake_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- setup data generators -------------------\n",
      "Starting data generators\n",
      "Found 1440 validated image filenames.\n",
      "Found 360 validated image filenames.\n",
      "Found 10000 validated image filenames.\n",
      "TOTAL: 11800\n",
      "\n",
      "Logging class indices\n",
      " .. MTL model not logging class indices!\n",
      "\n",
      "Using benchmarking dataset. Not logging class labels!\n"
     ]
    }
   ],
   "source": [
    "runner.setup_data_generators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- create experiment -------------------\n",
      "Not using Neptune\n"
     ]
    }
   ],
   "source": [
    "runner.setup_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Labels Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "runner.summary_labels_dist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Architecture Search - v3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, RNN, LSTMCell, Input\n",
    "\n",
    "\n",
    "all_archs = [(i,j,p,q) for i in range(1,6) for j in range(1,6) for p in range(1,6) for q in range(1,6)]\n",
    "\n",
    "print(f'all_archs[:10]: {all_archs[:10]}')\n",
    "\n",
    "search_space_size = len(all_archs)\n",
    "print(f'search_space_size: {search_space_size}')\n",
    "\n",
    "\n",
    "def __create_control_model(controller_input_shape):\n",
    "        main_input = Input(shape=controller_input_shape, name='main_input')        \n",
    "        print(f'Controller model input shape: {main_input.shape}')\n",
    "        x = RNN(LSTMCell(100), return_sequences=True)(main_input)\n",
    "        main_output = Dense(search_space_size, activation='softmax', name='main_output')(x)\n",
    "        print(f'Controller model output shape: {main_output.shape}')\n",
    "        model = Model(inputs=[main_input], outputs=[main_output])\n",
    "        return model\n",
    "    \n",
    "model = __create_control_model((1,4))    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "history = []\n",
    "for i in range(5):\n",
    "    print(10*'-')\n",
    "    if i == 0:\n",
    "        inp = np.zeros((1,1,4))\n",
    "    else:\n",
    "        inp = np.array(history[-1]).reshape(1,1,4)\n",
    "    \n",
    "    print(f'input: {inp}')\n",
    "    \n",
    "    prob_list = model.predict(inp)\n",
    "    \n",
    "    prob_list = prob_list[0][0]\n",
    "    print(f'prob_list[:5]: {prob_list[:5]}')\n",
    "    \n",
    "    chose_idx = np.random.choice(range(search_space_size), size=1, replace=False, p=prob_list)[0]\n",
    "    print(f'chose_idx: {chose_idx}')\n",
    "    \n",
    "    new_arch = all_archs[chose_idx]\n",
    "    print(f'new_arch: {new_arch}')\n",
    "    \n",
    "    history.append(new_arch)\n",
    "    print(f'history: {history}')\n",
    "    \n",
    "    print(10*'-')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- run neural architecture search -------------------\n",
      "all_archs[:10]: [[0, 0, 0, 0], [0, 0, 0, 1], [0, 0, 0, 2], [0, 0, 0, 3], [0, 0, 0, 4], [0, 0, 1, 0], [0, 0, 1, 1], [0, 0, 1, 2], [0, 0, 1, 3], [0, 0, 1, 4]]\n",
      "search_space_size: 625\n",
      "Controller model input shape: (None, 1, 4)\n",
      "Controller model output shape: (None, 1, 625)\n",
      "Model path:  trained_model\n",
      "----\n",
      "Checking model existence locally...\n",
      "Training a new model! Not checking model existence\n",
      "----\n",
      "------------------------------\n",
      "Checking GPU availability\n",
      " ..GPU is available!\n",
      "------------------------------\n",
      " ..prev_arch: [[[5 2 4 4]]]\n",
      " ..prev_arch.shape: (1, 1, 4)\n",
      "input: [[[5 2 4 4]]]\n",
      "prob_list[:5]: [0.00147728 0.00154044 0.00158851 0.00162069 0.00162576]\n",
      "chose_idx: 42\n",
      "new_arch: [0, 1, 3, 2]\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 1 | Feedback DNA: DNA([0, 1, 3, 2])\n",
      "----------------------------------------------------------------------\n",
      " -- Architecture 1: {'n_denses_0': 1, 'n_denses_1': 2, 'n_denses_2': 4, 'n_denses_3': 3}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 3,149,844\n",
      "  .. Trainable params: 891,860\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.76257, saving model to training/training_ckpt/best_model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_loss improved from 0.76257 to 0.65431, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "6/6 [==============================] - 1s 110ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00310 | EER_interp: 0.00000 | ACC: 0.99720\n",
      "  Task  1: n_1             | EER_mean: 0.02080 | EER_interp: 0.01520 | ACC: 0.98890\n",
      "  Task  2: n_2             | EER_mean: 0.13400 | EER_interp: 0.13110 | ACC: 0.86670\n",
      "  Task  3: n_3             | EER_mean: 0.15380 | EER_interp: 0.14880 | ACC: 0.85560\n",
      "  Task  4: n_4             | EER_mean: 0.09780 | EER_interp: 0.09540 | ACC: 0.90280\n",
      "  Task  5: n_5             | EER_mean: 0.15410 | EER_interp: 0.14600 | ACC: 0.84720\n",
      "  Task  6: n_6             | EER_mean: 0.02500 | EER_interp: 0.02340 | ACC: 0.97780\n",
      "  Task  7: n_7             | EER_mean: 0.16670 | EER_interp: 0.15160 | ACC: 0.86110\n",
      "  Task  8: n_8             | EER_mean: 0.08110 | EER_interp: 0.07920 | ACC: 0.92220\n",
      "  Task  9: n_9             | EER_mean: 0.08900 | EER_interp: 0.08860 | ACC: 0.91110\n",
      "final_EER_mean: 8.79% | final_EER_median: 9.2% | final_EER_std_dv: 5.51% | final_ACC: 91.31%\n",
      "validation accuracy:  91.31\n",
      "======================================================================\n",
      " ..nas_history_data: [[DNA([0, 1, 3, 2]), 91.31]]\n",
      " ..len(self.nas_history_data): 1\n",
      "logging data...\n",
      " ..prev_arch: [[[0 1 3 2]]]\n",
      " ..prev_arch.shape: (1, 1, 4)\n",
      "input: [[[0 1 3 2]]]\n",
      "prob_list[:5]: [0.00156788 0.00154769 0.00159364 0.00155594 0.00151859]\n",
      "chose_idx: 61\n",
      "new_arch: [0, 2, 2, 1]\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 2 | Feedback DNA: DNA([0, 2, 2, 1])\n",
      "----------------------------------------------------------------------\n",
      " -- Architecture 2: {'n_denses_0': 1, 'n_denses_1': 3, 'n_denses_2': 3, 'n_denses_3': 2}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 3,137,364\n",
      "  .. Trainable params: 879,380\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.58335, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.58335 to 0.50033, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "6/6 [==============================] - 1s 53ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.01230 | EER_interp: 0.00000 | ACC: 0.98890\n",
      "  Task  1: n_1             | EER_mean: 0.02080 | EER_interp: 0.02000 | ACC: 0.98060\n",
      "  Task  2: n_2             | EER_mean: 0.19940 | EER_interp: 0.18940 | ACC: 0.80280\n",
      "  Task  3: n_3             | EER_mean: 0.23080 | EER_interp: 0.22470 | ACC: 0.78060\n",
      "  Task  4: n_4             | EER_mean: 0.08520 | EER_interp: 0.08910 | ACC: 0.91390\n",
      "  Task  5: n_5             | EER_mean: 0.20690 | EER_interp: 0.20620 | ACC: 0.79440\n",
      "  Task  6: n_6             | EER_mean: 0.05940 | EER_interp: 0.05470 | ACC: 0.94170\n",
      "  Task  7: n_7             | EER_mean: 0.09390 | EER_interp: 0.09700 | ACC: 0.90560\n",
      "  Task  8: n_8             | EER_mean: 0.13510 | EER_interp: 0.13560 | ACC: 0.86390\n",
      "  Task  9: n_9             | EER_mean: 0.26470 | EER_interp: 0.26580 | ACC: 0.73330\n",
      "final_EER_mean: 12.82% | final_EER_median: 11.63% | final_EER_std_dv: 8.61% | final_ACC: 87.06%\n",
      "validation accuracy:  87.06\n",
      "======================================================================\n",
      " ..nas_history_data: [[DNA([0, 1, 3, 2]), 91.31], [DNA([0, 2, 2, 1]), 87.06]]\n",
      " ..len(self.nas_history_data): 2\n",
      "logging data...\n",
      "......................................................................\n",
      " ..New batch of architectures. Training controller model...\n",
      "Training controller model...\n",
      "Preparing controller data...\n",
      " ..nas_data_history: [[DNA([0, 1, 3, 2]), 91.31], [DNA([0, 2, 2, 1]), 87.06]]\n",
      " ..xc: [[[0 1 3 2]]\n",
      "\n",
      " [[0 2 2 1]]]\n",
      " ..xc.shape: (2, 1, 4)\n",
      " ..yc: [[[0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]]]\n",
      " ..yc.shape: (2, 1, 4)\n",
      " ..val_acc_target: [91.31, 87.06]\n",
      " ..val_acc_target.length: 2\n",
      "TRAINING CONTROLLER...\n",
      " ..Controller model trained!\n",
      "......................................................................\n",
      " ..prev_arch: [[[0 2 2 1]]]\n",
      " ..prev_arch.shape: (1, 1, 4)\n",
      "input: [[[0 2 2 1]]]\n",
      "prob_list[:5]: [0.00160638 0.00157429 0.00160176 0.00159447 0.00156415]\n",
      "chose_idx: 589\n",
      "new_arch: [4, 3, 2, 4]\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 3 | Feedback DNA: DNA([4, 3, 2, 4])\n",
      "----------------------------------------------------------------------\n",
      " -- Architecture 3: {'n_denses_0': 5, 'n_denses_1': 4, 'n_denses_2': 3, 'n_denses_3': 5}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 3,216,404\n",
      "  .. Trainable params: 958,420\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.52230, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.52230 to 0.44167, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "6/6 [==============================] - 1s 52ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.00310 | EER_interp: 0.00000 | ACC: 0.99720\n",
      "  Task  1: n_1             | EER_mean: 0.01920 | EER_interp: 0.02000 | ACC: 0.98060\n",
      "  Task  2: n_2             | EER_mean: 0.17950 | EER_interp: 0.16920 | ACC: 0.83890\n",
      "  Task  3: n_3             | EER_mean: 0.07780 | EER_interp: 0.07740 | ACC: 0.92220\n",
      "  Task  4: n_4             | EER_mean: 0.06980 | EER_interp: 0.05860 | ACC: 0.95000\n",
      "  Task  5: n_5             | EER_mean: 0.12990 | EER_interp: 0.13390 | ACC: 0.86940\n",
      "  Task  6: n_6             | EER_mean: 0.07500 | EER_interp: 0.07030 | ACC: 0.93330\n",
      "  Task  7: n_7             | EER_mean: 0.07270 | EER_interp: 0.06970 | ACC: 0.92780\n",
      "  Task  8: n_8             | EER_mean: 0.05410 | EER_interp: 0.05180 | ACC: 0.95000\n",
      "  Task  9: n_9             | EER_mean: 0.05880 | EER_interp: 0.05860 | ACC: 0.94170\n",
      "final_EER_mean: 7.09% | final_EER_median: 6.42% | final_EER_std_dv: 4.69% | final_ACC: 93.11%\n",
      "validation accuracy:  93.11\n",
      "======================================================================\n",
      " ..nas_history_data: [[DNA([0, 1, 3, 2]), 91.31], [DNA([0, 2, 2, 1]), 87.06], [DNA([4, 3, 2, 4]), 93.11]]\n",
      " ..len(self.nas_history_data): 3\n",
      "logging data...\n",
      " ..prev_arch: [[[4 3 2 4]]]\n",
      " ..prev_arch.shape: (1, 1, 4)\n",
      "input: [[[4 3 2 4]]]\n",
      "prob_list[:5]: [0.00152436 0.00154424 0.00157047 0.00171726 0.00162971]\n",
      "chose_idx: 584\n",
      "new_arch: [4, 3, 1, 4]\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 4 | Feedback DNA: DNA([4, 3, 1, 4])\n",
      "----------------------------------------------------------------------\n",
      " -- Architecture 4: {'n_denses_0': 5, 'n_denses_1': 4, 'n_denses_2': 2, 'n_denses_3': 5}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 3,208,084\n",
      "  .. Trainable params: 950,100\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.62041, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.62041\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "6/6 [==============================] - 1s 45ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.01840 | EER_interp: 0.00000 | ACC: 0.98330\n",
      "  Task  1: n_1             | EER_mean: 0.05770 | EER_interp: 0.07050 | ACC: 0.93890\n",
      "  Task  2: n_2             | EER_mean: 0.17950 | EER_interp: 0.17700 | ACC: 0.82500\n",
      "  Task  3: n_3             | EER_mean: 0.21560 | EER_interp: 0.22320 | ACC: 0.78330\n",
      "  Task  4: n_4             | EER_mean: 0.16280 | EER_interp: 0.15240 | ACC: 0.85560\n",
      "  Task  5: n_5             | EER_mean: 0.09670 | EER_interp: 0.08290 | ACC: 0.90560\n",
      "  Task  6: n_6             | EER_mean: 0.08750 | EER_interp: 0.08120 | ACC: 0.91390\n",
      "  Task  7: n_7             | EER_mean: 0.16670 | EER_interp: 0.16970 | ACC: 0.82780\n",
      "  Task  8: n_8             | EER_mean: 0.14550 | EER_interp: 0.14030 | ACC: 0.85560\n",
      "  Task  9: n_9             | EER_mean: 0.17650 | EER_interp: 0.17560 | ACC: 0.82500\n",
      "final_EER_mean: 12.73% | final_EER_median: 14.64% | final_EER_std_dv: 6.33% | final_ACC: 87.14%\n",
      "validation accuracy:  87.14\n",
      "======================================================================\n",
      " ..nas_history_data: [[DNA([0, 1, 3, 2]), 91.31], [DNA([0, 2, 2, 1]), 87.06], [DNA([4, 3, 2, 4]), 93.11], [DNA([4, 3, 1, 4]), 87.14]]\n",
      " ..len(self.nas_history_data): 4\n",
      "logging data...\n",
      "......................................................................\n",
      " ..New batch of architectures. Training controller model...\n",
      "Training controller model...\n",
      "Preparing controller data...\n",
      " ..nas_data_history: [[DNA([4, 3, 2, 4]), 93.11], [DNA([4, 3, 1, 4]), 87.14]]\n",
      " ..xc: [[[4 3 2 4]]\n",
      "\n",
      " [[4 3 1 4]]]\n",
      " ..xc.shape: (2, 1, 4)\n",
      " ..yc: [[[0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]]]\n",
      " ..yc.shape: (2, 1, 4)\n",
      " ..val_acc_target: [93.11, 87.14]\n",
      " ..val_acc_target.length: 2\n",
      "TRAINING CONTROLLER...\n",
      " ..Controller model trained!\n",
      "......................................................................\n",
      " ..prev_arch: [[[4 3 1 4]]]\n",
      " ..prev_arch.shape: (1, 1, 4)\n",
      "input: [[[4 3 1 4]]]\n",
      "prob_list[:5]: [0.00137993 0.00126379 0.00165768 0.00135451 0.00152604]\n",
      "chose_idx: 154\n",
      "new_arch: [1, 1, 0, 4]\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 5 | Feedback DNA: DNA([1, 1, 0, 4])\n",
      "----------------------------------------------------------------------\n",
      " -- Architecture 5: {'n_denses_0': 2, 'n_denses_1': 2, 'n_denses_2': 1, 'n_denses_3': 5}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 3,162,324\n",
      "  .. Trainable params: 904,340\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.82789, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.82789 to 0.80649, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "6/6 [==============================] - 1s 49ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.03680 | EER_interp: 0.03310 | ACC: 0.96390\n",
      "  Task  1: n_1             | EER_mean: 0.01600 | EER_interp: 0.01840 | ACC: 0.98330\n",
      "  Task  2: n_2             | EER_mean: 0.27410 | EER_interp: 0.27810 | ACC: 0.72500\n",
      "  Task  3: n_3             | EER_mean: 0.12570 | EER_interp: 0.12060 | ACC: 0.87500\n",
      "  Task  4: n_4             | EER_mean: 0.15770 | EER_interp: 0.16020 | ACC: 0.84170\n",
      "  Task  5: n_5             | EER_mean: 0.14800 | EER_interp: 0.14300 | ACC: 0.85280\n",
      "  Task  6: n_6             | EER_mean: 0.17500 | EER_interp: 0.17340 | ACC: 0.82780\n",
      "  Task  7: n_7             | EER_mean: 0.21520 | EER_interp: 0.22420 | ACC: 0.78330\n",
      "  Task  8: n_8             | EER_mean: 0.15790 | EER_interp: 0.16010 | ACC: 0.84170\n",
      "  Task  9: n_9             | EER_mean: 0.25150 | EER_interp: 0.25810 | ACC: 0.74720\n",
      "final_EER_mean: 15.69% | final_EER_median: 16.02% | final_EER_std_dv: 8.11% | final_ACC: 84.42%\n",
      "validation accuracy:  84.42\n",
      "======================================================================\n",
      " ..nas_history_data: [[DNA([0, 1, 3, 2]), 91.31], [DNA([0, 2, 2, 1]), 87.06], [DNA([4, 3, 2, 4]), 93.11], [DNA([4, 3, 1, 4]), 87.14], [DNA([1, 1, 0, 4]), 84.42]]\n",
      " ..len(self.nas_history_data): 5\n",
      "logging data...\n",
      " ..prev_arch: [[[1 1 0 4]]]\n",
      " ..prev_arch.shape: (1, 1, 4)\n",
      "input: [[[1 1 0 4]]]\n",
      "prob_list[:5]: [0.00151647 0.00139139 0.00160161 0.00150713 0.00153653]\n",
      "chose_idx: 494\n",
      "new_arch: [3, 4, 3, 4]\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 6 | Feedback DNA: DNA([3, 4, 3, 4])\n",
      "----------------------------------------------------------------------\n",
      " -- Architecture 6: {'n_denses_0': 4, 'n_denses_1': 5, 'n_denses_2': 4, 'n_denses_3': 5}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 3,233,044\n",
      "  .. Trainable params: 975,060\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.47278, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.47278\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "6/6 [==============================] - 1s 52ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.03070 | EER_interp: 0.03000 | ACC: 0.96940\n",
      "  Task  1: n_1             | EER_mean: 0.01600 | EER_interp: 0.00000 | ACC: 0.98610\n",
      "  Task  2: n_2             | EER_mean: 0.17950 | EER_interp: 0.18160 | ACC: 0.81670\n",
      "  Task  3: n_3             | EER_mean: 0.23950 | EER_interp: 0.25430 | ACC: 0.75830\n",
      "  Task  4: n_4             | EER_mean: 0.13950 | EER_interp: 0.13920 | ACC: 0.86110\n",
      "  Task  5: n_5             | EER_mean: 0.11480 | EER_interp: 0.10910 | ACC: 0.88610\n",
      "  Task  6: n_6             | EER_mean: 0.06560 | EER_interp: 0.07030 | ACC: 0.93330\n",
      "  Task  7: n_7             | EER_mean: 0.11520 | EER_interp: 0.10760 | ACC: 0.88610\n",
      "  Task  8: n_8             | EER_mean: 0.22600 | EER_interp: 0.22110 | ACC: 0.77500\n",
      "  Task  9: n_9             | EER_mean: 0.14420 | EER_interp: 0.14560 | ACC: 0.85560\n",
      "final_EER_mean: 12.59% | final_EER_median: 12.42% | final_EER_std_dv: 7.61% | final_ACC: 87.28%\n",
      "validation accuracy:  87.28\n",
      "======================================================================\n",
      " ..nas_history_data: [[DNA([0, 1, 3, 2]), 91.31], [DNA([0, 2, 2, 1]), 87.06], [DNA([4, 3, 2, 4]), 93.11], [DNA([4, 3, 1, 4]), 87.14], [DNA([1, 1, 0, 4]), 84.42], [DNA([3, 4, 3, 4]), 87.28]]\n",
      " ..len(self.nas_history_data): 6\n",
      "logging data...\n",
      "......................................................................\n",
      " ..New batch of architectures. Training controller model...\n",
      "Training controller model...\n",
      "Preparing controller data...\n",
      " ..nas_data_history: [[DNA([1, 1, 0, 4]), 84.42], [DNA([3, 4, 3, 4]), 87.28]]\n",
      " ..xc: [[[1 1 0 4]]\n",
      "\n",
      " [[3 4 3 4]]]\n",
      " ..xc.shape: (2, 1, 4)\n",
      " ..yc: [[[0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]]]\n",
      " ..yc.shape: (2, 1, 4)\n",
      " ..val_acc_target: [84.42, 87.28]\n",
      " ..val_acc_target.length: 2\n",
      "TRAINING CONTROLLER...\n",
      " ..Controller model trained!\n",
      "......................................................................\n",
      " ..prev_arch: [[[3 4 3 4]]]\n",
      " ..prev_arch.shape: (1, 1, 4)\n",
      "input: [[[3 4 3 4]]]\n",
      "prob_list[:5]: [0.00156786 0.00139201 0.00155949 0.00151672 0.00167839]\n",
      "chose_idx: 573\n",
      "new_arch: [4, 2, 4, 3]\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 7 | Feedback DNA: DNA([4, 2, 4, 3])\n",
      "----------------------------------------------------------------------\n",
      " -- Architecture 7: {'n_denses_0': 5, 'n_denses_1': 3, 'n_denses_2': 5, 'n_denses_3': 4}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 3,203,924\n",
      "  .. Trainable params: 945,940\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.63308, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.63308\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "6/6 [==============================] - 1s 49ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.08820 | EER_interp: 0.08700 | ACC: 0.91390\n",
      "  Task  1: n_1             | EER_mean: 0.06090 | EER_interp: 0.06170 | ACC: 0.93890\n",
      "  Task  2: n_2             | EER_mean: 0.25640 | EER_interp: 0.25750 | ACC: 0.74170\n",
      "  Task  3: n_3             | EER_mean: 0.12280 | EER_interp: 0.11910 | ACC: 0.87780\n",
      "  Task  4: n_4             | EER_mean: 0.15140 | EER_interp: 0.14550 | ACC: 0.85000\n",
      "  Task  5: n_5             | EER_mean: 0.13790 | EER_interp: 0.13540 | ACC: 0.86670\n",
      "  Task  6: n_6             | EER_mean: 0.13130 | EER_interp: 0.12810 | ACC: 0.86940\n",
      "  Task  7: n_7             | EER_mean: 0.16670 | EER_interp: 0.16520 | ACC: 0.83610\n",
      "  Task  8: n_8             | EER_mean: 0.09910 | EER_interp: 0.09010 | ACC: 0.90280\n",
      "  Task  9: n_9             | EER_mean: 0.22090 | EER_interp: 0.22810 | ACC: 0.77780\n",
      "final_EER_mean: 14.18% | final_EER_median: 13.17% | final_EER_std_dv: 5.85% | final_ACC: 85.75%\n",
      "validation accuracy:  85.75\n",
      "======================================================================\n",
      " ..nas_history_data: [[DNA([0, 1, 3, 2]), 91.31], [DNA([0, 2, 2, 1]), 87.06], [DNA([4, 3, 2, 4]), 93.11], [DNA([4, 3, 1, 4]), 87.14], [DNA([1, 1, 0, 4]), 84.42], [DNA([3, 4, 3, 4]), 87.28], [DNA([4, 2, 4, 3]), 85.75]]\n",
      " ..len(self.nas_history_data): 7\n",
      "logging data...\n",
      " ..prev_arch: [[[4 2 4 3]]]\n",
      " ..prev_arch.shape: (1, 1, 4)\n",
      "input: [[[4 2 4 3]]]\n",
      "prob_list[:5]: [0.00155759 0.00139691 0.001533   0.00150614 0.00173657]\n",
      "chose_idx: 332\n",
      "new_arch: [2, 3, 1, 2]\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 8 | Feedback DNA: DNA([2, 3, 1, 2])\n",
      "----------------------------------------------------------------------\n",
      " -- Architecture 8: {'n_denses_0': 3, 'n_denses_1': 4, 'n_denses_2': 2, 'n_denses_3': 3}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 3,166,484\n",
      "  .. Trainable params: 908,500\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.98073, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.98073 to 0.87885, saving model to training/training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "6/6 [==============================] - 1s 49ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.02940 | EER_interp: 0.02700 | ACC: 0.97500\n",
      "  Task  1: n_1             | EER_mean: 0.03210 | EER_interp: 0.02640 | ACC: 0.96940\n",
      "  Task  2: n_2             | EER_mean: 0.15380 | EER_interp: 0.15010 | ACC: 0.85280\n",
      "  Task  3: n_3             | EER_mean: 0.30240 | EER_interp: 0.30500 | ACC: 0.69720\n",
      "  Task  4: n_4             | EER_mean: 0.14830 | EER_interp: 0.14390 | ACC: 0.85280\n",
      "  Task  5: n_5             | EER_mean: 0.16010 | EER_interp: 0.14900 | ACC: 0.84170\n",
      "  Task  6: n_6             | EER_mean: 0.05000 | EER_interp: 0.04530 | ACC: 0.95830\n",
      "  Task  7: n_7             | EER_mean: 0.23330 | EER_interp: 0.23330 | ACC: 0.76670\n",
      "  Task  8: n_8             | EER_mean: 0.13930 | EER_interp: 0.13720 | ACC: 0.86110\n",
      "  Task  9: n_9             | EER_mean: 0.17790 | EER_interp: 0.20660 | ACC: 0.81670\n",
      "final_EER_mean: 14.24% | final_EER_median: 14.64% | final_EER_std_dv: 8.67% | final_ACC: 85.92%\n",
      "validation accuracy:  85.92\n",
      "======================================================================\n",
      " ..nas_history_data: [[DNA([0, 1, 3, 2]), 91.31], [DNA([0, 2, 2, 1]), 87.06], [DNA([4, 3, 2, 4]), 93.11], [DNA([4, 3, 1, 4]), 87.14], [DNA([1, 1, 0, 4]), 84.42], [DNA([3, 4, 3, 4]), 87.28], [DNA([4, 2, 4, 3]), 85.75], [DNA([2, 3, 1, 2]), 85.92]]\n",
      " ..len(self.nas_history_data): 8\n",
      "logging data...\n",
      "......................................................................\n",
      " ..New batch of architectures. Training controller model...\n",
      "Training controller model...\n",
      "Preparing controller data...\n",
      " ..nas_data_history: [[DNA([4, 2, 4, 3]), 85.75], [DNA([2, 3, 1, 2]), 85.92]]\n",
      " ..xc: [[[4 2 4 3]]\n",
      "\n",
      " [[2 3 1 2]]]\n",
      " ..xc.shape: (2, 1, 4)\n",
      " ..yc: [[[0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]]]\n",
      " ..yc.shape: (2, 1, 4)\n",
      " ..val_acc_target: [85.75, 85.92]\n",
      " ..val_acc_target.length: 2\n",
      "TRAINING CONTROLLER...\n",
      " ..Controller model trained!\n",
      "......................................................................\n",
      " ..prev_arch: [[[2 3 1 2]]]\n",
      " ..prev_arch.shape: (1, 1, 4)\n",
      "input: [[[2 3 1 2]]]\n",
      "prob_list[:5]: [0.00175323 0.00159912 0.00179339 0.00172257 0.00148481]\n",
      "chose_idx: 316\n",
      "new_arch: [2, 2, 3, 1]\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 9 | Feedback DNA: DNA([2, 2, 3, 1])\n",
      "----------------------------------------------------------------------\n",
      " -- Architecture 9: {'n_denses_0': 3, 'n_denses_1': 3, 'n_denses_2': 4, 'n_denses_3': 2}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 3,154,004\n",
      "  .. Trainable params: 896,020\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.77957, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.77957\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "6/6 [==============================] - 1s 49ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.11760 | EER_interp: 0.11560 | ACC: 0.88610\n",
      "  Task  1: n_1             | EER_mean: 0.08970 | EER_interp: 0.08650 | ACC: 0.91110\n",
      "  Task  2: n_2             | EER_mean: 0.23990 | EER_interp: 0.23540 | ACC: 0.76110\n",
      "  Task  3: n_3             | EER_mean: 0.26920 | EER_interp: 0.26940 | ACC: 0.73060\n",
      "  Task  4: n_4             | EER_mean: 0.34880 | EER_interp: 0.34790 | ACC: 0.65280\n",
      "  Task  5: n_5             | EER_mean: 0.17240 | EER_interp: 0.17230 | ACC: 0.82780\n",
      "  Task  6: n_6             | EER_mean: 0.20000 | EER_interp: 0.20000 | ACC: 0.80000\n",
      "  Task  7: n_7             | EER_mean: 0.14850 | EER_interp: 0.14090 | ACC: 0.85280\n",
      "  Task  8: n_8             | EER_mean: 0.32430 | EER_interp: 0.32320 | ACC: 0.67780\n",
      "  Task  9: n_9             | EER_mean: 0.41180 | EER_interp: 0.40990 | ACC: 0.59170\n",
      "final_EER_mean: 23.01% | final_EER_median: 21.77% | final_EER_std_dv: 10.12% | final_ACC: 76.92%\n",
      "validation accuracy:  76.92\n",
      "======================================================================\n",
      " ..nas_history_data: [[DNA([0, 1, 3, 2]), 91.31], [DNA([0, 2, 2, 1]), 87.06], [DNA([4, 3, 2, 4]), 93.11], [DNA([4, 3, 1, 4]), 87.14], [DNA([1, 1, 0, 4]), 84.42], [DNA([3, 4, 3, 4]), 87.28], [DNA([4, 2, 4, 3]), 85.75], [DNA([2, 3, 1, 2]), 85.92], [DNA([2, 2, 3, 1]), 76.92]]\n",
      " ..len(self.nas_history_data): 9\n",
      "logging data...\n",
      " ..prev_arch: [[[2 2 3 1]]]\n",
      " ..prev_arch.shape: (1, 1, 4)\n",
      "input: [[[2 2 3 1]]]\n",
      "prob_list[:5]: [0.00178274 0.0015999  0.00180522 0.00174411 0.00147495]\n",
      "chose_idx: 57\n",
      "new_arch: [0, 2, 1, 2]\n",
      "======================================================================\n",
      "  New Controller Epoch | Feedback ID: 10 | Feedback DNA: DNA([0, 2, 1, 2])\n",
      "----------------------------------------------------------------------\n",
      " -- Architecture 10: {'n_denses_0': 1, 'n_denses_1': 3, 'n_denses_2': 2, 'n_denses_3': 3}\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 3,145,684\n",
      "  .. Trainable params: 887,700\n",
      "  .. Non-trainable params: 2,257,984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.72091, saving model to training/training_ckpt/best_model.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.72091\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "6/6 [==============================] - 1s 45ms/step\n",
      "Prediction finished!\n",
      "  Task  0: n_0             | EER_mean: 0.03370 | EER_interp: 0.03160 | ACC: 0.96670\n",
      "  Task  1: n_1             | EER_mean: 0.04170 | EER_interp: 0.04010 | ACC: 0.96110\n",
      "  Task  2: n_2             | EER_mean: 0.23080 | EER_interp: 0.22760 | ACC: 0.77500\n",
      "  Task  3: n_3             | EER_mean: 0.39820 | EER_interp: 0.39140 | ACC: 0.60280\n",
      "  Task  4: n_4             | EER_mean: 0.06980 | EER_interp: 0.06800 | ACC: 0.93330\n",
      "  Task  5: n_5             | EER_mean: 0.24770 | EER_interp: 0.24460 | ACC: 0.75280\n",
      "  Task  6: n_6             | EER_mean: 0.17500 | EER_interp: 0.17500 | ACC: 0.82500\n",
      "  Task  7: n_7             | EER_mean: 0.19700 | EER_interp: 0.18190 | ACC: 0.80560\n",
      "  Task  8: n_8             | EER_mean: 0.24150 | EER_interp: 0.24240 | ACC: 0.75830\n",
      "  Task  9: n_9             | EER_mean: 0.23310 | EER_interp: 0.23420 | ACC: 0.76670\n",
      "final_EER_mean: 18.37% | final_EER_median: 20.47% | final_EER_std_dv: 10.58% | final_ACC: 81.47%\n",
      "validation accuracy:  81.47\n",
      "======================================================================\n",
      " ..nas_history_data: [[DNA([0, 1, 3, 2]), 91.31], [DNA([0, 2, 2, 1]), 87.06], [DNA([4, 3, 2, 4]), 93.11], [DNA([4, 3, 1, 4]), 87.14], [DNA([1, 1, 0, 4]), 84.42], [DNA([3, 4, 3, 4]), 87.28], [DNA([4, 2, 4, 3]), 85.75], [DNA([2, 3, 1, 2]), 85.92], [DNA([2, 2, 3, 1]), 76.92], [DNA([0, 2, 1, 2]), 81.47]]\n",
      " ..len(self.nas_history_data): 10\n",
      "logging data...\n",
      "\n",
      "\n",
      "------------------ TOP ARCHITECTURES FOUND --------------------\n",
      "Top 5 Architectures:\n",
      " . Architecture 0: {'n_denses_0': 5, 'n_denses_1': 4, 'n_denses_2': 3, 'n_denses_3': 5} | Validation accuracy: 93.11%\n",
      " . Architecture 1: {'n_denses_0': 1, 'n_denses_1': 2, 'n_denses_2': 4, 'n_denses_3': 3} | Validation accuracy: 91.31%\n",
      " . Architecture 2: {'n_denses_0': 4, 'n_denses_1': 5, 'n_denses_2': 4, 'n_denses_3': 5} | Validation accuracy: 87.28%\n",
      " . Architecture 3: {'n_denses_0': 5, 'n_denses_1': 4, 'n_denses_2': 2, 'n_denses_3': 5} | Validation accuracy: 87.14%\n",
      " . Architecture 4: {'n_denses_0': 1, 'n_denses_1': 3, 'n_denses_2': 3, 'n_denses_3': 2} | Validation accuracy: 87.06%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_archs_list = runner.run_neural_architecture_search_v3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create Model with Best Architecture Found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_arch = {'n_denses_0':2,'n_denses_1':2,'n_denses_2':2,'n_denses_3':2}\n",
    "best_arch = best_archs_list[0]['Architecture'] if best_archs_list is not None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.create_model(best_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "runner.visualize_model(outfile_path=f\"training/figs/nas/nas_model_{APPROACH.name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "runner.model_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.draw_training_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.load_best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.set_model_evaluator_data_src(DataSource.VALIDATION)\n",
    "runner.test_model(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.set_model_evaluator_data_src(DataSource.TEST)\n",
    "runner.test_model(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Model Classification"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "runner.visualize_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finishing Experiment Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.finish_experiment()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "85f5044ba23e75135dc4c908fd4d7609c1c80b195047fdb4d16ee0e66a953254"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "neptune": {
   "notebookId": "98a3967a-428e-4576-add1-6bd753600673",
   "projectVersion": 2
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
