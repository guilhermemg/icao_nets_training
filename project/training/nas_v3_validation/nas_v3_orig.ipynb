{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Notebook para avaliação de NAS-v3 com dataset NATS-Bench-201."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# disable tensorflow log level infos\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # show only errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if '../..' not in sys.path:\n",
    "    sys.path.insert(0, '../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import nats_bench\n",
    "\n",
    "import numpy as np\n",
    "import pyglove as pg\n",
    "import tensorflow as tf\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> Restrict GPU memory growth: True\n"
     ]
    }
   ],
   "source": [
    "## restrict memory growth -------------------\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "try:\n",
    "    gpu_0 = physical_devices[0]\n",
    "    tf.config.experimental.set_memory_growth(gpu_0, True) \n",
    "    #tf.config.experimental.set_virtual_device_configuration(gpu_0, [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=6500)])\n",
    "    print(' ==> Restrict GPU memory growth: True')\n",
    "except: \n",
    "    raise Exception(\"Invalid device or cannot modify virtual devices once initialized.\")\n",
    "## restrict memory growth ------------------- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NASController_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, RNN, LSTMCell, Input\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "from src.base.experiment.training.optimizers import Optimizer\n",
    "from src.nas.v3.mlp_search_space import MLPSearchSpaceCandidate\n",
    "\n",
    "class NASController_4:\n",
    "    def __init__(self, config_interp):        \n",
    "        self.config_interp = config_interp\n",
    "        \n",
    "        self.controller_classes         = self.config_interp.controller_params['controller_classes']\n",
    "        self.controller_lstm_dim        = self.config_interp.controller_params['controller_lstm_dim']\n",
    "        self.controller_optimizer       = self.config_interp.controller_params['controller_optimizer']\n",
    "        self.controller_lr              = self.config_interp.controller_params['controller_learning_rate']\n",
    "        self.controller_decay           = self.config_interp.controller_params['controller_decay']\n",
    "        self.controller_momentum        = self.config_interp.controller_params['controller_momentum']\n",
    "        self.use_predictor              = self.config_interp.controller_params['controller_use_predictor']\n",
    "        self.controller_loss_alpha      = self.config_interp.controller_params['controller_loss_alpha']\n",
    "        self.controller_train_epochs    = self.config_interp.controller_params['controller_training_epochs']\n",
    "        self.controller_sampling_epochs = self.config_interp.controller_params['controller_sampling_epochs']\n",
    "        \n",
    "        self.max_proposed_arch_length = self.config_interp.nas_params['max_proposed_arch_length']\n",
    "        \n",
    "        self.controller_weights_path = 'LOGS/controller_weights.h5'\n",
    "\n",
    "        self.n_tasks = len(self.config_interp.tasks)\n",
    "        \n",
    "        self.controller_noise_dim = 4\n",
    "        self.controller_input_shape = (1, self.controller_classes+self.controller_noise_dim)\n",
    "        \n",
    "        self.controller_batch_size = self.config_interp.controller_params['controller_batch_size']\n",
    "\n",
    "        self.controller_use_predictor = self.config_interp.controller_params['controller_use_predictor']\n",
    "        \n",
    "        self.nas_data_history = None\n",
    "        self.search_space_candidates = MLPSearchSpaceCandidate.N_DENSES.value + MLPSearchSpaceCandidate.N_CONVS.value\n",
    "        self.search_space_candidates_size = len(self.search_space_candidates)\n",
    "\n",
    "        self.__clean_controller_weights()        \n",
    "\n",
    "        if not self.controller_use_predictor:\n",
    "            self.controller_model = self.__create_control_model()\n",
    "        else:\n",
    "            self.controller_model = self.__create_hybrid_control_model()\n",
    "\n",
    "\n",
    "    def __clean_controller_weights(self):\n",
    "        if os.path.exists(self.controller_weights_path):\n",
    "            os.remove(self.controller_weights_path)\n",
    "\n",
    "\n",
    "    def __check_nas_data_history(self, new_dna_value):\n",
    "        if self.nas_data_history is None:\n",
    "            return True\n",
    "        else:\n",
    "            for tup in self.nas_data_history:\n",
    "                existing_dna = tup[0].to_numbers()\n",
    "                new_dna_value_rep = list(new_dna_value[0][0])\n",
    "                #print(f' ..{existing_dna}, {new_dna_value_rep}')\n",
    "                if np.array_equal(existing_dna, new_dna_value_rep):\n",
    "                    #print(f' ...Invalid DNA -> existing_dna: {existing_dna} | new_dna_value: {new_dna_value_rep}')\n",
    "                    #print(f' ....Proposing new architecture!')\n",
    "                    return False\n",
    "            #print(f' ..New valid DNA: {new_dna_value}')\n",
    "            return True\n",
    "    \n",
    "            \n",
    "    def build_new_arch(self, prev_arch):\n",
    "        inp = np.array(prev_arch).reshape(1,1,self.max_proposed_arch_length)\n",
    "\n",
    "        # print(f' ..input: {inp}')\n",
    "\n",
    "        final_arch = []\n",
    "        for i in range(self.max_proposed_arch_length):\n",
    "            noise = np.random.randint(0, 10, size=4).reshape(1,1,4)\n",
    "            # print(f' ..noise: {noise}')\n",
    "\n",
    "            inp = np.concatenate([inp,noise], axis=2)\n",
    "\n",
    "            prob_list = self.controller_model.predict(inp)   # output: (1,1,n_classes+noise_dim)\n",
    "            prob_list = prob_list[0][0]\n",
    "            \n",
    "            chose_idx = np.argmax(prob_list)  # choose from the first part of the list (5 classes)\n",
    "            \n",
    "            final_arch.append(int(chose_idx))\n",
    "            # print(f'final_arch: {final_arch}')\n",
    "\n",
    "            new_arch = pad_sequences([final_arch], maxlen=self.max_proposed_arch_length, padding='post', value=-1)\n",
    "            # print(new_arch.shape)\n",
    "\n",
    "            inp = np.array(new_arch).reshape(1,1,self.max_proposed_arch_length)\n",
    "            # print(f' ..new input: {inp}')\n",
    "        \n",
    "        final_arch = [[final_arch]]\n",
    "        # print(f' .final_arch: {final_arch}')\n",
    "        \n",
    "        # if not self.__check_nas_data_history(prev_arch):\n",
    "        #     print(' ..redoing proposal')\n",
    "        #     self.build_new_arch(prev_arch)   # redo the process if architecture already exists\n",
    "\n",
    "        return final_arch\n",
    "\n",
    "\n",
    "    def __prepare_controller_data(self, nas_data_history):\n",
    "        self.nas_data_history = nas_data_history\n",
    "\n",
    "        # print('Preparing controller data...')\n",
    "        # print(f' ..nas_data_history: {nas_data_history}')\n",
    "        \n",
    "        xc = np.array([[item[0].to_numbers() for item in nas_data_history]])       \n",
    "        xc = xc.reshape(self.controller_batch_size, 1, self.controller_classes)\n",
    "        # print(f' ..xc.shape: {xc.shape}')\n",
    "\n",
    "        noise = np.random.randint(0, 10, size=(self.controller_batch_size, 1, self.controller_noise_dim))\n",
    "        xc = np.concatenate([xc, noise], axis=2)\n",
    "        # print(f' ..xc + noise.shape: {xc.shape}')\n",
    "\n",
    "        #yc = to_categorical(controller_sequences[:, -1], self.controller_classes)\n",
    "        yc = np.zeros((self.controller_batch_size, 1, self.controller_classes))\n",
    "        # print(f' ..yc.shape: {yc.shape}')\n",
    "        \n",
    "        val_acc_target = [item[1] for item in nas_data_history]\n",
    "        # print(f' ..val_acc_target.length: {len(val_acc_target)}')\n",
    "        \n",
    "        # print(' ..done!')\n",
    "        \n",
    "        return xc, yc, val_acc_target\n",
    "\n",
    "\n",
    "    def get_discounted_reward(self, rewards):\n",
    "        # initialise discounted reward array\n",
    "        discounted_r = np.zeros_like(rewards, dtype=np.float32)\n",
    "\n",
    "        # every element in the discounted reward array\n",
    "        for t in range(len(rewards)):\n",
    "            running_add = 0.\n",
    "            exp = 0.\n",
    "\n",
    "            # will need us to iterate over all rewards from t to T\n",
    "            for r in rewards[t:]:\n",
    "                running_add += self.controller_loss_alpha**exp * r\n",
    "                exp += 1\n",
    "            \n",
    "            # add values to the discounted reward array\n",
    "            discounted_r[t] = running_add\n",
    "\n",
    "        # normalize discounted reward array    \n",
    "        discounted_r = (discounted_r - discounted_r.mean()) / discounted_r.std()\n",
    "\n",
    "        return discounted_r\n",
    "\n",
    "\n",
    "    # loss function based on discounted reward for policy gradients\n",
    "    def custom_loss(self, target, output):\n",
    "        # define baseline for rewards and subtract it from all validation accuracies to get reward.\n",
    "        baseline = 0.5\n",
    "        reward = np.array([item[1] - baseline for item in self.nas_data_history[-self.controller_batch_size:]]).reshape(\n",
    "           self.controller_batch_size, 1)\n",
    "        \n",
    "        # get discounted reward\n",
    "        discounted_reward = self.get_discounted_reward(reward)\n",
    "\n",
    "        # multiply discounted reward by log likelihood of actions to get loss function\n",
    "        loss = - K.log(output) * discounted_reward[:, None]\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def train_model_controller(self, nas_data_history):\n",
    "        # print(' ..Training controller model...')\n",
    "\n",
    "        nas_data_history = nas_data_history[-self.controller_batch_size:]\n",
    "\n",
    "        xc, yc, val_acc_target = self.__prepare_controller_data(nas_data_history)\n",
    "\n",
    "        if self.use_predictor:\n",
    "            self.__train_hybrid_control_model(\n",
    "                                            xc,\n",
    "                                            yc,\n",
    "                                            val_acc_target,\n",
    "                                            self.custom_loss,\n",
    "                                            self.controller_batch_size,\n",
    "                                            self.controller_train_epochs)\n",
    "        else:\n",
    "            self.__train_control_model(\n",
    "                                     xc,\n",
    "                                     yc,\n",
    "                                     self.custom_loss,\n",
    "                                     self.controller_batch_size,\n",
    "                                     self.controller_train_epochs)\n",
    "        \n",
    "        # print(' ..Controller model trained!')\n",
    "\n",
    "\n",
    "    def __get_optimizer(self):\n",
    "        if self.controller_optimizer.name == Optimizer.SGD.name:\n",
    "            optim = optimizers.SGD(learning_rate=self.controller_lr, decay=self.controller_decay, momentum=self.controller_momentum, clipnorm=1.0)\n",
    "        elif self.controller_optimizer.name == Optimizer.SGD_NESTEROV.name:\n",
    "            optim = optimizers.SGD(learning_rate=self.controller_lr, decay=self.controller_decay, momentum=self.controller_momentum, nesterov=True, clipnorm=1.0)\n",
    "        else:\n",
    "            optim = getattr(optimizers, self.controller_optimizer.value)(learning_rate=self.controller_lr, decay=self.controller_decay, clipnorm=1.0)\n",
    "        return optim\n",
    "\n",
    "\n",
    "    def __create_control_model(self):\n",
    "        main_input = Input(shape=self.controller_input_shape, name='main_input')        \n",
    "        # print(f'Controller model input shape: {main_input.shape}')\n",
    "        x = RNN(LSTMCell(self.controller_lstm_dim), return_sequences=True)(main_input)\n",
    "        main_output = Dense(self.controller_classes, activation='softmax', name='main_output')(x)\n",
    "        # print(f'Controller model output shape: {main_output.shape}')\n",
    "        model = Model(inputs=[main_input], outputs=[main_output])\n",
    "        return model\n",
    "\n",
    "\n",
    "    def __train_control_model(self, x_data, y_data, loss_func, controller_batch_size, nb_epochs):\n",
    "        optim = self.__get_optimizer()\n",
    "        \n",
    "        self.controller_model.compile(optimizer=optim, loss={'main_output': loss_func})\n",
    "        \n",
    "        if os.path.exists(self.controller_weights_path):\n",
    "            self.controller_model.load_weights(self.controller_weights_path)\n",
    "        \n",
    "        # print(\"TRAINING CONTROLLER...\")\n",
    "        \n",
    "        self.controller_model.fit({'main_input': x_data},\n",
    "                  {'main_output': y_data.reshape(len(y_data), 1, self.controller_classes)},\n",
    "                  epochs=nb_epochs,\n",
    "                  batch_size=controller_batch_size,\n",
    "                  verbose=0)\n",
    "        \n",
    "        self.controller_model.save_weights(self.controller_weights_path)\n",
    "\n",
    "\n",
    "    # ------------------- Hybrid Model -------------------\n",
    "\n",
    "    \n",
    "    def __create_hybrid_control_model(self):\n",
    "        main_input = Input(shape=self.controller_input_shape, name='main_input')\n",
    "        x = RNN(LSTMCell(self.controller_lstm_dim), return_sequences=True)(main_input)\n",
    "        predictor_output = Dense(1, activation='sigmoid', name='predictor_output')(x)\n",
    "        main_output = Dense(self.controller_classes, activation='softmax', name='main_output')(x)\n",
    "        model = Model(inputs=[main_input], outputs=[main_output, predictor_output])\n",
    "        return model\n",
    "\n",
    "\n",
    "    def __train_hybrid_control_model(self, x_data, y_data, pred_target, loss_func, controller_batch_size, nb_epochs):\n",
    "\n",
    "        optim = self.__get_optimizer()\n",
    "        \n",
    "        self.controller_model.compile(optimizer=optim,\n",
    "                      loss={'main_output': loss_func, 'predictor_output': 'mse'},\n",
    "                      loss_weights={'main_output': 1, 'predictor_output': 1})\n",
    "        \n",
    "        if os.path.exists(self.controller_weights_path):\n",
    "            self.controller_model.load_weights(self.controller_weights_path)\n",
    "        \n",
    "        print(\"TRAINING CONTROLLER...\")\n",
    "        \n",
    "        self.controller_model.fit({'main_input': x_data},\n",
    "                  {'main_output': y_data.reshape(len(y_data), 1, self.controller_classes),\n",
    "                   'predictor_output': np.array(pred_target).reshape(len(pred_target), 1, 1)},\n",
    "                  epochs=nb_epochs,\n",
    "                  batch_size=controller_batch_size,\n",
    "                  verbose=0)\n",
    "        \n",
    "        self.controller_model.save_weights(self.controller_weights_path)\n",
    "\n",
    "    \n",
    "    def get_predicted_accuracies_hybrid_model(self, model, seqs):\n",
    "        pred_accuracies = []\n",
    "        for seq in seqs:\n",
    "            control_sequences = pad_sequences([seq], maxlen=self.controller_classes, padding='post')\n",
    "            xc = control_sequences[:, :-1].reshape(len(control_sequences), 1, self.controller_classes - 1)\n",
    "            (_, pred_accuracy) = [x[0][0] for x in model.predict(xc)]\n",
    "            pred_accuracies.append(pred_accuracy[0])\n",
    "        return pred_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ConfigInterp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pprint\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from src.m_utils.nas_mtl_approach import NAS_MTLApproach\n",
    "from src.m_utils.mtl_approach import MTLApproach\n",
    "from src.m_utils.stl_approach import STLApproach\n",
    "from src.m_utils.utils import print_method_log_sig\n",
    "from src.base.experiment.dataset.dataset import Dataset\n",
    "from src.base.experiment.tasks.task import TASK\n",
    "\n",
    "class ConfigInterpreter:\n",
    "    def __init__(self, kwargs, yaml_config_file=None):\n",
    "        if yaml_config_file != None:\n",
    "            kwargs = self.__load_exp_config(yaml_config_file)\n",
    "\n",
    "        self.use_neptune = kwargs['use_neptune']\n",
    "        print('-----')\n",
    "        print('Use Neptune: ', self.use_neptune)\n",
    "        print('-----')\n",
    "        \n",
    "        print('-------------------')\n",
    "        print('Args: ')\n",
    "        pprint.pprint(kwargs)\n",
    "        print('-------------------')\n",
    "        \n",
    "        self.exp_args = kwargs['exp_params']\n",
    "        self.prop_args = kwargs['properties']\n",
    "        \n",
    "        self.mlp_params = kwargs['mlp_params']\n",
    "\n",
    "        self.nas_params = kwargs['nas_params']\n",
    "        self.controller_params = kwargs['controller_params']\n",
    "        \n",
    "        self.__kwargs_sanity_check()\n",
    "\n",
    "        self.dataset : Dataset = self.prop_args['dataset']\n",
    "        self.tasks : List[TASK] = self.prop_args['tasks']\n",
    "\n",
    "        self.base_model = self.mlp_params['mlp_base_model']\n",
    "        print('----')\n",
    "        print('Base Model Name: ', self.base_model)\n",
    "        print('----')\n",
    "\n",
    "        self.is_mtl_model = self.__get_is_mtl_model()\n",
    "        self.approach = self.__get_approach()\n",
    "        self.is_nas_mtl_model = self.__get_is_nas_mtl_model()\n",
    "        self.exec_nas = self.prop_args['exec_nas']\n",
    "        \n",
    "        print('----')\n",
    "\n",
    "\n",
    "    def __get_approach(self):\n",
    "        approach = self.prop_args['approach']\n",
    "\n",
    "        if len(self.tasks) == 1:\n",
    "            assert isinstance(approach, STLApproach)\n",
    "        elif len(self.tasks) > 1:\n",
    "            assert isinstance(approach, MTLApproach) or isinstance(approach, NAS_MTLApproach)\n",
    "        else:\n",
    "            raise Exception('Invalid approach')\n",
    "\n",
    "        print(f'Approach: {approach}')\n",
    "\n",
    "        return approach\n",
    "    \n",
    "\n",
    "    def __get_is_mtl_model(self):\n",
    "        is_mtl_model = len(self.tasks) > 1\n",
    "        print(f'MTL Model: {is_mtl_model}')\n",
    "        return is_mtl_model\n",
    "    \n",
    "\n",
    "    def __get_is_nas_mtl_model(self):\n",
    "        is_nas_mtl_model = len(self.tasks) > 1 and self.prop_args['exec_nas']\n",
    "        print(f'NAS MTL Model: {is_nas_mtl_model}')\n",
    "        return is_nas_mtl_model\n",
    "\n",
    "\n",
    "    def __load_exp_config(self, yaml_config_file):\n",
    "        print_method_log_sig('load experiment configs')\n",
    "        print(f'Loading experiment config from {yaml_config_file}')\n",
    "        with open(yaml_config_file, 'r') as f:\n",
    "            cnt = yaml.load(f, Loader=yaml.Loader)[0]\n",
    "            print('..Experiment configs loaded with success!')\n",
    "            return cnt\n",
    "    \n",
    "\n",
    "    def __kwargs_sanity_check(self):\n",
    "        has_experiment_id = True if self.prop_args['orig_model_experiment_id'] != '' else False\n",
    "        is_training_new_model = self.prop_args['train_model']\n",
    "        \n",
    "        if not has_experiment_id and not is_training_new_model:\n",
    "            raise Exception('You must train a new model or provide an experiment ID')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from src.nas.v3.nas_algorithm import NASAlgorithm\n",
    "from src.nas.v3.mlp_search_space import MLPSearchSpaceIndicator\n",
    "from src.base.experiment.training.optimizers import Optimizer\n",
    "from src.base.experiment.training.base_models import BaseModel\n",
    "\n",
    "\n",
    "DATASET = Dataset.MNIST\n",
    "APPROACH = NAS_MTLApproach.APPROACH_3\n",
    "\n",
    "kwargs = { \n",
    "    'use_neptune': False,\n",
    "    'exp_params' : {\n",
    "        'name': 'NAS experiment',\n",
    "        'description': 'NAS with Approach 3 - Testing parametrization of n_convs',\n",
    "        'tags': [f'{DATASET.value[\"name\"]}', 'nas', 'nas_approach_3_v2', 'no_use_predictor'],\n",
    "        'src_files': [\"../src/**/*.py\"]\n",
    "    },\n",
    "    'properties': {\n",
    "        'approach': APPROACH,\n",
    "        'dataset': DATASET,\n",
    "        'tasks': DATASET.value['tasks'],\n",
    "        'balance_input_data': False,\n",
    "        'train_model': True,\n",
    "        'save_trained_model': True,\n",
    "        'exec_nas': True,\n",
    "        'orig_model_experiment_id': '',\n",
    "        'sample_training_data': True,\n",
    "        'sample_prop': 0.02\n",
    "    },\n",
    "    'nas_params': {\n",
    "        'architecture_training_epochs': 2,     # n_epochs for training proposed architecture\n",
    "        'max_proposed_arch_length': 5,\n",
    "        'total_num_proposed_architectures': 10,\n",
    "        'nas_algorithm': NASAlgorithm.RL,\n",
    "        'nas_search_space': MLPSearchSpaceIndicator.SS_2\n",
    "    },\n",
    "    'controller_params': {\n",
    "        'controller_classes': 7,\n",
    "        'controller_lstm_dim': 100,\n",
    "        'controller_optimizer': Optimizer.ADAM,\n",
    "        'controller_learning_rate': 0.01,\n",
    "        'controller_decay': 0.1,\n",
    "        'controller_momentum': 0.0,\n",
    "        'controller_use_predictor': False,\n",
    "        'controller_loss_alpha': 0.9,\n",
    "        'controller_training_epochs': 5,\n",
    "        'controller_sampling_epochs': 6,\n",
    "        'controller_batch_size': 64\n",
    "    },\n",
    "    'mlp_params': {\n",
    "        'mlp_base_model': BaseModel.MOBILENET_V2,\n",
    "        'mlp_n_epochs': 50,\n",
    "        'mlp_batch_size': 64,\n",
    "        'mlp_early_stopping': 50,\n",
    "        'mlp_optimizer': Optimizer.ADAMAX,\n",
    "        'mlp_learning_rate': 1e-3,\n",
    "        'mlp_decay': 0.0,\n",
    "        'mlp_momentum': 0.0,\n",
    "        'mlp_dropout': 0.3,\n",
    "        'mlp_loss_function': 'sparse_categorical_crossentropy',\n",
    "        'mlp_one_shot': False\n",
    "    }\n",
    "}\n",
    "\n",
    "config_interp = ConfigInterpreter(kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RL_DNAGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pyglove as pg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class RL_DNAGenerator(pg.generators.geno.DNAGenerator):\n",
    "    def __init__(self, config_interp: ConfigInterpreter):\n",
    "        self.nas_history_data : list = []\n",
    "        self.nas_controller: NASController_4 = NASController_4(config_interp)\n",
    "        self.nas_data_log_path = 'LOGS/nas_data.csv'\n",
    "\n",
    "\n",
    "    def _feedback(self, dna, reward):\n",
    "        self.nas_history_data.append([dna,reward])\n",
    "        \n",
    "        #print(f' ..nas_history_data: {self.nas_history_data}')\n",
    "        #print(f' ..len(self.nas_history_data): {len(self.nas_history_data)}')\n",
    "\n",
    "        self.__log_data()\n",
    "\n",
    "    \n",
    "    def __log_data(self):\n",
    "        # print(f' ..Logging nas_history_data...')\n",
    "        # print(f' ..self.nas_history_data: {self.nas_history_data}')\n",
    "        # print(f' ..nas_data_log_path: {self.nas_data_log_path}')\n",
    "        df = pd.DataFrame(data=self.nas_history_data, columns=['dna', 'reward'])\n",
    "        df.to_csv(self.nas_data_log_path, index=False)\n",
    "        # print(' ..done!')\n",
    "\n",
    "\n",
    "    def _propose(self):\n",
    "        if self.num_feedbacks % self.nas_controller.controller_batch_size == 0 and self.num_feedbacks > 0:\n",
    "            # print(70*'.')\n",
    "            # print(' ..New batch of architectures. Training controller model...')\n",
    "            self.nas_controller.train_model_controller(self.nas_history_data)    \n",
    "            # print(70*'.')\n",
    "        \n",
    "        prev_arch = None\n",
    "        if self.num_feedbacks > 0:\n",
    "            prev_arch = self.nas_history_data[-1][0].to_numbers()\n",
    "        else:\n",
    "            prev_arch = [random.randint(0,10) for _ in range(self.nas_controller.max_proposed_arch_length)]\n",
    "\n",
    "        prev_arch = np.array(prev_arch).reshape(1,1,self.nas_controller.max_proposed_arch_length)\n",
    "\n",
    "        # print(f' ..prev_arch: {prev_arch}')\n",
    "        # print(f' ..prev_arch.shape: {prev_arch.shape}')\n",
    "\n",
    "        new_arch = self.nas_controller.build_new_arch(prev_arch)\n",
    "        \n",
    "        return pg.geno.DNA(new_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Utilitary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEFAULT_NATS_FILEs = dict(tss=None, sss=None)\n",
    "DEFAULT_REPORTING_EPOCH = dict(tss=200, sss=90)\n",
    "VALIDATION_SET_REPORTING_EPOCH = 12\n",
    "\n",
    "\n",
    "@pg.functor([('channels', pg.typing.List(pg.typing.Int()))])\n",
    "def model_sss_spc(channels):\n",
    "    return ':'.join(str(x) for x in channels)\n",
    "\n",
    "\n",
    "def get_search_space(ss_indicator):\n",
    "    info = nats_bench.search_space_info('nats-bench', ss_indicator)\n",
    "    print(f'Candidates: {info[\"candidates\"]}')\n",
    "    if ss_indicator == 'sss':\n",
    "        return model_sss_spc(pg.sublist_of(info['num_layers'], info['candidates'], choices_distinct=False))\n",
    "\n",
    "    \n",
    "def get_algorithm(algorithm_str):\n",
    "    \"\"\"Creates algorithm.\"\"\"\n",
    "    if algorithm_str == 'random':\n",
    "        return pg.generators.Random()\n",
    "    elif algorithm_str == 'evolution':\n",
    "        return pg.evolution.regularized_evolution(mutator=pg.evolution.mutators.Uniform(), population_size=50, tournament_size=10)\n",
    "    elif algorithm_str == 'rl':\n",
    "        return RL_DNAGenerator(config_interp)\n",
    "    else:\n",
    "        return pg.load(algorithm_str)\n",
    "    \n",
    "\n",
    "def search(nats_api, search_model, algo, dataset='cifar10', reporting_epoch=12, max_train_hours=2e4):\n",
    "    nats_api.reset_time()\n",
    "    valid_models = 0\n",
    "    time_spent_in_secs = 0\n",
    "    start_time = time.time()\n",
    "    last_report_time = start_time\n",
    "    \n",
    "    results_df = pd.DataFrame(columns=['id','dna','cell_spec',\n",
    "                                       'val_acc','latency','time_cost','total_time',\n",
    "                                       'test_acc','test_loss','test_per_time','test_all_time',\n",
    "                                       'time_spent_in_hours','time_spent_in_secs',\n",
    "                                       'train_accuracy','train_loss','train_per_time','train_all_time',\n",
    "                                       'comment'])\n",
    "    \n",
    "    for model, feedback in pg.sample(search_model, algo):\n",
    "        spec = model()\n",
    "        \n",
    "        (validation_accuracy, latency, time_cost, total_time) = nats_api.simulate_train_eval(spec, dataset=dataset, hp=VALIDATION_SET_REPORTING_EPOCH)\n",
    "        \n",
    "        time_spent_in_secs = nats_api.used_time\n",
    "        \n",
    "        more_info = nats_api.get_more_info(spec, dataset, hp=reporting_epoch)  # pytype: disable=wrong-arg-types  # dict-kwargs\n",
    "        \n",
    "        valid_models += 1\n",
    "        \n",
    "        feedback(validation_accuracy)\n",
    "        \n",
    "        time_spent_in_hours = time_spent_in_secs / (60 * 60)\n",
    "        \n",
    "        if time_spent_in_hours > max_train_hours:\n",
    "            break # Break the first time we exceed the budget.\n",
    "        \n",
    "        if feedback.id % 100 == 0:\n",
    "            now = time.time()\n",
    "            print(f'Tried {feedback.id} models, valid {valid_models}, '\n",
    "                  f'time_spent_in_hours: {int(time_spent_in_hours)}h, '\n",
    "                  f'time_spent_in_secs: {round(time_spent_in_secs,3)}s, '\n",
    "                  f'elapse since last report: {round(now - last_report_time,3)}s.')\n",
    "            last_report_time = now\n",
    "        \n",
    "        formatted_spec = ':'.join(['{:02d}'.format(int(x)) for x in spec.split(':')])\n",
    "        #print(f'Cell-spec: {formatted_spec} | ID: {feedback.id} | DNA: {feedback.dna} | Validation Acc: {validation_accuracy}')\n",
    "        \n",
    "        results_df.loc[len(results_df)] = {'id': feedback.id,\n",
    "                                           'cell_spec': formatted_spec, \n",
    "                                           'dna': feedback.dna, \n",
    "                                           'val_acc': validation_accuracy, \n",
    "                                           'latency': latency,\n",
    "                                           'time_cost': time_cost,\n",
    "                                           'total_time': total_time,\n",
    "                                           'test_acc': more_info['test-accuracy'],\n",
    "                                           'test_loss': more_info['test-loss'],\n",
    "                                           'test_per_time': more_info['test-per-time'],\n",
    "                                           'test_all_time': more_info['test-all-time'],\n",
    "                                           'time_spent_in_secs': round(time_spent_in_secs,3),\n",
    "                                           'time_spent_in_hours': int(time_spent_in_hours),\n",
    "                                           'train_loss': more_info['train-loss'],\n",
    "                                           'train_accuracy': more_info['train-accuracy'],\n",
    "                                           'train_per_time': more_info['train-per-time'],\n",
    "                                           'train_all_time': more_info['train-all-time'],\n",
    "                                           'comment': more_info['comment']}\n",
    "        \n",
    "            \n",
    "    print(f'Total time elapse: {time.time() - start_time} seconds.')\n",
    "    \n",
    "    return results_df\n",
    "    \n",
    "    \n",
    "def test_nas_algo(algo_name):\n",
    "    SEARCH_SPACE = 'sss'    \n",
    "    \n",
    "    nats_bench.api_utils.reset_file_system('default')\n",
    "    nats_api = nats_bench.create(DEFAULT_NATS_FILEs[SEARCH_SPACE], SEARCH_SPACE, fast_mode=True, verbose=False)\n",
    "\n",
    "    search_model = get_search_space(SEARCH_SPACE)\n",
    "    reporting_epoch = DEFAULT_REPORTING_EPOCH[SEARCH_SPACE]\n",
    "\n",
    "    algorithm = get_algorithm(algo_name)\n",
    "\n",
    "    results_df = search(nats_api, search_model, algorithm, 'cifar10', reporting_epoch, max_train_hours=3)\n",
    "    \n",
    "    sorted_results = results_df.sort_values(by='val_acc', ascending=False)\n",
    "    \n",
    "    return sorted_results\n",
    "    \n",
    "    \n",
    "def print_report(sorted_results_df):\n",
    "    n_trials = len(sorted_results_df)\n",
    "    print(f'Best architecture found after {n_trials} evaluated models!')\n",
    "    print('Best model found: ')\n",
    "    display(sorted_results_df.iloc[:,:13].head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests NAS ALgorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test with Random Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-28 00:45:16] Try to use the default NATS-Bench (size) path from fast_mode=True and path=None.\n",
      "Candidates: [8, 16, 24, 32, 40, 48, 56, 64]\n",
      "Tried 100 models, valid 100, time_spent_in_hours: 1h, time_spent_in_secs: 5173.49s, elapse since last report: 1.801s.\n",
      "Tried 200 models, valid 200, time_spent_in_hours: 2h, time_spent_in_secs: 10469.77s, elapse since last report: 1.82s.\n",
      "Tried 300 models, valid 300, time_spent_in_hours: 4h, time_spent_in_secs: 15685.205s, elapse since last report: 1.835s.\n",
      "Tried 400 models, valid 400, time_spent_in_hours: 5h, time_spent_in_secs: 20946.303s, elapse since last report: 1.848s.\n",
      "Tried 500 models, valid 500, time_spent_in_hours: 7h, time_spent_in_secs: 26271.46s, elapse since last report: 1.847s.\n",
      "Tried 600 models, valid 600, time_spent_in_hours: 8h, time_spent_in_secs: 31490.496s, elapse since last report: 1.788s.\n",
      "Tried 700 models, valid 700, time_spent_in_hours: 10h, time_spent_in_secs: 36832.76s, elapse since last report: 2.441s.\n",
      "Tried 800 models, valid 800, time_spent_in_hours: 11h, time_spent_in_secs: 42062.001s, elapse since last report: 1.836s.\n",
      "Tried 900 models, valid 900, time_spent_in_hours: 13h, time_spent_in_secs: 47352.704s, elapse since last report: 1.802s.\n",
      "Tried 1000 models, valid 1000, time_spent_in_hours: 14h, time_spent_in_secs: 52702.387s, elapse since last report: 1.794s.\n",
      "Tried 1100 models, valid 1100, time_spent_in_hours: 16h, time_spent_in_secs: 57772.637s, elapse since last report: 1.8s.\n",
      "Tried 1200 models, valid 1200, time_spent_in_hours: 17h, time_spent_in_secs: 63073.274s, elapse since last report: 1.843s.\n",
      "Tried 1300 models, valid 1300, time_spent_in_hours: 18h, time_spent_in_secs: 68349.743s, elapse since last report: 1.847s.\n",
      "Tried 1400 models, valid 1400, time_spent_in_hours: 20h, time_spent_in_secs: 73545.649s, elapse since last report: 1.814s.\n",
      "Tried 1500 models, valid 1500, time_spent_in_hours: 21h, time_spent_in_secs: 78862.923s, elapse since last report: 1.842s.\n",
      "Tried 1600 models, valid 1600, time_spent_in_hours: 23h, time_spent_in_secs: 83949.314s, elapse since last report: 1.858s.\n",
      "Tried 1700 models, valid 1700, time_spent_in_hours: 24h, time_spent_in_secs: 89198.036s, elapse since last report: 1.798s.\n",
      "Tried 1800 models, valid 1800, time_spent_in_hours: 26h, time_spent_in_secs: 94247.467s, elapse since last report: 1.812s.\n",
      "Tried 1900 models, valid 1900, time_spent_in_hours: 27h, time_spent_in_secs: 99579.465s, elapse since last report: 2.582s.\n",
      "Tried 2000 models, valid 2000, time_spent_in_hours: 29h, time_spent_in_secs: 104820.615s, elapse since last report: 1.795s.\n",
      "Tried 2100 models, valid 2100, time_spent_in_hours: 30h, time_spent_in_secs: 109966.163s, elapse since last report: 1.781s.\n",
      "Tried 2200 models, valid 2200, time_spent_in_hours: 31h, time_spent_in_secs: 115187.458s, elapse since last report: 1.787s.\n",
      "Tried 2300 models, valid 2300, time_spent_in_hours: 33h, time_spent_in_secs: 120499.047s, elapse since last report: 1.852s.\n",
      "Tried 2400 models, valid 2400, time_spent_in_hours: 34h, time_spent_in_secs: 125813.352s, elapse since last report: 1.859s.\n",
      "Tried 2500 models, valid 2500, time_spent_in_hours: 36h, time_spent_in_secs: 131143.424s, elapse since last report: 1.8s.\n",
      "Tried 2600 models, valid 2600, time_spent_in_hours: 37h, time_spent_in_secs: 136507.115s, elapse since last report: 1.842s.\n",
      "Tried 2700 models, valid 2700, time_spent_in_hours: 39h, time_spent_in_secs: 141764.646s, elapse since last report: 1.826s.\n",
      "Tried 2800 models, valid 2800, time_spent_in_hours: 40h, time_spent_in_secs: 147210.21s, elapse since last report: 1.946s.\n",
      "Tried 2900 models, valid 2900, time_spent_in_hours: 42h, time_spent_in_secs: 152462.091s, elapse since last report: 1.921s.\n",
      "Tried 3000 models, valid 3000, time_spent_in_hours: 43h, time_spent_in_secs: 157682.452s, elapse since last report: 1.959s.\n",
      "Tried 3100 models, valid 3100, time_spent_in_hours: 45h, time_spent_in_secs: 163060.456s, elapse since last report: 1.911s.\n",
      "Tried 3200 models, valid 3200, time_spent_in_hours: 46h, time_spent_in_secs: 168399.734s, elapse since last report: 1.894s.\n",
      "Tried 3300 models, valid 3300, time_spent_in_hours: 48h, time_spent_in_secs: 173729.031s, elapse since last report: 2.881s.\n",
      "Tried 3400 models, valid 3400, time_spent_in_hours: 49h, time_spent_in_secs: 179168.729s, elapse since last report: 1.887s.\n",
      "Tried 3500 models, valid 3500, time_spent_in_hours: 51h, time_spent_in_secs: 184354.103s, elapse since last report: 1.874s.\n",
      "Tried 3600 models, valid 3600, time_spent_in_hours: 52h, time_spent_in_secs: 189449.697s, elapse since last report: 1.808s.\n",
      "Tried 3700 models, valid 3700, time_spent_in_hours: 54h, time_spent_in_secs: 194708.586s, elapse since last report: 1.837s.\n",
      "Tried 3800 models, valid 3800, time_spent_in_hours: 55h, time_spent_in_secs: 199981.692s, elapse since last report: 1.848s.\n",
      "Tried 3900 models, valid 3900, time_spent_in_hours: 57h, time_spent_in_secs: 205353.388s, elapse since last report: 1.858s.\n",
      "Tried 4000 models, valid 4000, time_spent_in_hours: 58h, time_spent_in_secs: 210681.204s, elapse since last report: 1.866s.\n",
      "Tried 4100 models, valid 4100, time_spent_in_hours: 59h, time_spent_in_secs: 215930.456s, elapse since last report: 1.889s.\n",
      "Tried 4200 models, valid 4200, time_spent_in_hours: 61h, time_spent_in_secs: 221146.433s, elapse since last report: 1.94s.\n",
      "Tried 4300 models, valid 4300, time_spent_in_hours: 62h, time_spent_in_secs: 226468.66s, elapse since last report: 1.93s.\n",
      "Tried 4400 models, valid 4400, time_spent_in_hours: 64h, time_spent_in_secs: 231727.169s, elapse since last report: 2.262s.\n",
      "Tried 4500 models, valid 4500, time_spent_in_hours: 65h, time_spent_in_secs: 237070.24s, elapse since last report: 1.91s.\n",
      "Tried 4600 models, valid 4600, time_spent_in_hours: 67h, time_spent_in_secs: 242309.1s, elapse since last report: 1.846s.\n",
      "Tried 4700 models, valid 4700, time_spent_in_hours: 68h, time_spent_in_secs: 247457.108s, elapse since last report: 1.85s.\n",
      "Tried 4800 models, valid 4800, time_spent_in_hours: 70h, time_spent_in_secs: 252650.714s, elapse since last report: 1.859s.\n",
      "Tried 4900 models, valid 4900, time_spent_in_hours: 71h, time_spent_in_secs: 257835.753s, elapse since last report: 1.871s.\n",
      "Tried 5000 models, valid 5000, time_spent_in_hours: 73h, time_spent_in_secs: 263257.225s, elapse since last report: 3.001s.\n",
      "Tried 5100 models, valid 5100, time_spent_in_hours: 74h, time_spent_in_secs: 268443.501s, elapse since last report: 1.903s.\n",
      "Tried 5200 models, valid 5200, time_spent_in_hours: 75h, time_spent_in_secs: 273553.018s, elapse since last report: 1.986s.\n",
      "Tried 5300 models, valid 5300, time_spent_in_hours: 77h, time_spent_in_secs: 278847.96s, elapse since last report: 1.917s.\n",
      "Tried 5400 models, valid 5400, time_spent_in_hours: 78h, time_spent_in_secs: 284212.961s, elapse since last report: 1.999s.\n",
      "Tried 5500 models, valid 5500, time_spent_in_hours: 80h, time_spent_in_secs: 289532.797s, elapse since last report: 1.919s.\n",
      "Tried 5600 models, valid 5600, time_spent_in_hours: 81h, time_spent_in_secs: 294781.034s, elapse since last report: 1.91s.\n",
      "Tried 5700 models, valid 5700, time_spent_in_hours: 83h, time_spent_in_secs: 300044.449s, elapse since last report: 1.926s.\n",
      "Tried 5800 models, valid 5800, time_spent_in_hours: 84h, time_spent_in_secs: 305296.928s, elapse since last report: 1.905s.\n",
      "Tried 5900 models, valid 5900, time_spent_in_hours: 86h, time_spent_in_secs: 310608.157s, elapse since last report: 1.89s.\n",
      "Tried 6000 models, valid 6000, time_spent_in_hours: 87h, time_spent_in_secs: 315881.213s, elapse since last report: 1.916s.\n",
      "Tried 6100 models, valid 6100, time_spent_in_hours: 89h, time_spent_in_secs: 321142.526s, elapse since last report: 1.996s.\n",
      "Tried 6200 models, valid 6200, time_spent_in_hours: 90h, time_spent_in_secs: 326413.215s, elapse since last report: 2.068s.\n",
      "Tried 6300 models, valid 6300, time_spent_in_hours: 92h, time_spent_in_secs: 331651.817s, elapse since last report: 2.037s.\n",
      "Tried 6400 models, valid 6400, time_spent_in_hours: 93h, time_spent_in_secs: 336964.381s, elapse since last report: 2.054s.\n",
      "Tried 6500 models, valid 6500, time_spent_in_hours: 95h, time_spent_in_secs: 342174.04s, elapse since last report: 2.039s.\n",
      "Tried 6600 models, valid 6600, time_spent_in_hours: 96h, time_spent_in_secs: 347335.934s, elapse since last report: 2.004s.\n",
      "Tried 6700 models, valid 6700, time_spent_in_hours: 97h, time_spent_in_secs: 352517.964s, elapse since last report: 2.037s.\n",
      "Tried 6800 models, valid 6800, time_spent_in_hours: 99h, time_spent_in_secs: 357815.462s, elapse since last report: 2.017s.\n",
      "Total time elapse: 132.78419661521912 seconds.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dna</th>\n",
       "      <th>cell_spec</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>latency</th>\n",
       "      <th>time_cost</th>\n",
       "      <th>total_time</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_per_time</th>\n",
       "      <th>test_all_time</th>\n",
       "      <th>time_spent_in_hours</th>\n",
       "      <th>time_spent_in_secs</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_per_time</th>\n",
       "      <th>train_all_time</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>2646</td>\n",
       "      <td>DNA([7, 7, 7, 6, 6])</td>\n",
       "      <td>64:64:64:56:56</td>\n",
       "      <td>85.020</td>\n",
       "      <td>0.020324</td>\n",
       "      <td>69.808378</td>\n",
       "      <td>138888.197737</td>\n",
       "      <td>93.18</td>\n",
       "      <td>0.261427</td>\n",
       "      <td>0.860657</td>\n",
       "      <td>77.459171</td>\n",
       "      <td>38</td>\n",
       "      <td>138888.198</td>\n",
       "      <td>99.910</td>\n",
       "      <td>0.007389</td>\n",
       "      <td>10.772471</td>\n",
       "      <td>969.522386</td>\n",
       "      <td>In this dict, train-loss/accuracy/time is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3336</th>\n",
       "      <td>3337</td>\n",
       "      <td>DNA([7, 7, 7, 6, 6])</td>\n",
       "      <td>64:64:64:56:56</td>\n",
       "      <td>85.020</td>\n",
       "      <td>0.020324</td>\n",
       "      <td>69.808378</td>\n",
       "      <td>175693.649063</td>\n",
       "      <td>93.18</td>\n",
       "      <td>0.261427</td>\n",
       "      <td>0.860657</td>\n",
       "      <td>77.459171</td>\n",
       "      <td>48</td>\n",
       "      <td>175693.649</td>\n",
       "      <td>99.910</td>\n",
       "      <td>0.007389</td>\n",
       "      <td>10.772471</td>\n",
       "      <td>969.522386</td>\n",
       "      <td>In this dict, train-loss/accuracy/time is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>3795</td>\n",
       "      <td>DNA([7, 7, 7, 7, 5])</td>\n",
       "      <td>64:64:64:64:48</td>\n",
       "      <td>84.672</td>\n",
       "      <td>0.020464</td>\n",
       "      <td>70.513710</td>\n",
       "      <td>199747.001945</td>\n",
       "      <td>93.45</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>0.845815</td>\n",
       "      <td>76.123366</td>\n",
       "      <td>55</td>\n",
       "      <td>199747.002</td>\n",
       "      <td>99.924</td>\n",
       "      <td>0.007676</td>\n",
       "      <td>10.850560</td>\n",
       "      <td>976.550417</td>\n",
       "      <td>In this dict, train-loss/accuracy/time is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2509</th>\n",
       "      <td>2510</td>\n",
       "      <td>DNA([7, 7, 6, 7, 6])</td>\n",
       "      <td>64:64:56:64:56</td>\n",
       "      <td>84.612</td>\n",
       "      <td>0.020573</td>\n",
       "      <td>71.375285</td>\n",
       "      <td>131691.330401</td>\n",
       "      <td>93.30</td>\n",
       "      <td>0.255049</td>\n",
       "      <td>0.859325</td>\n",
       "      <td>77.339222</td>\n",
       "      <td>36</td>\n",
       "      <td>131691.330</td>\n",
       "      <td>99.874</td>\n",
       "      <td>0.008999</td>\n",
       "      <td>11.038129</td>\n",
       "      <td>993.431597</td>\n",
       "      <td>In this dict, train-loss/accuracy/time is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6581</th>\n",
       "      <td>6582</td>\n",
       "      <td>DNA([7, 6, 7, 7, 4])</td>\n",
       "      <td>64:56:64:64:40</td>\n",
       "      <td>84.576</td>\n",
       "      <td>0.020175</td>\n",
       "      <td>70.785582</td>\n",
       "      <td>346486.535568</td>\n",
       "      <td>92.96</td>\n",
       "      <td>0.279243</td>\n",
       "      <td>0.866001</td>\n",
       "      <td>77.940080</td>\n",
       "      <td>96</td>\n",
       "      <td>346486.536</td>\n",
       "      <td>99.868</td>\n",
       "      <td>0.009217</td>\n",
       "      <td>10.970484</td>\n",
       "      <td>987.343562</td>\n",
       "      <td>In this dict, train-loss/accuracy/time is the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                   dna       cell_spec  val_acc   latency  \\\n",
       "2645  2646  DNA([7, 7, 7, 6, 6])  64:64:64:56:56   85.020  0.020324   \n",
       "3336  3337  DNA([7, 7, 7, 6, 6])  64:64:64:56:56   85.020  0.020324   \n",
       "3794  3795  DNA([7, 7, 7, 7, 5])  64:64:64:64:48   84.672  0.020464   \n",
       "2509  2510  DNA([7, 7, 6, 7, 6])  64:64:56:64:56   84.612  0.020573   \n",
       "6581  6582  DNA([7, 6, 7, 7, 4])  64:56:64:64:40   84.576  0.020175   \n",
       "\n",
       "      time_cost     total_time  test_acc  test_loss  test_per_time  \\\n",
       "2645  69.808378  138888.197737     93.18   0.261427       0.860657   \n",
       "3336  69.808378  175693.649063     93.18   0.261427       0.860657   \n",
       "3794  70.513710  199747.001945     93.45   0.251412       0.845815   \n",
       "2509  71.375285  131691.330401     93.30   0.255049       0.859325   \n",
       "6581  70.785582  346486.535568     92.96   0.279243       0.866001   \n",
       "\n",
       "      test_all_time time_spent_in_hours  time_spent_in_secs  train_accuracy  \\\n",
       "2645      77.459171                  38          138888.198          99.910   \n",
       "3336      77.459171                  48          175693.649          99.910   \n",
       "3794      76.123366                  55          199747.002          99.924   \n",
       "2509      77.339222                  36          131691.330          99.874   \n",
       "6581      77.940080                  96          346486.536          99.868   \n",
       "\n",
       "      train_loss  train_per_time  train_all_time  \\\n",
       "2645    0.007389       10.772471      969.522386   \n",
       "3336    0.007389       10.772471      969.522386   \n",
       "3794    0.007676       10.850560      976.550417   \n",
       "2509    0.008999       11.038129      993.431597   \n",
       "6581    0.009217       10.970484      987.343562   \n",
       "\n",
       "                                                comment  \n",
       "2645  In this dict, train-loss/accuracy/time is the ...  \n",
       "3336  In this dict, train-loss/accuracy/time is the ...  \n",
       "3794  In this dict, train-loss/accuracy/time is the ...  \n",
       "2509  In this dict, train-loss/accuracy/time is the ...  \n",
       "6581  In this dict, train-loss/accuracy/time is the ...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_results_rnd = test_nas_algo('random')\n",
    "sorted_results_rnd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dna</th>\n",
       "      <th>cell_spec</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>latency</th>\n",
       "      <th>time_cost</th>\n",
       "      <th>total_time</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_per_time</th>\n",
       "      <th>test_all_time</th>\n",
       "      <th>time_spent_in_hours</th>\n",
       "      <th>time_spent_in_secs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>2646</td>\n",
       "      <td>DNA([7, 7, 7, 6, 6])</td>\n",
       "      <td>64:64:64:56:56</td>\n",
       "      <td>85.02</td>\n",
       "      <td>0.020324</td>\n",
       "      <td>69.808378</td>\n",
       "      <td>138888.197737</td>\n",
       "      <td>93.18</td>\n",
       "      <td>0.261427</td>\n",
       "      <td>0.860657</td>\n",
       "      <td>77.459171</td>\n",
       "      <td>38</td>\n",
       "      <td>138888.198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                   dna       cell_spec  val_acc   latency  \\\n",
       "2645  2646  DNA([7, 7, 7, 6, 6])  64:64:64:56:56    85.02  0.020324   \n",
       "\n",
       "      time_cost     total_time  test_acc  test_loss  test_per_time  \\\n",
       "2645  69.808378  138888.197737     93.18   0.261427       0.860657   \n",
       "\n",
       "      test_all_time time_spent_in_hours  time_spent_in_secs  \n",
       "2645      77.459171                  38          138888.198  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_report(sorted_results_rnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_results_rnd.to_csv('data/random_100h.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test with Regularized Evolution Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-28 00:49:16] Try to use the default NATS-Bench (size) path from fast_mode=True and path=None.\n",
      "Candidates: [8, 16, 24, 32, 40, 48, 56, 64]\n",
      "Tried 100 models, valid 100, time_spent_in_hours: 1h, time_spent_in_secs: 5593.314s, elapse since last report: 1.766s.\n",
      "Tried 200 models, valid 200, time_spent_in_hours: 3h, time_spent_in_secs: 11795.439s, elapse since last report: 1.605s.\n",
      "Tried 300 models, valid 300, time_spent_in_hours: 5h, time_spent_in_secs: 18231.932s, elapse since last report: 1.51s.\n",
      "Tried 400 models, valid 400, time_spent_in_hours: 6h, time_spent_in_secs: 24663.906s, elapse since last report: 2.621s.\n",
      "Tried 500 models, valid 500, time_spent_in_hours: 8h, time_spent_in_secs: 31288.741s, elapse since last report: 1.518s.\n",
      "Tried 600 models, valid 600, time_spent_in_hours: 10h, time_spent_in_secs: 37791.194s, elapse since last report: 1.421s.\n",
      "Tried 700 models, valid 700, time_spent_in_hours: 12h, time_spent_in_secs: 44360.279s, elapse since last report: 1.45s.\n",
      "Tried 800 models, valid 800, time_spent_in_hours: 14h, time_spent_in_secs: 50627.941s, elapse since last report: 1.451s.\n",
      "Tried 900 models, valid 900, time_spent_in_hours: 15h, time_spent_in_secs: 57006.144s, elapse since last report: 1.462s.\n",
      "Tried 1000 models, valid 1000, time_spent_in_hours: 17h, time_spent_in_secs: 63558.715s, elapse since last report: 1.421s.\n",
      "Tried 1100 models, valid 1100, time_spent_in_hours: 19h, time_spent_in_secs: 70041.647s, elapse since last report: 1.503s.\n",
      "Tried 1200 models, valid 1200, time_spent_in_hours: 21h, time_spent_in_secs: 76535.044s, elapse since last report: 1.462s.\n",
      "Tried 1300 models, valid 1300, time_spent_in_hours: 23h, time_spent_in_secs: 83005.522s, elapse since last report: 1.439s.\n",
      "Tried 1400 models, valid 1400, time_spent_in_hours: 24h, time_spent_in_secs: 89272.53s, elapse since last report: 1.442s.\n",
      "Tried 1500 models, valid 1500, time_spent_in_hours: 26h, time_spent_in_secs: 95610.847s, elapse since last report: 1.462s.\n",
      "Tried 1600 models, valid 1600, time_spent_in_hours: 28h, time_spent_in_secs: 101862.175s, elapse since last report: 1.472s.\n",
      "Tried 1700 models, valid 1700, time_spent_in_hours: 30h, time_spent_in_secs: 108362.522s, elapse since last report: 1.41s.\n",
      "Tried 1800 models, valid 1800, time_spent_in_hours: 31h, time_spent_in_secs: 114687.22s, elapse since last report: 1.482s.\n",
      "Tried 1900 models, valid 1900, time_spent_in_hours: 33h, time_spent_in_secs: 120914.126s, elapse since last report: 1.554s.\n",
      "Tried 2000 models, valid 2000, time_spent_in_hours: 35h, time_spent_in_secs: 127162.642s, elapse since last report: 1.534s.\n",
      "Tried 2100 models, valid 2100, time_spent_in_hours: 37h, time_spent_in_secs: 133627.369s, elapse since last report: 1.434s.\n",
      "Tried 2200 models, valid 2200, time_spent_in_hours: 38h, time_spent_in_secs: 140122.387s, elapse since last report: 1.499s.\n",
      "Tried 2300 models, valid 2300, time_spent_in_hours: 40h, time_spent_in_secs: 146600.239s, elapse since last report: 1.52s.\n",
      "Tried 2400 models, valid 2400, time_spent_in_hours: 42h, time_spent_in_secs: 153126.148s, elapse since last report: 1.498s.\n",
      "Tried 2500 models, valid 2500, time_spent_in_hours: 44h, time_spent_in_secs: 159616.765s, elapse since last report: 1.48s.\n",
      "Tried 2600 models, valid 2600, time_spent_in_hours: 46h, time_spent_in_secs: 166013.894s, elapse since last report: 1.493s.\n",
      "Tried 2700 models, valid 2700, time_spent_in_hours: 47h, time_spent_in_secs: 172453.64s, elapse since last report: 1.466s.\n",
      "Tried 2800 models, valid 2800, time_spent_in_hours: 49h, time_spent_in_secs: 178528.108s, elapse since last report: 1.635s.\n",
      "Tried 2900 models, valid 2900, time_spent_in_hours: 51h, time_spent_in_secs: 184926.01s, elapse since last report: 1.663s.\n",
      "Tried 3000 models, valid 3000, time_spent_in_hours: 53h, time_spent_in_secs: 191455.646s, elapse since last report: 1.515s.\n",
      "Tried 3100 models, valid 3100, time_spent_in_hours: 54h, time_spent_in_secs: 197789.213s, elapse since last report: 1.617s.\n",
      "Tried 3200 models, valid 3200, time_spent_in_hours: 56h, time_spent_in_secs: 204134.871s, elapse since last report: 3.043s.\n",
      "Tried 3300 models, valid 3300, time_spent_in_hours: 58h, time_spent_in_secs: 210677.965s, elapse since last report: 1.653s.\n",
      "Tried 3400 models, valid 3400, time_spent_in_hours: 60h, time_spent_in_secs: 217094.983s, elapse since last report: 1.574s.\n",
      "Tried 3500 models, valid 3500, time_spent_in_hours: 62h, time_spent_in_secs: 223484.024s, elapse since last report: 1.576s.\n",
      "Tried 3600 models, valid 3600, time_spent_in_hours: 63h, time_spent_in_secs: 229879.916s, elapse since last report: 1.547s.\n",
      "Tried 3700 models, valid 3700, time_spent_in_hours: 65h, time_spent_in_secs: 236167.099s, elapse since last report: 1.488s.\n",
      "Tried 3800 models, valid 3800, time_spent_in_hours: 67h, time_spent_in_secs: 242572.212s, elapse since last report: 1.529s.\n",
      "Tried 3900 models, valid 3900, time_spent_in_hours: 69h, time_spent_in_secs: 249063.988s, elapse since last report: 1.608s.\n",
      "Tried 4000 models, valid 4000, time_spent_in_hours: 70h, time_spent_in_secs: 255410.933s, elapse since last report: 1.619s.\n",
      "Tried 4100 models, valid 4100, time_spent_in_hours: 72h, time_spent_in_secs: 261830.643s, elapse since last report: 1.556s.\n",
      "Tried 4200 models, valid 4200, time_spent_in_hours: 74h, time_spent_in_secs: 268292.942s, elapse since last report: 1.637s.\n",
      "Tried 4300 models, valid 4300, time_spent_in_hours: 76h, time_spent_in_secs: 274539.331s, elapse since last report: 1.533s.\n",
      "Tried 4400 models, valid 4400, time_spent_in_hours: 78h, time_spent_in_secs: 280895.34s, elapse since last report: 1.611s.\n",
      "Tried 4500 models, valid 4500, time_spent_in_hours: 79h, time_spent_in_secs: 287251.503s, elapse since last report: 1.595s.\n",
      "Tried 4600 models, valid 4600, time_spent_in_hours: 81h, time_spent_in_secs: 293682.578s, elapse since last report: 1.579s.\n",
      "Tried 4700 models, valid 4700, time_spent_in_hours: 83h, time_spent_in_secs: 300109.306s, elapse since last report: 1.603s.\n",
      "Tried 4800 models, valid 4800, time_spent_in_hours: 85h, time_spent_in_secs: 306485.379s, elapse since last report: 1.575s.\n",
      "Tried 4900 models, valid 4900, time_spent_in_hours: 86h, time_spent_in_secs: 312749.386s, elapse since last report: 1.59s.\n",
      "Tried 5000 models, valid 5000, time_spent_in_hours: 88h, time_spent_in_secs: 318996.235s, elapse since last report: 1.618s.\n",
      "Tried 5100 models, valid 5100, time_spent_in_hours: 90h, time_spent_in_secs: 325375.573s, elapse since last report: 1.568s.\n",
      "Tried 5200 models, valid 5200, time_spent_in_hours: 92h, time_spent_in_secs: 331755.748s, elapse since last report: 1.578s.\n",
      "Tried 5300 models, valid 5300, time_spent_in_hours: 93h, time_spent_in_secs: 337970.391s, elapse since last report: 1.573s.\n",
      "Tried 5400 models, valid 5400, time_spent_in_hours: 95h, time_spent_in_secs: 344428.847s, elapse since last report: 1.606s.\n",
      "Tried 5500 models, valid 5500, time_spent_in_hours: 97h, time_spent_in_secs: 350935.8s, elapse since last report: 1.579s.\n",
      "Tried 5600 models, valid 5600, time_spent_in_hours: 99h, time_spent_in_secs: 357321.471s, elapse since last report: 1.591s.\n",
      "Total time elapse: 89.45915842056274 seconds.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dna</th>\n",
       "      <th>cell_spec</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>latency</th>\n",
       "      <th>time_cost</th>\n",
       "      <th>total_time</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_per_time</th>\n",
       "      <th>test_all_time</th>\n",
       "      <th>time_spent_in_hours</th>\n",
       "      <th>time_spent_in_secs</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_per_time</th>\n",
       "      <th>train_all_time</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5068</th>\n",
       "      <td>5069</td>\n",
       "      <td>DNA([7, 7, 7, 6, 6])</td>\n",
       "      <td>64:64:64:56:56</td>\n",
       "      <td>85.02</td>\n",
       "      <td>0.020324</td>\n",
       "      <td>69.808378</td>\n",
       "      <td>323456.034085</td>\n",
       "      <td>93.18</td>\n",
       "      <td>0.261427</td>\n",
       "      <td>0.860657</td>\n",
       "      <td>77.459171</td>\n",
       "      <td>89</td>\n",
       "      <td>323456.034</td>\n",
       "      <td>99.91</td>\n",
       "      <td>0.007389</td>\n",
       "      <td>10.772471</td>\n",
       "      <td>969.522386</td>\n",
       "      <td>In this dict, train-loss/accuracy/time is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>2612</td>\n",
       "      <td>DNA([7, 7, 7, 6, 6])</td>\n",
       "      <td>64:64:64:56:56</td>\n",
       "      <td>85.02</td>\n",
       "      <td>0.020324</td>\n",
       "      <td>69.808378</td>\n",
       "      <td>166808.332951</td>\n",
       "      <td>93.18</td>\n",
       "      <td>0.261427</td>\n",
       "      <td>0.860657</td>\n",
       "      <td>77.459171</td>\n",
       "      <td>46</td>\n",
       "      <td>166808.333</td>\n",
       "      <td>99.91</td>\n",
       "      <td>0.007389</td>\n",
       "      <td>10.772471</td>\n",
       "      <td>969.522386</td>\n",
       "      <td>In this dict, train-loss/accuracy/time is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>1287</td>\n",
       "      <td>DNA([7, 7, 7, 6, 6])</td>\n",
       "      <td>64:64:64:56:56</td>\n",
       "      <td>85.02</td>\n",
       "      <td>0.020324</td>\n",
       "      <td>69.808378</td>\n",
       "      <td>82184.983194</td>\n",
       "      <td>93.18</td>\n",
       "      <td>0.261427</td>\n",
       "      <td>0.860657</td>\n",
       "      <td>77.459171</td>\n",
       "      <td>22</td>\n",
       "      <td>82184.983</td>\n",
       "      <td>99.91</td>\n",
       "      <td>0.007389</td>\n",
       "      <td>10.772471</td>\n",
       "      <td>969.522386</td>\n",
       "      <td>In this dict, train-loss/accuracy/time is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>2609</td>\n",
       "      <td>DNA([7, 7, 7, 6, 6])</td>\n",
       "      <td>64:64:64:56:56</td>\n",
       "      <td>85.02</td>\n",
       "      <td>0.020324</td>\n",
       "      <td>69.808378</td>\n",
       "      <td>166601.095250</td>\n",
       "      <td>93.18</td>\n",
       "      <td>0.261427</td>\n",
       "      <td>0.860657</td>\n",
       "      <td>77.459171</td>\n",
       "      <td>46</td>\n",
       "      <td>166601.095</td>\n",
       "      <td>99.91</td>\n",
       "      <td>0.007389</td>\n",
       "      <td>10.772471</td>\n",
       "      <td>969.522386</td>\n",
       "      <td>In this dict, train-loss/accuracy/time is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>5002</td>\n",
       "      <td>DNA([7, 7, 7, 6, 6])</td>\n",
       "      <td>64:64:64:56:56</td>\n",
       "      <td>85.02</td>\n",
       "      <td>0.020324</td>\n",
       "      <td>69.808378</td>\n",
       "      <td>319136.337607</td>\n",
       "      <td>93.18</td>\n",
       "      <td>0.261427</td>\n",
       "      <td>0.860657</td>\n",
       "      <td>77.459171</td>\n",
       "      <td>88</td>\n",
       "      <td>319136.338</td>\n",
       "      <td>99.91</td>\n",
       "      <td>0.007389</td>\n",
       "      <td>10.772471</td>\n",
       "      <td>969.522386</td>\n",
       "      <td>In this dict, train-loss/accuracy/time is the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                   dna       cell_spec  val_acc   latency  \\\n",
       "5068  5069  DNA([7, 7, 7, 6, 6])  64:64:64:56:56    85.02  0.020324   \n",
       "2611  2612  DNA([7, 7, 7, 6, 6])  64:64:64:56:56    85.02  0.020324   \n",
       "1286  1287  DNA([7, 7, 7, 6, 6])  64:64:64:56:56    85.02  0.020324   \n",
       "2608  2609  DNA([7, 7, 7, 6, 6])  64:64:64:56:56    85.02  0.020324   \n",
       "5001  5002  DNA([7, 7, 7, 6, 6])  64:64:64:56:56    85.02  0.020324   \n",
       "\n",
       "      time_cost     total_time  test_acc  test_loss  test_per_time  \\\n",
       "5068  69.808378  323456.034085     93.18   0.261427       0.860657   \n",
       "2611  69.808378  166808.332951     93.18   0.261427       0.860657   \n",
       "1286  69.808378   82184.983194     93.18   0.261427       0.860657   \n",
       "2608  69.808378  166601.095250     93.18   0.261427       0.860657   \n",
       "5001  69.808378  319136.337607     93.18   0.261427       0.860657   \n",
       "\n",
       "      test_all_time time_spent_in_hours  time_spent_in_secs  train_accuracy  \\\n",
       "5068      77.459171                  89          323456.034           99.91   \n",
       "2611      77.459171                  46          166808.333           99.91   \n",
       "1286      77.459171                  22           82184.983           99.91   \n",
       "2608      77.459171                  46          166601.095           99.91   \n",
       "5001      77.459171                  88          319136.338           99.91   \n",
       "\n",
       "      train_loss  train_per_time  train_all_time  \\\n",
       "5068    0.007389       10.772471      969.522386   \n",
       "2611    0.007389       10.772471      969.522386   \n",
       "1286    0.007389       10.772471      969.522386   \n",
       "2608    0.007389       10.772471      969.522386   \n",
       "5001    0.007389       10.772471      969.522386   \n",
       "\n",
       "                                                comment  \n",
       "5068  In this dict, train-loss/accuracy/time is the ...  \n",
       "2611  In this dict, train-loss/accuracy/time is the ...  \n",
       "1286  In this dict, train-loss/accuracy/time is the ...  \n",
       "2608  In this dict, train-loss/accuracy/time is the ...  \n",
       "5001  In this dict, train-loss/accuracy/time is the ...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_results_evol = test_nas_algo('evolution')\n",
    "sorted_results_evol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best architecture found after 5640 evaluated models!\n",
      "Best model found: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dna</th>\n",
       "      <th>cell_spec</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>latency</th>\n",
       "      <th>time_cost</th>\n",
       "      <th>total_time</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_per_time</th>\n",
       "      <th>test_all_time</th>\n",
       "      <th>time_spent_in_hours</th>\n",
       "      <th>time_spent_in_secs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5068</th>\n",
       "      <td>5069</td>\n",
       "      <td>DNA([7, 7, 7, 6, 6])</td>\n",
       "      <td>64:64:64:56:56</td>\n",
       "      <td>85.02</td>\n",
       "      <td>0.020324</td>\n",
       "      <td>69.808378</td>\n",
       "      <td>323456.034085</td>\n",
       "      <td>93.18</td>\n",
       "      <td>0.261427</td>\n",
       "      <td>0.860657</td>\n",
       "      <td>77.459171</td>\n",
       "      <td>89</td>\n",
       "      <td>323456.034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                   dna       cell_spec  val_acc   latency  \\\n",
       "5068  5069  DNA([7, 7, 7, 6, 6])  64:64:64:56:56    85.02  0.020324   \n",
       "\n",
       "      time_cost     total_time  test_acc  test_loss  test_per_time  \\\n",
       "5068  69.808378  323456.034085     93.18   0.261427       0.860657   \n",
       "\n",
       "      test_all_time time_spent_in_hours  time_spent_in_secs  \n",
       "5068      77.459171                  89          323456.034  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_report(sorted_results_evol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_results_evol.to_csv('data/evolution_100h.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with Reinforcement Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-28 01:48:56] Try to use the default NATS-Bench (size) path from fast_mode=True and path=None.\n",
      "Candidates: [8, 16, 24, 32, 40, 48, 56, 64]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/guilherme/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1569 predict_function  *\n        return step_function(self, iterator)\n    /home/guilherme/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1559 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/guilherme/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/guilherme/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/guilherme/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/guilherme/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1552 run_step  **\n        outputs = model.predict_step(data)\n    /home/guilherme/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1525 predict_step\n        return self(x, training=False)\n    /home/guilherme/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/guilherme/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:267 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model_11: expected shape=(None, 1, 11), found shape=(None, 1, 9)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_114347/1718915689.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msorted_results_rl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_nas_algo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msorted_results_rl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_114347/6827030.py\u001b[0m in \u001b[0;36mtest_nas_algo\u001b[0;34m(algo_name)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0malgorithm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgo_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnats_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cifar10'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreporting_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_train_hours\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0msorted_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_114347/6827030.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(nats_api, search_model, algo, dataset, reporting_epoch, max_train_hours)\u001b[0m\n\u001b[1;32m     42\u001b[0m                                        'comment'])\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeedback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/pyglove/core/tuning/sample.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(hyper_value, algorithm, num_examples, early_stopping_policy, where, name, group, backend, metrics_to_optimize, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m       \u001b[0mfeedback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m       \u001b[0mdna\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeedback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/pyglove/core/tuning/local_backend.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_study\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_latest_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'PENDING'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m       \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_study\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_dna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_feedback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_study\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/pyglove/core/tuning/local_backend.py\u001b[0m in \u001b[0;36mcreate_trial\u001b[0;34m(self, dna_fn, group_id)\u001b[0m\n\u001b[1;32m    189\u001b[0m           and self.next_trial_id() > self._max_num_trials):\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m       trial = Trial(id=self.next_trial_id(), dna=dna_fn(), status='PENDING',\n\u001b[0m\u001b[1;32m    192\u001b[0m                     created_time=int(time.time()), metadata=dict())\n\u001b[1;32m    193\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/pyglove/core/tuning/local_backend.py\u001b[0m in \u001b[0;36mnext_dna\u001b[0;34m()\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;34m\"\"\"Get the feedback object for the next trial.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext_dna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_algorithm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_study\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_active\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/pyglove/core/geno/dna_generator.py\u001b[0m in \u001b[0;36mpropose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpropose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDNA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;34m\"\"\"Propose a DNA to evaluate.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mdna\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_propose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_proposals\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_114347/3343570177.py\u001b[0m in \u001b[0;36m_propose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# print(f' ..prev_arch.shape: {prev_arch.shape}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mnew_arch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnas_controller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_new_arch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_arch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDNA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_114347/539488154.py\u001b[0m in \u001b[0;36mbuild_new_arch\u001b[0;34m(self, prev_arch)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mprob_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontroller_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# output: (1,1,n_classes+noise_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0mprob_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1725\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1727\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1728\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 763\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    764\u001b[0m             *args, **kwds))\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3279\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/guilherme/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1569 predict_function  *\n        return step_function(self, iterator)\n    /home/guilherme/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1559 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/guilherme/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/guilherme/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/guilherme/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/guilherme/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1552 run_step  **\n        outputs = model.predict_step(data)\n    /home/guilherme/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1525 predict_step\n        return self(x, training=False)\n    /home/guilherme/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/guilherme/data2/anaconda3/envs/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:267 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model_11: expected shape=(None, 1, 11), found shape=(None, 1, 9)\n"
     ]
    }
   ],
   "source": [
    "sorted_results_rl = test_nas_algo('rl')\n",
    "sorted_results_rl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best architecture found after 239 evaluated models!\n",
      "Best model found: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dna</th>\n",
       "      <th>cell_spec</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>latency</th>\n",
       "      <th>time_cost</th>\n",
       "      <th>total_time</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_per_time</th>\n",
       "      <th>test_all_time</th>\n",
       "      <th>time_spent_in_hours</th>\n",
       "      <th>time_spent_in_secs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>230</td>\n",
       "      <td>DNA([3, 4, 4, 3, 3])</td>\n",
       "      <td>32:40:40:32:32</td>\n",
       "      <td>82.74</td>\n",
       "      <td>0.01439</td>\n",
       "      <td>49.39539</td>\n",
       "      <td>10340.721351</td>\n",
       "      <td>91.67</td>\n",
       "      <td>0.297276</td>\n",
       "      <td>0.728126</td>\n",
       "      <td>65.531344</td>\n",
       "      <td>2</td>\n",
       "      <td>10340.721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                   dna       cell_spec  val_acc  latency  time_cost  \\\n",
       "229  230  DNA([3, 4, 4, 3, 3])  32:40:40:32:32    82.74  0.01439   49.39539   \n",
       "\n",
       "       total_time  test_acc  test_loss  test_per_time  test_all_time  \\\n",
       "229  10340.721351     91.67   0.297276       0.728126      65.531344   \n",
       "\n",
       "    time_spent_in_hours  time_spent_in_secs  \n",
       "229                   2           10340.721  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_report(sorted_results_rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_results_rl.to_csv('data/rl_100h.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "85f5044ba23e75135dc4c908fd4d7609c1c80b195047fdb4d16ee0e66a953254"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "neptune": {
   "notebookId": "98a3967a-428e-4576-add1-6bd753600673",
   "projectVersion": 2
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
