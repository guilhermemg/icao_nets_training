{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Notebook for training deep neural networks to estimate the compliance of an image to the MOUTH requisite.\n",
    "\n",
    "The training is supervised and labels were obtained through the running of the MouthOpenface model followed by a Tagger execution\n",
    "with a threshold of 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from imutils import paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "if '../../../notebooks/' not in sys.path:\n",
    "    sys.path.append('../../../notebooks/')\n",
    "\n",
    "import utils.constants as cts\n",
    "import utils.draw_utils as dr\n",
    "\n",
    "from models.oface_mouth_model import OpenfaceMouth\n",
    "\n",
    "from data_loaders.fvc_pyb_loader import FvcPybossaDL\n",
    "from data_loaders.vgg_loader import VggFace2DL\n",
    "from data_loaders.caltech_loader import CaltechDL\n",
    "from data_loaders.cvl_loader import CvlDL\n",
    "from data_loaders.colorferet_loader import ColorFeretDL\n",
    "from data_loaders.fei_loader import FeiDB_DL\n",
    "from data_loaders.gtech_loader import GeorgiaTechDL\n",
    "from data_loaders.uni_essex_loader import UniEssexDL\n",
    "from data_loaders.icpr04_loader import ICPR04_DL\n",
    "from data_loaders.imfdb_loader import IMFDB_DL\n",
    "from data_loaders.ijbc_loader import IJBC_DL\n",
    "from data_loaders.lfw_loader import LFWDL\n",
    "from data_loaders.celeba_loader import CelebA_DL\n",
    "from data_loaders.casia_webface_loader import CasiaWebface_DL\n",
    "\n",
    "from gt_loaders.gen_gt import Eval\n",
    "from gt_loaders.fvc_gt import FVC_GTLoader\n",
    "from gt_loaders.pybossa_gt import PybossaGTLoader\n",
    "\n",
    "from tagger.tagger import Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "try: \n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True) \n",
    "except: \n",
    "    raise Exception(\"Invalid device or cannot modify virtual devices once initialized.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54363, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = OpenfaceMouth()\n",
    "\n",
    "req = cts.ICAO_REQ.MOUTH\n",
    "\n",
    "dl_list = [FvcPybossaDL(aligned=False), FvcPybossaDL(aligned=True),\n",
    "           CaltechDL(aligned=False), \n",
    "           VggFace2DL(aligned=False), VggFace2DL(aligned=True),\n",
    "           CvlDL(aligned=False), \n",
    "           ColorFeretDL(aligned=False), \n",
    "           FeiDB_DL(aligned=False), FeiDB_DL(aligned=True),\n",
    "           CvlDL(aligned=False), \n",
    "           GeorgiaTechDL(aligned=False), GeorgiaTechDL(aligned=True), \n",
    "           UniEssexDL(aligned=False),\n",
    "           UniEssexDL(aligned=False), \n",
    "           ICPR04_DL(aligned=False), \n",
    "           IMFDB_DL(aligned=True),\n",
    "           IJBC_DL(aligned=False),\n",
    "           LFWDL(aligned=False), LFWDL(aligned=True), \n",
    "           CelebA_DL(aligned=True),\n",
    "           CasiaWebface_DL(aligned=False)\n",
    "          ]\n",
    "\n",
    "in_data = pd.DataFrame(columns=['origin','img_name','comp'])\n",
    "\n",
    "for dl in dl_list:\n",
    "    t = Tagger(dl, m, req)\n",
    "    t.load_labels_df()\n",
    "    tmp_df = t.labels_df\n",
    "    tmp_df['origin'] = dl.get_name().value\n",
    "    tmp_df['aligned'] = dl.is_aligned()\n",
    "    in_data = in_data.append(tmp_df)\n",
    "\n",
    "in_data.shape    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for img_path,label in zip(in_data.img_name,in_data.comp):\n",
    "\timage = load_img(img_path, target_size=(224, 224))\n",
    "\timage = img_to_array(image)\n",
    "\timage = preprocess_input(image)\n",
    "\n",
    "\tdata.append(image)\n",
    "\tlabels.append(label)\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(data.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "\ttest_size=0.20, stratify=labels, random_state=42)\n",
    "\n",
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.15,\n",
    "\twidth_shift_range=0.2,\n",
    "\theight_shift_range=0.2,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "# load the MobileNetV2 network, ensuring the head FC layer sets are\n",
    "# left off\n",
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "# loop over all layers in the base model and freeze them so they will\n",
    "# *not* be updated during the first training process\n",
    "for layer in baseModel.layers:\n",
    "\tlayer.trainable = False\n",
    "\n",
    "# compile our model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# train the head of the network\n",
    "print(\"[INFO] training head...\")\n",
    "H = model.fit(\n",
    "\taug.flow(trainX, trainY, batch_size=BS),\n",
    "\tsteps_per_epoch=len(trainX) // BS,\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tvalidation_steps=len(testX) // BS,\n",
    "\tepochs=EPOCHS)\n",
    "\n",
    "# make predictions on the testing set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predIdxs = model.predict(testX, batch_size=BS)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(testY.argmax(axis=1), predIdxs, target_names=lb.classes_))\n",
    "\n",
    "# serialize the model to disk\n",
    "print(\"[INFO] saving mask detector model...\")\n",
    "model.save(\"model\", save_format=\"h5\")\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "N = EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"train.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
