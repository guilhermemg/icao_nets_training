{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "if '../../../notebooks/' not in sys.path:\n",
    "    sys.path.append('../../../notebooks/')\n",
    "\n",
    "import utils.constants as cts\n",
    "\n",
    "from models.oface_mouth_model import OpenfaceMouth\n",
    "from data_loaders.data_loader import DLName\n",
    "from gt_loaders.gt_names import GTName\n",
    "from net_trainer import NetworkTrainer, BaseModel, Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Network Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "Use Neptune:  False\n",
      "-----\n",
      "===================\n",
      "Args: \n",
      "{'exp_params': {'description': 'Training mtl network for mouth and veil '\n",
      "                               'requisites',\n",
      "                'name': 'train_vgg16',\n",
      "                'src_files': ['net_trainer.py'],\n",
      "                'tags': ['vgg16', 'ground truths', 'adagrad', 'veil', 'mouth']},\n",
      " 'net_train_params': {'base_model': <BaseModel.VGG16: {'target_size': (224, 224), 'prep_function': <function preprocess_input at 0x7fa5546ea040>}>,\n",
      "                      'batch_size': 64,\n",
      "                      'dense_units': 128,\n",
      "                      'dropout': 0.2,\n",
      "                      'early_stopping': 10,\n",
      "                      'learning_rate': 0.001,\n",
      "                      'n_epochs': 15,\n",
      "                      'optimizer': <Optimizer.ADAGRAD: 'Adagrad'>,\n",
      "                      'seed': 42,\n",
      "                      'shuffle': True,\n",
      "                      'test_prop': 0.05,\n",
      "                      'train_prop': 0.9,\n",
      "                      'validation_prop': 0.05,\n",
      "                      'validation_split': 0.1},\n",
      " 'properties': {'aligned': True,\n",
      "                'balance_input_data': False,\n",
      "                'gt_names': {'test': [],\n",
      "                             'train_validation': [],\n",
      "                             'train_validation_test': [<GTName.FVC: 'fvc'>,\n",
      "                                                       <GTName.GENKI: 'genki'>]},\n",
      "                'reqs': [<ICAO_REQ.MOUTH: 'mouth'>, <ICAO_REQ.VEIL: 'veil'>],\n",
      "                'save_trained_model': False,\n",
      "                'use_gt_data': True},\n",
      " 'use_neptune': False}\n",
      "===================\n",
      "----\n",
      "Base Model Name:  BaseModel.VGG16\n",
      "----\n",
      "----\n",
      "MTL Model: True\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "kwargs = { \n",
    "    'use_neptune': False,\n",
    "    'exp_params' : {\n",
    "        'name': 'train_vgg16',\n",
    "        'description': 'Training mtl network for mouth and veil requisites',\n",
    "        'tags': ['vgg16', 'ground truths', 'adagrad', 'veil', 'mouth'],\n",
    "        'src_files': ['net_trainer.py']\n",
    "    },\n",
    "    'properties': {\n",
    "#         'tagger_model': OpenfaceMouth(),\n",
    "#         'dl_names': {'train_validation':\n",
    "#                            [DLName.VGGFACE2, DLName.CALTECH, DLName.FVC_PYBOSSA, \n",
    "#                             DLName.CVL, DLName.FEI_DB, DLName.GEORGIA_TECH, DLName.COLOR_FERET,\n",
    "#                             DLName.ICPR04, DLName.IMFDB, DLName.IJBC, DLName.LFW, DLName.CASIA_WF,\n",
    "#                             DLName.GENKI4K_DB],\n",
    "#                       'test': [],\n",
    "        'reqs': [cts.ICAO_REQ.MOUTH, cts.ICAO_REQ.VEIL],\n",
    "        'aligned': True,\n",
    "        'use_gt_data': True,\n",
    "        'gt_names': {\n",
    "            'train_validation': [],\n",
    "            'test': [],\n",
    "            'train_validation_test': [GTName.FVC, GTName.GENKI]\n",
    "        },\n",
    "        'balance_input_data': False,\n",
    "        'save_trained_model': False\n",
    "    },\n",
    "    'net_train_params': {\n",
    "        'base_model': BaseModel.VGG16,\n",
    "        'batch_size': 64,\n",
    "        'n_epochs': 15,\n",
    "        'early_stopping': 10,\n",
    "        'shuffle': True,\n",
    "        'dense_units': 128,\n",
    "        'learning_rate': 1e-3,\n",
    "        'optimizer': Optimizer.ADAGRAD,\n",
    "        'dropout': 0.2,\n",
    "        'train_prop': 0.9,\n",
    "        'validation_prop': 0.05,\n",
    "        'test_prop': 0.05,\n",
    "        'seed': 42,\n",
    "        'validation_split': 0.1\n",
    "    }\n",
    "}\n",
    "\n",
    "trainer = NetworkTrainer(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Loading GT FVC...\n",
      "..Ignoring 19 dummy and empty label values\n",
      "Loading GT GENKI...\n",
      "..Ignoring 0 dummy and empty label values\n",
      "Input data.shape: (9751, 5)\n",
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "trainer.load_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not balancing input_data\n"
     ]
    }
   ],
   "source": [
    "trainer.balance_input_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data generators\n",
      "Found 8337 validated image filenames.\n",
      "Found 926 validated image filenames.\n",
      "Found 488 validated image filenames.\n",
      "TOTAL: 9751\n"
     ]
    }
   ],
   "source": [
    "trainer.setup_data_generators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requisite: MOUTH\n",
      "N_TRAIN_VALID_COMP: 5768 (62.27%)\n",
      "N_TRAIN_VALID_NOT_COMP: 3495 (37.73%)\n",
      "N_TEST_COMP: 306 (62.7%)\n",
      "N_TEST_NOT_COMP: 182 (37.3%)\n",
      "----\n",
      "Requisite: VEIL\n",
      "N_TRAIN_VALID_COMP: 8917 (96.26%)\n",
      "N_TRAIN_VALID_NOT_COMP: 346 (3.74%)\n",
      "N_TEST_COMP: 470 (96.31%)\n",
      "N_TEST_NOT_COMP: 18 (3.69%)\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "trainer.summary_labels_dist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using Neptune\n",
      "Not using Neptune\n"
     ]
    }
   ],
   "source": [
    "trainer.start_neptune()\n",
    "trainer.create_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model...\n",
      "Model created\n"
     ]
    }
   ],
   "source": [
    "trainer.create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vizualize Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trainer.vizualize_model()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trainer.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VGG16 network\n",
      "Epoch 1/15\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.7938 - mouth_loss: 0.9061 - veil_loss: 0.8876 - mouth_accuracy: 0.5085 - veil_accuracy: 0.5018WARNING:tensorflow:Early stopping conditioned on metric `accuracy` which is not available. Available metrics are: loss,mouth_loss,veil_loss,mouth_accuracy,veil_accuracy,val_loss,val_mouth_loss,val_veil_loss,val_mouth_accuracy,val_veil_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "130/130 [==============================] - 68s 525ms/step - loss: 1.7938 - mouth_loss: 0.9061 - veil_loss: 0.8876 - mouth_accuracy: 0.5085 - veil_accuracy: 0.5018 - val_loss: 1.4110 - val_mouth_loss: 0.7061 - val_veil_loss: 0.7049 - val_mouth_accuracy: 0.4531 - val_veil_accuracy: 0.7176\n",
      "Epoch 2/15\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.5305 - mouth_loss: 0.7696 - veil_loss: 0.7609 - mouth_accuracy: 0.4943 - veil_accuracy: 0.5080WARNING:tensorflow:Early stopping conditioned on metric `accuracy` which is not available. Available metrics are: loss,mouth_loss,veil_loss,mouth_accuracy,veil_accuracy,val_loss,val_mouth_loss,val_veil_loss,val_mouth_accuracy,val_veil_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "130/130 [==============================] - 68s 527ms/step - loss: 1.5305 - mouth_loss: 0.7696 - veil_loss: 0.7609 - mouth_accuracy: 0.4943 - veil_accuracy: 0.5080 - val_loss: 1.3993 - val_mouth_loss: 0.7009 - val_veil_loss: 0.6984 - val_mouth_accuracy: 0.4185 - val_veil_accuracy: 0.6864\n",
      "Epoch 3/15\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.4841 - mouth_loss: 0.7435 - veil_loss: 0.7405 - mouth_accuracy: 0.4852 - veil_accuracy: 0.5056WARNING:tensorflow:Early stopping conditioned on metric `accuracy` which is not available. Available metrics are: loss,mouth_loss,veil_loss,mouth_accuracy,veil_accuracy,val_loss,val_mouth_loss,val_veil_loss,val_mouth_accuracy,val_veil_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "130/130 [==============================] - 68s 525ms/step - loss: 1.4841 - mouth_loss: 0.7435 - veil_loss: 0.7405 - mouth_accuracy: 0.4852 - veil_accuracy: 0.5056 - val_loss: 1.3951 - val_mouth_loss: 0.6976 - val_veil_loss: 0.6976 - val_mouth_accuracy: 0.4163 - val_veil_accuracy: 0.6786\n",
      "Epoch 4/15\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.4600 - mouth_loss: 0.7312 - veil_loss: 0.7289 - mouth_accuracy: 0.4897 - veil_accuracy: 0.5123WARNING:tensorflow:Early stopping conditioned on metric `accuracy` which is not available. Available metrics are: loss,mouth_loss,veil_loss,mouth_accuracy,veil_accuracy,val_loss,val_mouth_loss,val_veil_loss,val_mouth_accuracy,val_veil_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "130/130 [==============================] - 69s 528ms/step - loss: 1.4600 - mouth_loss: 0.7312 - veil_loss: 0.7289 - mouth_accuracy: 0.4897 - veil_accuracy: 0.5123 - val_loss: 1.3928 - val_mouth_loss: 0.6967 - val_veil_loss: 0.6961 - val_mouth_accuracy: 0.4208 - val_veil_accuracy: 0.6741\n",
      "Epoch 5/15\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.4465 - mouth_loss: 0.7234 - veil_loss: 0.7231 - mouth_accuracy: 0.4871 - veil_accuracy: 0.4973WARNING:tensorflow:Early stopping conditioned on metric `accuracy` which is not available. Available metrics are: loss,mouth_loss,veil_loss,mouth_accuracy,veil_accuracy,val_loss,val_mouth_loss,val_veil_loss,val_mouth_accuracy,val_veil_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "130/130 [==============================] - 69s 528ms/step - loss: 1.4465 - mouth_loss: 0.7234 - veil_loss: 0.7231 - mouth_accuracy: 0.4871 - veil_accuracy: 0.4973 - val_loss: 1.3918 - val_mouth_loss: 0.6962 - val_veil_loss: 0.6957 - val_mouth_accuracy: 0.3917 - val_veil_accuracy: 0.7243\n",
      "Epoch 6/15\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.4348 - mouth_loss: 0.7176 - veil_loss: 0.7172 - mouth_accuracy: 0.4830 - veil_accuracy: 0.4997WARNING:tensorflow:Early stopping conditioned on metric `accuracy` which is not available. Available metrics are: loss,mouth_loss,veil_loss,mouth_accuracy,veil_accuracy,val_loss,val_mouth_loss,val_veil_loss,val_mouth_accuracy,val_veil_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "130/130 [==============================] - 69s 528ms/step - loss: 1.4348 - mouth_loss: 0.7176 - veil_loss: 0.7172 - mouth_accuracy: 0.4830 - veil_accuracy: 0.4997 - val_loss: 1.3907 - val_mouth_loss: 0.6953 - val_veil_loss: 0.6953 - val_mouth_accuracy: 0.4007 - val_veil_accuracy: 0.7132\n",
      "Epoch 7/15\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.4289 - mouth_loss: 0.7143 - veil_loss: 0.7147 - mouth_accuracy: 0.4829 - veil_accuracy: 0.5082WARNING:tensorflow:Early stopping conditioned on metric `accuracy` which is not available. Available metrics are: loss,mouth_loss,veil_loss,mouth_accuracy,veil_accuracy,val_loss,val_mouth_loss,val_veil_loss,val_mouth_accuracy,val_veil_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "130/130 [==============================] - 69s 529ms/step - loss: 1.4289 - mouth_loss: 0.7143 - veil_loss: 0.7147 - mouth_accuracy: 0.4829 - veil_accuracy: 0.5082 - val_loss: 1.3896 - val_mouth_loss: 0.6949 - val_veil_loss: 0.6947 - val_mouth_accuracy: 0.4007 - val_veil_accuracy: 0.6295\n",
      "Epoch 8/15\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.4230 - mouth_loss: 0.7112 - veil_loss: 0.7118 - mouth_accuracy: 0.4898 - veil_accuracy: 0.4916WARNING:tensorflow:Early stopping conditioned on metric `accuracy` which is not available. Available metrics are: loss,mouth_loss,veil_loss,mouth_accuracy,veil_accuracy,val_loss,val_mouth_loss,val_veil_loss,val_mouth_accuracy,val_veil_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "130/130 [==============================] - 69s 529ms/step - loss: 1.4230 - mouth_loss: 0.7112 - veil_loss: 0.7118 - mouth_accuracy: 0.4898 - veil_accuracy: 0.4916 - val_loss: 1.3896 - val_mouth_loss: 0.6948 - val_veil_loss: 0.6948 - val_mouth_accuracy: 0.4018 - val_veil_accuracy: 0.6484\n",
      "Epoch 9/15\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.4195 - mouth_loss: 0.7092 - veil_loss: 0.7103 - mouth_accuracy: 0.4883 - veil_accuracy: 0.5045WARNING:tensorflow:Early stopping conditioned on metric `accuracy` which is not available. Available metrics are: loss,mouth_loss,veil_loss,mouth_accuracy,veil_accuracy,val_loss,val_mouth_loss,val_veil_loss,val_mouth_accuracy,val_veil_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "130/130 [==============================] - 69s 530ms/step - loss: 1.4195 - mouth_loss: 0.7092 - veil_loss: 0.7103 - mouth_accuracy: 0.4883 - veil_accuracy: 0.5045 - val_loss: 1.3890 - val_mouth_loss: 0.6946 - val_veil_loss: 0.6944 - val_mouth_accuracy: 0.4007 - val_veil_accuracy: 0.6239\n",
      "Epoch 10/15\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.4160 - mouth_loss: 0.7070 - veil_loss: 0.7090 - mouth_accuracy: 0.4885 - veil_accuracy: 0.4930WARNING:tensorflow:Early stopping conditioned on metric `accuracy` which is not available. Available metrics are: loss,mouth_loss,veil_loss,mouth_accuracy,veil_accuracy,val_loss,val_mouth_loss,val_veil_loss,val_mouth_accuracy,val_veil_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "130/130 [==============================] - 69s 527ms/step - loss: 1.4160 - mouth_loss: 0.7070 - veil_loss: 0.7090 - mouth_accuracy: 0.4885 - veil_accuracy: 0.4930 - val_loss: 1.3887 - val_mouth_loss: 0.6944 - val_veil_loss: 0.6943 - val_mouth_accuracy: 0.4141 - val_veil_accuracy: 0.5502\n",
      "Epoch 11/15\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.4130 - mouth_loss: 0.7058 - veil_loss: 0.7072 - mouth_accuracy: 0.4865 - veil_accuracy: 0.4898WARNING:tensorflow:Early stopping conditioned on metric `accuracy` which is not available. Available metrics are: loss,mouth_loss,veil_loss,mouth_accuracy,veil_accuracy,val_loss,val_mouth_loss,val_veil_loss,val_mouth_accuracy,val_veil_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "130/130 [==============================] - 69s 530ms/step - loss: 1.4130 - mouth_loss: 0.7058 - veil_loss: 0.7072 - mouth_accuracy: 0.4865 - veil_accuracy: 0.4898 - val_loss: 1.3884 - val_mouth_loss: 0.6943 - val_veil_loss: 0.6941 - val_mouth_accuracy: 0.3884 - val_veil_accuracy: 0.6071\n",
      "Epoch 12/15\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.4107 - mouth_loss: 0.7050 - veil_loss: 0.7057 - mouth_accuracy: 0.4857 - veil_accuracy: 0.5056WARNING:tensorflow:Early stopping conditioned on metric `accuracy` which is not available. Available metrics are: loss,mouth_loss,veil_loss,mouth_accuracy,veil_accuracy,val_loss,val_mouth_loss,val_veil_loss,val_mouth_accuracy,val_veil_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "130/130 [==============================] - 69s 528ms/step - loss: 1.4107 - mouth_loss: 0.7050 - veil_loss: 0.7057 - mouth_accuracy: 0.4857 - veil_accuracy: 0.5056 - val_loss: 1.3883 - val_mouth_loss: 0.6943 - val_veil_loss: 0.6940 - val_mouth_accuracy: 0.4040 - val_veil_accuracy: 0.5312\n",
      "Epoch 13/15\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.4091 - mouth_loss: 0.7038 - veil_loss: 0.7053 - mouth_accuracy: 0.4846 - veil_accuracy: 0.4966WARNING:tensorflow:Early stopping conditioned on metric `accuracy` which is not available. Available metrics are: loss,mouth_loss,veil_loss,mouth_accuracy,veil_accuracy,val_loss,val_mouth_loss,val_veil_loss,val_mouth_accuracy,val_veil_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "130/130 [==============================] - 69s 529ms/step - loss: 1.4091 - mouth_loss: 0.7038 - veil_loss: 0.7053 - mouth_accuracy: 0.4846 - veil_accuracy: 0.4966 - val_loss: 1.3879 - val_mouth_loss: 0.6939 - val_veil_loss: 0.6940 - val_mouth_accuracy: 0.4208 - val_veil_accuracy: 0.5469\n",
      "Epoch 14/15\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.4083 - mouth_loss: 0.7032 - veil_loss: 0.7051 - mouth_accuracy: 0.4927 - veil_accuracy: 0.5070WARNING:tensorflow:Early stopping conditioned on metric `accuracy` which is not available. Available metrics are: loss,mouth_loss,veil_loss,mouth_accuracy,veil_accuracy,val_loss,val_mouth_loss,val_veil_loss,val_mouth_accuracy,val_veil_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "130/130 [==============================] - 69s 529ms/step - loss: 1.4083 - mouth_loss: 0.7032 - veil_loss: 0.7051 - mouth_accuracy: 0.4927 - veil_accuracy: 0.5070 - val_loss: 1.3877 - val_mouth_loss: 0.6939 - val_veil_loss: 0.6938 - val_mouth_accuracy: 0.3951 - val_veil_accuracy: 0.5045\n",
      "Epoch 15/15\n",
      "130/130 [==============================] - ETA: 0s - loss: 1.4057 - mouth_loss: 0.7019 - veil_loss: 0.7039 - mouth_accuracy: 0.4883 - veil_accuracy: 0.4912WARNING:tensorflow:Early stopping conditioned on metric `accuracy` which is not available. Available metrics are: loss,mouth_loss,veil_loss,mouth_accuracy,veil_accuracy,val_loss,val_mouth_loss,val_veil_loss,val_mouth_accuracy,val_veil_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "130/130 [==============================] - 69s 531ms/step - loss: 1.4057 - mouth_loss: 0.7019 - veil_loss: 0.7039 - mouth_accuracy: 0.4883 - veil_accuracy: 0.4912 - val_loss: 1.3876 - val_mouth_loss: 0.6938 - val_veil_loss: 0.6938 - val_mouth_accuracy: 0.4364 - val_veil_accuracy: 0.4922\n"
     ]
    }
   ],
   "source": [
    "trainer.train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.draw_training_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load_best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vizualize Model Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.vizualize_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finishing Experiment Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.finish_experiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "neptune": {
   "notebookId": "d6d95e8a-b251-40a1-bf9d-610ebc484f63"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
