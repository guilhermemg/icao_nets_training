{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> Restrict GPU memory growth: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# disable tensorflow log level infos\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # show only errors\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "if '../../../../notebooks/' not in sys.path:\n",
    "    sys.path.append('../../../../notebooks/')\n",
    "if 'src' not in sys.path:\n",
    "    sys.path.insert(0, 'src')\n",
    "\n",
    "import utils.constants as cts\n",
    "\n",
    "from data_loaders.data_loader import DLName\n",
    "from gt_loaders.gt_names import GTName\n",
    "from exp_runner import ExperimentRunner\n",
    "from base.benchmark_dataset import BenchmarkDataset\n",
    "from base.model_evaluator import DataSource, DataPredSelection\n",
    "from base.base_models import BaseModel\n",
    "from base.optimizers import Optimizer\n",
    "from m_utils.mtl_approach import MTLApproach\n",
    "from m_utils.nas_mtl_approach import NAS_MTLApproach\n",
    "from m_utils.constants import ICAO_REQ, MNIST_TASK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Network runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Init ExperimentRunner -------------------\n",
      "---------------------------\n",
      "Parent Process ID: 93209\n",
      "Process ID: 106076\n",
      "---------------------------\n",
      "-----\n",
      "Use Neptune:  True\n",
      "-----\n",
      "-------------------\n",
      "Args: \n",
      "{'exp_params': {'description': 'NAS Approach 2 with FVC-ICAO dataset with 3 '\n",
      "                               'trials and patience',\n",
      "                'name': 'neural_arch_search',\n",
      "                'src_files': ['src'],\n",
      "                'tags': ['ground_truth', 'nas', 'nas_approach_2', 'fvc']},\n",
      " 'nas_params': {'controller_batch_size': 32,\n",
      "                'controller_epochs': 50,\n",
      "                'max_blocks_per_branch': 5,\n",
      "                'n_trials': 3},\n",
      " 'net_train_params': {'base_model': <BaseModel.MOBILENET_V2: {'name': 'mobilnet_v2', 'target_size': (224, 224), 'prep_function': <function preprocess_input at 0x7f0e2cfda700>}>,\n",
      "                      'batch_size': 32,\n",
      "                      'dropout': 0.3,\n",
      "                      'early_stopping': 5,\n",
      "                      'learning_rate': 0.001,\n",
      "                      'n_epochs': 50,\n",
      "                      'optimizer': <Optimizer.ADAMAX: 'Adamax'>},\n",
      " 'properties': {'approach': <NAS_MTLApproach.APPROACH_2: 'approach_2'>,\n",
      "                'balance_input_data': False,\n",
      "                'benchmarking': {'benchmark_dataset': <BenchmarkDataset.MNIST: {'name': 'mnist', 'target_cols': ['n_0', 'n_1', 'n_2', 'n_3', 'n_4', 'n_5', 'n_6', 'n_7', 'n_8', 'n_9']}>,\n",
      "                                 'tasks': [<MNIST_TASK.N_0: 'n_0'>,\n",
      "                                           <MNIST_TASK.N_1: 'n_1'>,\n",
      "                                           <MNIST_TASK.N_2: 'n_2'>,\n",
      "                                           <MNIST_TASK.N_3: 'n_3'>,\n",
      "                                           <MNIST_TASK.N_4: 'n_4'>,\n",
      "                                           <MNIST_TASK.N_5: 'n_5'>,\n",
      "                                           <MNIST_TASK.N_6: 'n_6'>,\n",
      "                                           <MNIST_TASK.N_7: 'n_7'>,\n",
      "                                           <MNIST_TASK.N_8: 'n_8'>,\n",
      "                                           <MNIST_TASK.N_9: 'n_9'>],\n",
      "                                 'use_benchmark_data': False},\n",
      "                'exec_nas': True,\n",
      "                'icao_data': {'aligned': False,\n",
      "                              'icao_dl': {'tagger_model': None,\n",
      "                                          'use_dl_data': False},\n",
      "                              'icao_gt': {'gt_names': {'test': [],\n",
      "                                                       'train_validation': [],\n",
      "                                                       'train_validation_test': [<GTName.FVC: 'fvc'>]},\n",
      "                                          'use_gt_data': True},\n",
      "                              'reqs': [<ICAO_REQ.MOUTH: 'mouth'>,\n",
      "                                       <ICAO_REQ.ROTATION: 'rotation'>,\n",
      "                                       <ICAO_REQ.L_AWAY: 'l_away'>,\n",
      "                                       <ICAO_REQ.EYES_CLOSED: 'eyes_closed'>,\n",
      "                                       <ICAO_REQ.CLOSE: 'close'>,\n",
      "                                       <ICAO_REQ.HAT: 'hat'>,\n",
      "                                       <ICAO_REQ.DARK_GLASSES: 'dark_glasses'>,\n",
      "                                       <ICAO_REQ.FRAMES_HEAVY: 'frames_heavy'>,\n",
      "                                       <ICAO_REQ.FRAME_EYES: 'frame_eyes'>,\n",
      "                                       <ICAO_REQ.FLASH_LENSES: 'flash_lenses'>,\n",
      "                                       <ICAO_REQ.VEIL: 'veil'>,\n",
      "                                       <ICAO_REQ.REFLECTION: 'reflection'>,\n",
      "                                       <ICAO_REQ.LIGHT: 'light'>,\n",
      "                                       <ICAO_REQ.SHADOW_FACE: 'sh_face'>,\n",
      "                                       <ICAO_REQ.SHADOW_HEAD: 'sh_head'>,\n",
      "                                       <ICAO_REQ.BLURRED: 'blurred'>,\n",
      "                                       <ICAO_REQ.INK_MARK: 'ink_mark'>,\n",
      "                                       <ICAO_REQ.SKIN_TONE: 'skin_tone'>,\n",
      "                                       <ICAO_REQ.WASHED_OUT: 'washed_out'>,\n",
      "                                       <ICAO_REQ.PIXELATION: 'pixelation'>,\n",
      "                                       <ICAO_REQ.HAIR_EYES: 'hair_eyes'>,\n",
      "                                       <ICAO_REQ.BACKGROUND: 'background'>,\n",
      "                                       <ICAO_REQ.RED_EYES: 'red_eyes'>]},\n",
      "                'orig_model_experiment_id': '',\n",
      "                'sample_prop': 1.0,\n",
      "                'sample_training_data': False,\n",
      "                'save_trained_model': True,\n",
      "                'train_model': True},\n",
      " 'use_neptune': True}\n",
      "-------------------\n",
      "----\n",
      "Base Model Name:  BaseModel.MOBILENET_V2\n",
      "----\n",
      "MTL Model: True\n",
      "Approach: NAS_MTLApproach.APPROACH_2\n",
      "----\n",
      "--------------------  starting neptune  -------------------\n",
      "Starting Neptune\n",
      "https://ui.neptune.ai/guilhermemg/icao-nets-training-2/e/ICAO-319\n",
      "----\n",
      "----\n",
      "Checking model existence locally...\n",
      "Training a new model! Not checking model existence\n",
      "----\n",
      "------------------------------\n",
      "Checking GPU availability\n",
      " ..GPU is available!\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/anaconda3/envs/mteval-icao-reqs/submodules/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "kwargs = { \n",
    "    'use_neptune': True,\n",
    "    'exp_params' : {\n",
    "        'name': 'neural_arch_search',\n",
    "        'description': 'NAS Approach 2 with FVC-ICAO dataset with 3 trials and patience',\n",
    "        'tags': ['ground_truth', 'nas', 'nas_approach_2', 'fvc'],\n",
    "        'src_files': [\"src\"]\n",
    "    },\n",
    "    'properties': {\n",
    "        'approach': NAS_MTLApproach.APPROACH_2,\n",
    "        'benchmarking': {\n",
    "            'use_benchmark_data': False,\n",
    "            'benchmark_dataset': BenchmarkDataset.MNIST,\n",
    "            'tasks': list(MNIST_TASK)\n",
    "        },\n",
    "        'icao_data': {\n",
    "            'icao_gt': {\n",
    "                'use_gt_data': True,\n",
    "                'gt_names': {\n",
    "                    'train_validation': [],\n",
    "                    'test': [],\n",
    "                    'train_validation_test': [GTName.FVC]\n",
    "                },\n",
    "            },\n",
    "            'icao_dl': {\n",
    "                'use_dl_data': False,\n",
    "                'tagger_model': None\n",
    "            },\n",
    "            'reqs': list(ICAO_REQ),\n",
    "            'aligned': False\n",
    "        },\n",
    "        'balance_input_data': False,\n",
    "        'train_model': True,\n",
    "        'save_trained_model': True,\n",
    "        'exec_nas': True,\n",
    "        'orig_model_experiment_id': '',\n",
    "        'sample_training_data': False,\n",
    "        'sample_prop': 1.0\n",
    "    },\n",
    "    'net_train_params': {\n",
    "        'base_model': BaseModel.MOBILENET_V2,\n",
    "        'batch_size': 32,\n",
    "        'n_epochs': 50,\n",
    "        'early_stopping': 5,\n",
    "        'learning_rate': 1e-3,\n",
    "        'optimizer': Optimizer.ADAMAX,\n",
    "        'dropout': 0.3\n",
    "    },\n",
    "    'nas_params': {\n",
    "        'max_blocks_per_branch': 5,\n",
    "        'controller_epochs': 50,\n",
    "        'controller_batch_size': 32,\n",
    "        'n_trials': 3\n",
    "    }\n",
    "}\n",
    "\n",
    "runner = ExperimentRunner(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- load training data -------------------\n",
      "Loading data\n",
      "Loading GT FVC - TRAIN split...\n",
      "..Ignoring 0 empty label values\n",
      "Input data.shape: (4928, 26)\n",
      "Loading GT FVC - VALIDATION split...\n",
      "..Ignoring 0 empty label values\n",
      "Input data.shape: (547, 26)\n",
      "Loading GT FVC - TEST split...\n",
      "..Ignoring 0 empty label values\n",
      "Input data.shape: (288, 26)\n",
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "runner.load_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>img_name</th>\n",
       "      <th>mouth</th>\n",
       "      <th>rotation</th>\n",
       "      <th>l_away</th>\n",
       "      <th>eyes_closed</th>\n",
       "      <th>close</th>\n",
       "      <th>hat</th>\n",
       "      <th>dark_glasses</th>\n",
       "      <th>frames_heavy</th>\n",
       "      <th>...</th>\n",
       "      <th>sh_head</th>\n",
       "      <th>blurred</th>\n",
       "      <th>ink_mark</th>\n",
       "      <th>skin_tone</th>\n",
       "      <th>washed_out</th>\n",
       "      <th>pixelation</th>\n",
       "      <th>hair_eyes</th>\n",
       "      <th>background</th>\n",
       "      <th>red_eyes</th>\n",
       "      <th>aligned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fvc</td>\n",
       "      <td>/home/guilherme/data1/Dropbox/Link to Desktop/...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fvc</td>\n",
       "      <td>/home/guilherme/data1/Dropbox/Link to Desktop/...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fvc</td>\n",
       "      <td>/home/guilherme/data1/Dropbox/Link to Desktop/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fvc</td>\n",
       "      <td>/home/guilherme/data1/Dropbox/Link to Desktop/...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fvc</td>\n",
       "      <td>/home/guilherme/data1/Dropbox/Link to Desktop/...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  origin                                           img_name  mouth  rotation  \\\n",
       "0    fvc  /home/guilherme/data1/Dropbox/Link to Desktop/...    1.0       1.0   \n",
       "1    fvc  /home/guilherme/data1/Dropbox/Link to Desktop/...    1.0       1.0   \n",
       "2    fvc  /home/guilherme/data1/Dropbox/Link to Desktop/...    0.0       1.0   \n",
       "3    fvc  /home/guilherme/data1/Dropbox/Link to Desktop/...    1.0       1.0   \n",
       "4    fvc  /home/guilherme/data1/Dropbox/Link to Desktop/...    1.0       1.0   \n",
       "\n",
       "   l_away  eyes_closed  close  hat  dark_glasses  frames_heavy  ...  sh_head  \\\n",
       "0     1.0          1.0    1.0  1.0           1.0           1.0  ...      0.0   \n",
       "1     0.0          1.0    1.0  1.0           1.0           1.0  ...      1.0   \n",
       "2     1.0          1.0    1.0  1.0           1.0           1.0  ...      1.0   \n",
       "3     1.0          1.0    1.0  1.0           1.0           1.0  ...      0.0   \n",
       "4     1.0          1.0    1.0  1.0           1.0           1.0  ...      0.0   \n",
       "\n",
       "   blurred  ink_mark  skin_tone  washed_out  pixelation  hair_eyes  \\\n",
       "0      1.0       1.0        1.0         1.0         1.0        1.0   \n",
       "1      1.0       1.0        1.0         1.0         1.0        1.0   \n",
       "2      1.0       1.0        1.0         1.0         1.0        1.0   \n",
       "3      1.0       1.0        0.0         1.0         1.0        1.0   \n",
       "4      1.0       1.0        0.0         1.0         1.0        1.0   \n",
       "\n",
       "   background  red_eyes  aligned  \n",
       "0         1.0       1.0    False  \n",
       "1         1.0       1.0    False  \n",
       "2         1.0       1.0    False  \n",
       "3         0.0       1.0    False  \n",
       "4         0.0       1.0    False  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Producing Fake Data</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "runner.produce_fake_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- setup data generators -------------------\n",
      "Starting data generators\n",
      "Found 4928 validated image filenames.\n",
      "Found 547 validated image filenames.\n",
      "Found 288 validated image filenames.\n",
      "TOTAL: 5763\n",
      "\n",
      "Logging class indices\n",
      " .. MTL model not logging class indices!\n",
      "\n",
      "Logging class labels\n",
      " COMPLIANT label: 1\n",
      " NON_COMPLIANT label: 0\n",
      " DUMMY label: -1\n",
      " DUMMY_CLS label: 2\n",
      " NO_ANSWER label: -99\n"
     ]
    }
   ],
   "source": [
    "runner.setup_data_generators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- create experiment -------------------\n",
      "Setup neptune properties and parameters\n",
      "Properties and parameters setup done!\n"
     ]
    }
   ],
   "source": [
    "runner.setup_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "runner.summary_labels_dist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Architecture Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- run neural architecture search -------------------\n",
      "Executing neural architectural search\n",
      "  Memory reseted\n",
      "\n",
      "==================== STARTING NEW TRIAL ====================\n",
      " selecting new config...\n",
      "  Memory is empty\n",
      " controller_pred: [[0.39429787 0.148866   0.24217187 0.2146643 ]]\n",
      "\n",
      "\n",
      " ------ Training 1 | Config: {'n_denses_0': 2, 'n_denses_1': 1, 'n_denses_2': 2, 'n_denses_3': 2} -----\n",
      "\n",
      "Creating model...\n",
      "Model created\n",
      "Training MOBILENET_V2 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 4,233,966\n",
      "  .. Trainable params: 1,975,982\n",
      "  .. Non-trainable params: 2,257,984\n"
     ]
    }
   ],
   "source": [
    "runner.run_neural_architeture_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model with Best Config Found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.visualize_model(outfile_path=f\"figs/nas/nas_model_approach_2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "runner.model_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.draw_training_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.load_best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.set_model_evaluator_data_src(DataSource.VALIDATION)\n",
    "runner.test_model(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.set_model_evaluator_data_src(DataSource.TEST)\n",
    "runner.test_model(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Model Classification"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "runner.visualize_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finishing Experiment Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.finish_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Network Modification"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Input, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_tensor = Input(shape=(20,), name=\"input\")\n",
    "hidden = Dense(100, activation='relu')(input_tensor)\n",
    "out = Dense(10, activation='relu', name=\"out\")(hidden)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=out)\n",
    "model.compile(loss=\"mse\", optimizer='adam')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "out = Dense(5, activation='softmax', name='new_out')(model.layers[-2].output)\n",
    "\n",
    "new_model = Model(input_tensor, out)\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test - Customized Loss Function"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Input, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "def my_loss_func(y_true, y_pred):\n",
    "    print(y_true, y_pred)\n",
    "    squared_difference = tf.square(y_true - y_pred)\n",
    "    return tf.reduce_mean(squared_difference, axis=-1)\n",
    "\n",
    "\n",
    "def _controller_loss(y_true, y_pred):\n",
    "    baseline = None\n",
    "    baseline_decay = 0.999\n",
    "    reward = 0\n",
    "\n",
    "    if baseline is None:\n",
    "        baseline = 0\n",
    "    else:\n",
    "        baseline -= (1 - baseline_decay) * (baseline - reward)\n",
    "    return y_pred * (reward - baseline)\n",
    "\n",
    "def _define_loss(controller_loss):\n",
    "    print(controller_loss)\n",
    "    a =  {f\"out\": controller_loss for i in range(4)}\n",
    "    print(a)\n",
    "    return a\n",
    "\n",
    "\n",
    "\n",
    "input_tensor = Input(shape=(4), name=\"input\")\n",
    "hidden = Dense(64, activation='relu')(input_tensor)\n",
    "out = Dense(4, activation='softmax', name=\"out\")(hidden)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=out)\n",
    "#model.compile(loss=my_loss_func, optimizer='adam')\n",
    "model.compile(loss=_define_loss(_controller_loss), optimizer='adam')\n",
    "\n",
    "#print(model.summary())\n",
    "\n",
    "#x = np.random.rand(4,4)\n",
    "#y = np.random.rand(4,1)\n",
    "\n",
    "x = np.matrix([[2,1,4,5], [3,4,5,2]], dtype='float32').A\n",
    "y = np.array([4,2], dtype='float32')\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "H = model.fit(x, y, epochs=3, batch_size=1)\n",
    "H.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "# disable tensorflow log level infos\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # show only errors\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def __create_rnn_model():\n",
    "    model = Sequential([\n",
    "        Dense(4, activation=\"relu\"),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(4, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(), metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "def __preprocess_config(config):\n",
    "    return np.linalg.norm(config)\n",
    "    \n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "X = np.random.rand(400,4)\n",
    "y = np.random.rand(400,4)\n",
    "\n",
    "# X = tf.expand_dims(X, axis=0)\n",
    "# y = np.expand_dims(y, axis=0)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "X_test = np.random.rand(20,4)\n",
    "y_test = np.random.rand(20,4)\n",
    "\n",
    "# X_test = tf.expand_dims(X_test, axis=0)\n",
    "# y_test = tf.expand_dims(y_test, axis=0)\n",
    "\n",
    "m = __create_rnn_model()\n",
    "\n",
    "m.fit(X,y, batch_size=32, epochs=5)\n",
    "\n",
    "loss, acc = m.evaluate(X_test,y_test, batch_size=32)\n",
    "\n",
    "print(f'loss: {loss}%')\n",
    "print(f'acc: {round(acc*100,2)}%')\n",
    "\n",
    "print(f'prediction: {m.predict(np.array(X_test[0]).reshape(1,4))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Add, Concatenate, Embedding, LSTM, LSTMCell, RNN, Reshape\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import losses, metrics\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.initializers import RandomUniform, HeNormal, GlorotNormal\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def get_weight_initializer(initializer=None, seed=None):\n",
    "    if initializer is None:\n",
    "        return HeNormal()\n",
    "    elif initializer == \"lstm\":\n",
    "        return RandomUniform(minval=-0.1, maxval=0.1)\n",
    "    else:\n",
    "        return GlorotNormal()\n",
    "\n",
    "\n",
    "def get_weight_regularizer(regularizer=None, rate=1e-4):\n",
    "    if regularizer is None:\n",
    "        return regularizers.l2(rate)\n",
    "    else:\n",
    "        return regularizer(rate)\n",
    "\n",
    "\n",
    "class ControllerRNNController(object):\n",
    "    def __init__(self,\n",
    "                 controller_network_name,\n",
    "                 num_nodes,\n",
    "                 num_opers,\n",
    "                 input_x,\n",
    "                 reward=0,\n",
    "                 temperature=5.0,\n",
    "                 tanh_constant=2.5,\n",
    "                 model_file=None,\n",
    "                 lstm_cell_units=32,\n",
    "                 baseline_decay=0.999,\n",
    "                 opt=Adam(learning_rate=0.00035, decay=1e-3, amsgrad=True)):\n",
    "\n",
    "        self.controller_network_name = controller_network_name\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_opers = num_opers\n",
    "        self.reward = reward\n",
    "        self.input_x = input_x\n",
    "        self.temperature = temperature\n",
    "        self.tanh_constant = tanh_constant\n",
    "        self.lstm_cell_units = lstm_cell_units\n",
    "        self.opt = opt\n",
    "        self.model_file = model_file\n",
    "\n",
    "        self.controller_rnn = self.generate_controller_rnn()\n",
    "        self.baseline = None\n",
    "        self.baseline_decay = baseline_decay\n",
    "\n",
    "        #self.graph = tf.get_default_graph()\n",
    "\n",
    "    def lstm_reshape(self,\n",
    "                     inputs,\n",
    "                     name_prefix,\n",
    "                     index,\n",
    "                     reshaped_inputs=None,\n",
    "                     initial=False):\n",
    "        name_prefix = \"{0}_{1}_{2}\".format(self.controller_network_name,\n",
    "                                           name_prefix, index)\n",
    "        cell = LSTMCell(\n",
    "            self.lstm_cell_units,\n",
    "            kernel_initializer=get_weight_initializer(initializer=\"lstm\"),\n",
    "            recurrent_initializer=get_weight_initializer(initializer=\"lstm\"))\n",
    "        if initial:\n",
    "            x = RNN(\n",
    "                cell,\n",
    "                return_state=True,\n",
    "                name=\"{0}_{1}\".format(name_prefix, \"lstm\"))(inputs)\n",
    "        else:\n",
    "            x = RNN(\n",
    "                cell,\n",
    "                return_state=True,\n",
    "                name=\"{0}_{1}\".format(name_prefix, \"lstm\"))(\n",
    "                    reshaped_inputs, initial_state=inputs[1:])\n",
    "        rx = Reshape(\n",
    "            (-1, self.lstm_cell_units),\n",
    "            name=\"{0}_{1}\".format(name_prefix, \"reshape\"))(x[0])\n",
    "        return x, rx\n",
    "\n",
    "    def dense_softmax(self, inputs, num_classes, name_prefix, index):\n",
    "        name_prefix = \"{0}_{1}_{2}\".format(self.controller_network_name,\n",
    "                                           name_prefix, index)\n",
    "        y = Dense(\n",
    "            num_classes, name=\"{0}_{1}\".format(name_prefix, \"dense\"))(inputs)\n",
    "        y = Activation(\n",
    "            activation=\"softmax\",\n",
    "            name=\"{0}_{1}\".format(name_prefix, \"softmax\"))(y)\n",
    "        return y\n",
    "\n",
    "    def generate_controller_rnn(self):\n",
    "        outputs = []\n",
    "        controller_input = Input(shape=(1, 1,), name=\"{0}_{1}\".format(self.controller_network_name, \"input\"))\n",
    "\n",
    "        for i in range(2, self.num_nodes):\n",
    "            for o in [\"inputL\", \"inputR\", \"operL\", \"operR\"]:\n",
    "                if i == 2 and o == \"inputL\":\n",
    "                    _x, _rx, _initial = controller_input, None, True\n",
    "                else:\n",
    "                    _x, _rx, _initial = x, rx, False\n",
    "\n",
    "                if o in [\"inputL\", \"inputR\"]:\n",
    "                    _num_classes = i\n",
    "                else:\n",
    "                    _num_classes = self.num_opers\n",
    "\n",
    "                x, rx = self.lstm_reshape(\n",
    "                    inputs=_x,\n",
    "                    name_prefix=o,\n",
    "                    index=i,\n",
    "                    reshaped_inputs=_rx,\n",
    "                    initial=_initial)\n",
    "                y = self.dense_softmax(\n",
    "                    inputs=x[0],\n",
    "                    num_classes=_num_classes,\n",
    "                    name_prefix=o,\n",
    "                    index=i)\n",
    "                outputs.append(y)\n",
    "\n",
    "        controller_rnn = Model(inputs=controller_input, outputs=outputs)\n",
    "\n",
    "        if self.model_file is not None and os.path.exists(self.model_file):\n",
    "            controller_rnn.load_weights(self.model_file)\n",
    "        return controller_rnn\n",
    "\n",
    "    def compile_controller_rnn(self):\n",
    "        def _controller_loss(y_true, y_pred):\n",
    "            if self.baseline is None:\n",
    "                self.baseline = 0\n",
    "            else:\n",
    "                self.baseline -= (1 - self.baseline_decay) * (self.baseline - self.reward)\n",
    "            return y_pred * (self.reward - self.baseline)\n",
    "\n",
    "        def _define_loss(controller_loss):\n",
    "            outputs_loss = {}\n",
    "            for i in range(2, self.num_nodes):\n",
    "                outputs_loss[\"{0}_{1}_{2}_{3}\".format(self.controller_network_name, \"inputL\", i, \"softmax\")] = controller_loss\n",
    "                outputs_loss[\"{0}_{1}_{2}_{3}\".format(self.controller_network_name, \"inputR\", i, \"softmax\")] = controller_loss\n",
    "                outputs_loss[\"{0}_{1}_{2}_{3}\".format(self.controller_network_name, \"operL\", i, \"softmax\")] = controller_loss\n",
    "                outputs_loss[\"{0}_{1}_{2}_{3}\".format(self.controller_network_name, \"operR\", i, \"softmax\")] = controller_loss\n",
    "            return outputs_loss\n",
    "\n",
    "        self.controller_rnn.compile(loss=_define_loss(_controller_loss), optimizer=self.opt)\n",
    "\n",
    "    def save_model(self):\n",
    "        self.controller_rnn.save_weights(self.model_file)\n",
    "\n",
    "    def train_controller_rnn(self,\n",
    "                             targets,\n",
    "                             batch_size=1,\n",
    "                             epochs=50,\n",
    "                             callbacks=[EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')]):\n",
    "        #with self.graph.as_default():\n",
    "        self.compile_controller_rnn()\n",
    "        self.controller_rnn.fit(\n",
    "            self.input_x,\n",
    "            targets,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=0)\n",
    "\n",
    "    def softmax_predict(self):\n",
    "        #with self.graph.as_default():\n",
    "        self.compile_controller_rnn()\n",
    "        return self.controller_rnn.predict(self.input_x)\n",
    "\n",
    "    def random_sample_softmax(self, controller_pred):\n",
    "        sample_softmax = []\n",
    "        for cp in controller_pred:\n",
    "            cp /= self.temperature\n",
    "            cp = self.tanh_constant * np.tanh(cp)\n",
    "            cp = np.exp(cp) / np.sum(np.exp(cp))\n",
    "            cp = np.array([np.random.multinomial(1, cp[0])])\n",
    "            sample_softmax.append(cp)\n",
    "        return sample_softmax\n",
    "\n",
    "    def convert_pred_to_cell(self, controller_pred):\n",
    "        cell_pred = {}\n",
    "        for p in range(2, self.num_nodes):\n",
    "            pos = list(range((p - 2) * 4, ((p - 2) * 4) + 4))\n",
    "            cell_pred[p] = {\n",
    "                \"L\": {\n",
    "                    \"input_layer\": np.argmax(controller_pred[pos[0]]),\n",
    "                    \"oper_id\": np.argmax(controller_pred[pos[2]])\n",
    "                },\n",
    "                \"R\": {\n",
    "                    \"input_layer\": np.argmax(controller_pred[pos[1]]),\n",
    "                    \"oper_id\": np.argmax(controller_pred[pos[3]])\n",
    "                }\n",
    "            }\n",
    "        return cell_pred\n",
    "\n",
    "    def convert_pred_to_ydict(self, controller_pred):\n",
    "        ydict = {}\n",
    "        name_prefix = self.controller_network_name\n",
    "        for i in range(2, self.num_nodes):\n",
    "            pos = list(range((i - 2) * 4, ((i - 2) * 4) + 4))\n",
    "            ydict[\"{0}_{1}_{2}_{3}\".format(name_prefix, \"inputL\", i, \"softmax\")] = controller_pred[pos[0]]\n",
    "            ydict[\"{0}_{1}_{2}_{3}\".format(name_prefix, \"inputR\", i, \"softmax\")] = controller_pred[pos[1]]\n",
    "            ydict[\"{0}_{1}_{2}_{3}\".format(name_prefix, \"operL\", i, \"softmax\")] = controller_pred[pos[2]]\n",
    "            ydict[\"{0}_{1}_{2}_{3}\".format(name_prefix, \"operR\", i, \"softmax\")] = controller_pred[pos[3]]\n",
    "        return ydict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contr = ControllerRNNController(\"netname\", num_nodes=3, num_opers=3, input_x=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "#contr.controller_rnn.summary()\n",
    "plot_model(contr.controller_rnn, expand_nested=True, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "# disable tensorflow log level infos\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # show only errors\n",
    "\n",
    "inputs = tf.random.normal([32, 10, 8])\n",
    "lstm = tf.keras.layers.LSTM(4, return_sequences=True, return_state=True)\n",
    "\n",
    "whole_seq_output, final_memory_state, final_carry_state = lstm(inputs)\n",
    "\n",
    "print(whole_seq_output.shape, final_memory_state.shape, final_carry_state.shape)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "85f5044ba23e75135dc4c908fd4d7609c1c80b195047fdb4d16ee0e66a953254"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
