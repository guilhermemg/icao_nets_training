{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> Restrict GPU memory growth: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# disable tensorflow log level infos\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # show only errors\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "if '../../../../notebooks/' not in sys.path:\n",
    "    sys.path.append('../../../../notebooks/')\n",
    "if 'src' not in sys.path:\n",
    "    sys.path.insert(0, 'src')\n",
    "\n",
    "import utils.constants as cts\n",
    "\n",
    "from data_loaders.data_loader import DLName\n",
    "from gt_loaders.gt_names import GTName\n",
    "from exp_runner import ExperimentRunner\n",
    "from base.model_evaluator import DataSource, DataPredSelection\n",
    "from base.base_models import BaseModel\n",
    "from base.optimizers import Optimizer\n",
    "from base.model_creator import MTLApproach, NAS_MTLApproach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Network runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Init ExperimentRunner -------------------\n",
      "---------------------------\n",
      "Parent Process ID: 134774\n",
      "Process ID: 145049\n",
      "---------------------------\n",
      "-----\n",
      "Use Neptune:  False\n",
      "-----\n",
      "-------------------\n",
      "Args: \n",
      "{'exp_params': {'description': 'Making NAS with APPROACH_1 (random) and '\n",
      "                               'training best architecture for 50 epochs to '\n",
      "                               'evaluate on test set',\n",
      "                'name': 'neural_arch_search',\n",
      "                'src_files': ['src/**/*.py'],\n",
      "                'tags': ['ground truths', 'nas', 'nas_approach_1']},\n",
      " 'nas_params': {'controller_batch_size': 32,\n",
      "                'controller_epochs': 50,\n",
      "                'max_blocks_per_branch': 5,\n",
      "                'n_trials': 3},\n",
      " 'net_train_params': {'base_model': <BaseModel.VGG16: {'target_size': (224, 224), 'prep_function': <function preprocess_input at 0x7f36e780a430>}>,\n",
      "                      'batch_size': 32,\n",
      "                      'dropout': 0.3,\n",
      "                      'early_stopping': 99,\n",
      "                      'learning_rate': 0.001,\n",
      "                      'n_epochs': 50,\n",
      "                      'optimizer': <Optimizer.ADAMAX: 'Adamax'>},\n",
      " 'properties': {'aligned': True,\n",
      "                'approach': <NAS_MTLApproach.APPROACH_2: 'approach_2'>,\n",
      "                'balance_input_data': False,\n",
      "                'exec_nas': True,\n",
      "                'gt_names': {'test': [],\n",
      "                             'train_validation': [],\n",
      "                             'train_validation_test': [<GTName.FVC: 'fvc'>]},\n",
      "                'orig_model_experiment_id': '',\n",
      "                'reqs': [<ICAO_REQ.MOUTH: 'mouth'>,\n",
      "                         <ICAO_REQ.ROTATION: 'rotation'>,\n",
      "                         <ICAO_REQ.L_AWAY: 'l_away'>,\n",
      "                         <ICAO_REQ.EYES_CLOSED: 'eyes_closed'>,\n",
      "                         <ICAO_REQ.CLOSE: 'close'>,\n",
      "                         <ICAO_REQ.HAT: 'hat'>,\n",
      "                         <ICAO_REQ.DARK_GLASSES: 'dark_glasses'>,\n",
      "                         <ICAO_REQ.FRAMES_HEAVY: 'frames_heavy'>,\n",
      "                         <ICAO_REQ.FRAME_EYES: 'frame_eyes'>,\n",
      "                         <ICAO_REQ.FLASH_LENSES: 'flash_lenses'>,\n",
      "                         <ICAO_REQ.VEIL: 'veil'>,\n",
      "                         <ICAO_REQ.REFLECTION: 'reflection'>,\n",
      "                         <ICAO_REQ.LIGHT: 'light'>,\n",
      "                         <ICAO_REQ.SHADOW_FACE: 'sh_face'>,\n",
      "                         <ICAO_REQ.SHADOW_HEAD: 'sh_head'>,\n",
      "                         <ICAO_REQ.BLURRED: 'blurred'>,\n",
      "                         <ICAO_REQ.INK_MARK: 'ink_mark'>,\n",
      "                         <ICAO_REQ.SKIN_TONE: 'skin_tone'>,\n",
      "                         <ICAO_REQ.WASHED_OUT: 'washed_out'>,\n",
      "                         <ICAO_REQ.PIXELATION: 'pixelation'>,\n",
      "                         <ICAO_REQ.HAIR_EYES: 'hair_eyes'>,\n",
      "                         <ICAO_REQ.BACKGROUND: 'background'>,\n",
      "                         <ICAO_REQ.RED_EYES: 'red_eyes'>],\n",
      "                'sample_prop': 1.0,\n",
      "                'sample_training_data': False,\n",
      "                'save_trained_model': True,\n",
      "                'train_model': True,\n",
      "                'use_gt_data': True},\n",
      " 'use_neptune': False}\n",
      "-------------------\n",
      "----\n",
      "Base Model Name:  BaseModel.VGG16\n",
      "----\n",
      "-------------------- start neptune -------------------\n",
      "Not using Neptune to record Experiment Metadata\n",
      "----\n",
      "MTL Model: True\n",
      "Approach: NAS_MTLApproach.APPROACH_2\n",
      "----\n",
      "----\n",
      "Checking model existence locally...\n",
      "Training a new model! Not checking model existence\n",
      "----\n",
      "------------------------------\n",
      "Checking GPU availability\n",
      " ..GPU is available!\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/anaconda3/envs/mteval-icao-reqs/submodules/icao_nets_training/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "kwargs = { \n",
    "    'use_neptune': False,\n",
    "    'exp_params' : {\n",
    "        'name': 'neural_arch_search',\n",
    "        'description': 'Making NAS with APPROACH_1 (random) and training best architecture for 50 epochs to evaluate on test set',\n",
    "        'tags': ['ground truths', 'nas', 'nas_approach_1'],\n",
    "        'src_files': [\"src/**/*.py\"]\n",
    "    },\n",
    "    'properties': {\n",
    "        'approach': NAS_MTLApproach.APPROACH_2,\n",
    "        'reqs': list(cts.ICAO_REQ),\n",
    "        'aligned': True,\n",
    "        'use_gt_data': True,\n",
    "        'gt_names': {\n",
    "            'train_validation': [],\n",
    "            'test': [],\n",
    "            'train_validation_test': [GTName.FVC]\n",
    "        },\n",
    "        'balance_input_data': False,\n",
    "        'train_model': True,\n",
    "        'save_trained_model': True,\n",
    "        'exec_nas': True,\n",
    "        'orig_model_experiment_id': '',\n",
    "        'sample_training_data': False,\n",
    "        'sample_prop': 1.0\n",
    "    },\n",
    "    'net_train_params': {\n",
    "        'base_model': BaseModel.VGG16,\n",
    "        'batch_size': 32,\n",
    "        'n_epochs': 50,\n",
    "        'early_stopping': 99,\n",
    "        'learning_rate': 1e-3,\n",
    "        'optimizer': Optimizer.ADAMAX,\n",
    "        'dropout': 0.3\n",
    "    },\n",
    "    'nas_params': {\n",
    "        'max_blocks_per_branch': 5,\n",
    "        'controller_epochs': 50,\n",
    "        'controller_batch_size': 32,\n",
    "        'n_trials': 3\n",
    "    }\n",
    "}\n",
    "\n",
    "runner = ExperimentRunner(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- load training data -------------------\n",
      "Loading data\n",
      "Loading GT FVC - TRAIN split...\n",
      "..Ignoring 0 empty label values\n",
      "Input data.shape: (4926, 26)\n",
      "Loading GT FVC - VALIDATION split...\n",
      "..Ignoring 0 empty label values\n",
      "Input data.shape: (547, 26)\n",
      "Loading GT FVC - TEST split...\n",
      "..Ignoring 0 empty label values\n",
      "Input data.shape: (288, 26)\n",
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "runner.load_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Producing Fake Data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- producing fake data for experimental purposes -------------------\n",
      "fake_train_data.shape: (500, 26)\n",
      "fake_validation_data_df.shape: (100, 26)\n",
      "fake_test_data_df.shape: (50, 26)\n"
     ]
    }
   ],
   "source": [
    "runner.produce_fake_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- setup data generators -------------------\n",
      "Starting data generators\n",
      "Found 500 validated image filenames.\n",
      "Found 100 validated image filenames.\n",
      "Found 50 validated image filenames.\n",
      "TOTAL: 650\n",
      "\n",
      "Logging class indices\n",
      " .. MTL model not logging class indices!\n",
      "\n",
      "Logging class labels\n",
      " COMPLIANT label: 1\n",
      " NON_COMPLIANT label: 0\n",
      " DUMMY label: -1\n",
      " DUMMY_CLS label: 2\n",
      " NO_ANSWER label: -99\n"
     ]
    }
   ],
   "source": [
    "runner.setup_data_generators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- create experiment -------------------\n",
      "Not using Neptune\n"
     ]
    }
   ],
   "source": [
    "runner.setup_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "runner.summary_labels_dist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Architecture Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- run neural architecture search -------------------\n",
      "Executing neural architectural search\n",
      "  Memory reseted\n",
      "\n",
      "==================== STARTING NEW TRIAL ====================\n",
      " selecting new config...\n",
      "  Memory is empty\n",
      " controller_pred: [[0.25900057 0.30553287 0.19277617 0.24269034]]\n",
      "\n",
      "\n",
      " ------ Training 1 | Config: {'n_denses_0': 2, 'n_denses_1': 2, 'n_denses_2': 1, 'n_denses_3': 2} -----\n",
      "\n",
      "Creating model...\n",
      "Model created\n",
      "Training VGG16 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 15,535,214\n",
      "  .. Trainable params: 820,526\n",
      "  .. Non-trainable params: 14,714,688\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.59726, saving model to training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "4/4 [==============================] - 1s 320ms/step\n",
      "Prediction finished!\n",
      "final_EER_mean: 50.77% | final_ACC: 49.23%\n",
      " .. training controller rnn ..\n",
      "  .. targets: [[0.25900057 0.30553287 0.19277617 0.24269034]]\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 12.2829\n",
      "  Loss: 12.2829\n",
      "====================FINISHING TRIAL====================\n",
      "\n",
      "\n",
      "==================== STARTING NEW TRIAL ====================\n",
      " selecting new config...\n",
      "  Memory is not empty\n",
      " controller_pred: [[0.24416286 0.2589955  0.24290177 0.2539399 ]]\n",
      "\n",
      "\n",
      " ------ Training 2 | Config: {'n_denses_0': 2, 'n_denses_1': 2, 'n_denses_2': 2, 'n_denses_3': 2} -----\n",
      "\n",
      "Creating model...\n",
      "Model created\n",
      "Training VGG16 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 15,568,494\n",
      "  .. Trainable params: 853,806\n",
      "  .. Non-trainable params: 14,714,688\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.59793, saving model to training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "4/4 [==============================] - 1s 71ms/step\n",
      "Prediction finished!\n",
      "final_EER_mean: 49.41% | final_ACC: 50.59%\n",
      " .. training controller rnn ..\n",
      "  .. targets: [[0.24416286 0.2589955  0.24290177 0.2539399 ]]\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 12.5977\n",
      "  Loss: 12.5977\n",
      "====================FINISHING TRIAL====================\n",
      "\n",
      "\n",
      "==================== STARTING NEW TRIAL ====================\n",
      " selecting new config...\n",
      "  Memory is not empty\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3783900430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      " controller_pred: [[0.24501018 0.25599924 0.23781113 0.2611795 ]]\n",
      "\n",
      "\n",
      " ------ Training 3 | Config: {'n_denses_0': 2, 'n_denses_1': 2, 'n_denses_2': 2, 'n_denses_3': 2} -----\n",
      "\n",
      "Creating model...\n",
      "Model created\n",
      "Training VGG16 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 15,568,494\n",
      "  .. Trainable params: 853,806\n",
      "  .. Non-trainable params: 14,714,688\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7f362c62f3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.59651, saving model to training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f35feee51f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "4/4 [==============================] - 1s 70ms/step\n",
      "Prediction finished!\n",
      "final_EER_mean: 50.56% | final_ACC: 49.45%\n",
      " .. training controller rnn ..\n",
      "  .. targets: [[0.24501018 0.25599924 0.23781113 0.2611795 ]]\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f36e3b17550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 12.2880\n",
      "  Loss: 12.288\n",
      "====================FINISHING TRIAL====================\n",
      "\n",
      "Trial: \n",
      "  num: 1\n",
      "  config: {'n_denses_0': 2, 'n_denses_1': 2, 'n_denses_2': 1, 'n_denses_3': 2}\n",
      "  result: {'final_EER_mean': 50.77, 'final_ACC': 49.23}\n",
      "Trial: \n",
      "  num: 2\n",
      "  config: {'n_denses_0': 2, 'n_denses_1': 2, 'n_denses_2': 2, 'n_denses_3': 2}\n",
      "  result: {'final_EER_mean': 49.41, 'final_ACC': 50.59}\n",
      "Trial: \n",
      "  num: 3\n",
      "  config: {'n_denses_0': 2, 'n_denses_1': 2, 'n_denses_2': 2, 'n_denses_3': 2}\n",
      "  result: {'final_EER_mean': 50.56, 'final_ACC': 49.45}\n",
      "\n",
      "best_trial: Trial: \n",
      "  num: 2\n",
      "  config: {'n_denses_0': 2, 'n_denses_1': 2, 'n_denses_2': 2, 'n_denses_3': 2}\n",
      "  result: {'final_EER_mean': 49.41, 'final_ACC': 50.59}\n",
      "\n",
      "best_config: {'n_denses_0': 2, 'n_denses_1': 2, 'n_denses_2': 2, 'n_denses_3': 2}\n"
     ]
    }
   ],
   "source": [
    "runner.run_neural_architeture_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config = {'n_denses_0': 5, 'n_denses_1': 1, 'n_denses_2': 4, 'n_denses_3': 5}\n",
    "runner.create_model(best_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.visualize_model(outfile_path=f\"figs/nas/nas_model_approach_1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "runner.model_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.draw_training_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.load_best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.set_model_evaluator_data_src(DataSource.VALIDATION)\n",
    "runner.test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.set_model_evaluator_data_src(DataSource.TEST)\n",
    "runner.test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Model Classification"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "runner.visualize_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finishing Experiment Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.finish_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Network Modification"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Input, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_tensor = Input(shape=(20,), name=\"input\")\n",
    "hidden = Dense(100, activation='relu')(input_tensor)\n",
    "out = Dense(10, activation='relu', name=\"out\")(hidden)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=out)\n",
    "model.compile(loss=\"mse\", optimizer='adam')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "out = Dense(5, activation='softmax', name='new_out')(model.layers[-2].output)\n",
    "\n",
    "new_model = Model(input_tensor, out)\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test - Customized Loss Function"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Input, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "def my_loss_func(y_true, y_pred):\n",
    "    print(y_true, y_pred)\n",
    "    squared_difference = tf.square(y_true - y_pred)\n",
    "    return tf.reduce_mean(squared_difference, axis=-1)\n",
    "\n",
    "\n",
    "def _controller_loss(y_true, y_pred):\n",
    "    baseline = None\n",
    "    baseline_decay = 0.999\n",
    "    reward = 0\n",
    "\n",
    "    if baseline is None:\n",
    "        baseline = 0\n",
    "    else:\n",
    "        baseline -= (1 - baseline_decay) * (baseline - reward)\n",
    "    return y_pred * (reward - baseline)\n",
    "\n",
    "def _define_loss(controller_loss):\n",
    "    print(controller_loss)\n",
    "    a =  {f\"out\": controller_loss for i in range(4)}\n",
    "    print(a)\n",
    "    return a\n",
    "\n",
    "\n",
    "\n",
    "input_tensor = Input(shape=(4), name=\"input\")\n",
    "hidden = Dense(64, activation='relu')(input_tensor)\n",
    "out = Dense(4, activation='softmax', name=\"out\")(hidden)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=out)\n",
    "#model.compile(loss=my_loss_func, optimizer='adam')\n",
    "model.compile(loss=_define_loss(_controller_loss), optimizer='adam')\n",
    "\n",
    "#print(model.summary())\n",
    "\n",
    "#x = np.random.rand(4,4)\n",
    "#y = np.random.rand(4,1)\n",
    "\n",
    "x = np.matrix([[2,1,4,5], [3,4,5,2]], dtype='float32').A\n",
    "y = np.array([4,2], dtype='float32')\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "H = model.fit(x, y, epochs=3, batch_size=1)\n",
    "H.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "# disable tensorflow log level infos\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # show only errors\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def __create_rnn_model():\n",
    "    model = Sequential([\n",
    "        Dense(4, activation=\"relu\"),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(4, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(), metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "def __preprocess_config(config):\n",
    "    return np.linalg.norm(config)\n",
    "    \n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "X = np.random.rand(400,4)\n",
    "y = np.random.rand(400,4)\n",
    "\n",
    "# X = tf.expand_dims(X, axis=0)\n",
    "# y = np.expand_dims(y, axis=0)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "X_test = np.random.rand(20,4)\n",
    "y_test = np.random.rand(20,4)\n",
    "\n",
    "# X_test = tf.expand_dims(X_test, axis=0)\n",
    "# y_test = tf.expand_dims(y_test, axis=0)\n",
    "\n",
    "m = __create_rnn_model()\n",
    "\n",
    "m.fit(X,y, batch_size=32, epochs=5)\n",
    "\n",
    "loss, acc = m.evaluate(X_test,y_test, batch_size=32)\n",
    "\n",
    "print(f'loss: {loss}%')\n",
    "print(f'acc: {round(acc*100,2)}%')\n",
    "\n",
    "print(f'prediction: {m.predict(np.array(X_test[0]).reshape(1,4))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Add, Concatenate, Embedding, LSTM, LSTMCell, RNN, Reshape\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import losses, metrics\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.initializers import RandomUniform, HeNormal, GlorotNormal\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def get_weight_initializer(initializer=None, seed=None):\n",
    "    if initializer is None:\n",
    "        return HeNormal()\n",
    "    elif initializer == \"lstm\":\n",
    "        return RandomUniform(minval=-0.1, maxval=0.1)\n",
    "    else:\n",
    "        return GlorotNormal()\n",
    "\n",
    "\n",
    "def get_weight_regularizer(regularizer=None, rate=1e-4):\n",
    "    if regularizer is None:\n",
    "        return regularizers.l2(rate)\n",
    "    else:\n",
    "        return regularizer(rate)\n",
    "\n",
    "\n",
    "class ControllerRNNController(object):\n",
    "    def __init__(self,\n",
    "                 controller_network_name,\n",
    "                 num_nodes,\n",
    "                 num_opers,\n",
    "                 input_x,\n",
    "                 reward=0,\n",
    "                 temperature=5.0,\n",
    "                 tanh_constant=2.5,\n",
    "                 model_file=None,\n",
    "                 lstm_cell_units=32,\n",
    "                 baseline_decay=0.999,\n",
    "                 opt=Adam(learning_rate=0.00035, decay=1e-3, amsgrad=True)):\n",
    "\n",
    "        self.controller_network_name = controller_network_name\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_opers = num_opers\n",
    "        self.reward = reward\n",
    "        self.input_x = input_x\n",
    "        self.temperature = temperature\n",
    "        self.tanh_constant = tanh_constant\n",
    "        self.lstm_cell_units = lstm_cell_units\n",
    "        self.opt = opt\n",
    "        self.model_file = model_file\n",
    "\n",
    "        self.controller_rnn = self.generate_controller_rnn()\n",
    "        self.baseline = None\n",
    "        self.baseline_decay = baseline_decay\n",
    "\n",
    "        #self.graph = tf.get_default_graph()\n",
    "\n",
    "    def lstm_reshape(self,\n",
    "                     inputs,\n",
    "                     name_prefix,\n",
    "                     index,\n",
    "                     reshaped_inputs=None,\n",
    "                     initial=False):\n",
    "        name_prefix = \"{0}_{1}_{2}\".format(self.controller_network_name,\n",
    "                                           name_prefix, index)\n",
    "        cell = LSTMCell(\n",
    "            self.lstm_cell_units,\n",
    "            kernel_initializer=get_weight_initializer(initializer=\"lstm\"),\n",
    "            recurrent_initializer=get_weight_initializer(initializer=\"lstm\"))\n",
    "        if initial:\n",
    "            x = RNN(\n",
    "                cell,\n",
    "                return_state=True,\n",
    "                name=\"{0}_{1}\".format(name_prefix, \"lstm\"))(inputs)\n",
    "        else:\n",
    "            x = RNN(\n",
    "                cell,\n",
    "                return_state=True,\n",
    "                name=\"{0}_{1}\".format(name_prefix, \"lstm\"))(\n",
    "                    reshaped_inputs, initial_state=inputs[1:])\n",
    "        rx = Reshape(\n",
    "            (-1, self.lstm_cell_units),\n",
    "            name=\"{0}_{1}\".format(name_prefix, \"reshape\"))(x[0])\n",
    "        return x, rx\n",
    "\n",
    "    def dense_softmax(self, inputs, num_classes, name_prefix, index):\n",
    "        name_prefix = \"{0}_{1}_{2}\".format(self.controller_network_name,\n",
    "                                           name_prefix, index)\n",
    "        y = Dense(\n",
    "            num_classes, name=\"{0}_{1}\".format(name_prefix, \"dense\"))(inputs)\n",
    "        y = Activation(\n",
    "            activation=\"softmax\",\n",
    "            name=\"{0}_{1}\".format(name_prefix, \"softmax\"))(y)\n",
    "        return y\n",
    "\n",
    "    def generate_controller_rnn(self):\n",
    "        outputs = []\n",
    "        controller_input = Input(shape=(1, 1,), name=\"{0}_{1}\".format(self.controller_network_name, \"input\"))\n",
    "\n",
    "        for i in range(2, self.num_nodes):\n",
    "            for o in [\"inputL\", \"inputR\", \"operL\", \"operR\"]:\n",
    "                if i == 2 and o == \"inputL\":\n",
    "                    _x, _rx, _initial = controller_input, None, True\n",
    "                else:\n",
    "                    _x, _rx, _initial = x, rx, False\n",
    "\n",
    "                if o in [\"inputL\", \"inputR\"]:\n",
    "                    _num_classes = i\n",
    "                else:\n",
    "                    _num_classes = self.num_opers\n",
    "\n",
    "                x, rx = self.lstm_reshape(\n",
    "                    inputs=_x,\n",
    "                    name_prefix=o,\n",
    "                    index=i,\n",
    "                    reshaped_inputs=_rx,\n",
    "                    initial=_initial)\n",
    "                y = self.dense_softmax(\n",
    "                    inputs=x[0],\n",
    "                    num_classes=_num_classes,\n",
    "                    name_prefix=o,\n",
    "                    index=i)\n",
    "                outputs.append(y)\n",
    "\n",
    "        controller_rnn = Model(inputs=controller_input, outputs=outputs)\n",
    "\n",
    "        if self.model_file is not None and os.path.exists(self.model_file):\n",
    "            controller_rnn.load_weights(self.model_file)\n",
    "        return controller_rnn\n",
    "\n",
    "    def compile_controller_rnn(self):\n",
    "        def _controller_loss(y_true, y_pred):\n",
    "            if self.baseline is None:\n",
    "                self.baseline = 0\n",
    "            else:\n",
    "                self.baseline -= (1 - self.baseline_decay) * (self.baseline - self.reward)\n",
    "            return y_pred * (self.reward - self.baseline)\n",
    "\n",
    "        def _define_loss(controller_loss):\n",
    "            outputs_loss = {}\n",
    "            for i in range(2, self.num_nodes):\n",
    "                outputs_loss[\"{0}_{1}_{2}_{3}\".format(self.controller_network_name, \"inputL\", i, \"softmax\")] = controller_loss\n",
    "                outputs_loss[\"{0}_{1}_{2}_{3}\".format(self.controller_network_name, \"inputR\", i, \"softmax\")] = controller_loss\n",
    "                outputs_loss[\"{0}_{1}_{2}_{3}\".format(self.controller_network_name, \"operL\", i, \"softmax\")] = controller_loss\n",
    "                outputs_loss[\"{0}_{1}_{2}_{3}\".format(self.controller_network_name, \"operR\", i, \"softmax\")] = controller_loss\n",
    "            return outputs_loss\n",
    "\n",
    "        self.controller_rnn.compile(loss=_define_loss(_controller_loss), optimizer=self.opt)\n",
    "\n",
    "    def save_model(self):\n",
    "        self.controller_rnn.save_weights(self.model_file)\n",
    "\n",
    "    def train_controller_rnn(self,\n",
    "                             targets,\n",
    "                             batch_size=1,\n",
    "                             epochs=50,\n",
    "                             callbacks=[EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')]):\n",
    "        #with self.graph.as_default():\n",
    "        self.compile_controller_rnn()\n",
    "        self.controller_rnn.fit(\n",
    "            self.input_x,\n",
    "            targets,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=0)\n",
    "\n",
    "    def softmax_predict(self):\n",
    "        #with self.graph.as_default():\n",
    "        self.compile_controller_rnn()\n",
    "        return self.controller_rnn.predict(self.input_x)\n",
    "\n",
    "    def random_sample_softmax(self, controller_pred):\n",
    "        sample_softmax = []\n",
    "        for cp in controller_pred:\n",
    "            cp /= self.temperature\n",
    "            cp = self.tanh_constant * np.tanh(cp)\n",
    "            cp = np.exp(cp) / np.sum(np.exp(cp))\n",
    "            cp = np.array([np.random.multinomial(1, cp[0])])\n",
    "            sample_softmax.append(cp)\n",
    "        return sample_softmax\n",
    "\n",
    "    def convert_pred_to_cell(self, controller_pred):\n",
    "        cell_pred = {}\n",
    "        for p in range(2, self.num_nodes):\n",
    "            pos = list(range((p - 2) * 4, ((p - 2) * 4) + 4))\n",
    "            cell_pred[p] = {\n",
    "                \"L\": {\n",
    "                    \"input_layer\": np.argmax(controller_pred[pos[0]]),\n",
    "                    \"oper_id\": np.argmax(controller_pred[pos[2]])\n",
    "                },\n",
    "                \"R\": {\n",
    "                    \"input_layer\": np.argmax(controller_pred[pos[1]]),\n",
    "                    \"oper_id\": np.argmax(controller_pred[pos[3]])\n",
    "                }\n",
    "            }\n",
    "        return cell_pred\n",
    "\n",
    "    def convert_pred_to_ydict(self, controller_pred):\n",
    "        ydict = {}\n",
    "        name_prefix = self.controller_network_name\n",
    "        for i in range(2, self.num_nodes):\n",
    "            pos = list(range((i - 2) * 4, ((i - 2) * 4) + 4))\n",
    "            ydict[\"{0}_{1}_{2}_{3}\".format(name_prefix, \"inputL\", i, \"softmax\")] = controller_pred[pos[0]]\n",
    "            ydict[\"{0}_{1}_{2}_{3}\".format(name_prefix, \"inputR\", i, \"softmax\")] = controller_pred[pos[1]]\n",
    "            ydict[\"{0}_{1}_{2}_{3}\".format(name_prefix, \"operL\", i, \"softmax\")] = controller_pred[pos[2]]\n",
    "            ydict[\"{0}_{1}_{2}_{3}\".format(name_prefix, \"operR\", i, \"softmax\")] = controller_pred[pos[3]]\n",
    "        return ydict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contr = ControllerRNNController(\"netname\", num_nodes=3, num_opers=3, input_x=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "#contr.controller_rnn.summary()\n",
    "plot_model(contr.controller_rnn, expand_nested=True, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "# disable tensorflow log level infos\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # show only errors\n",
    "\n",
    "inputs = tf.random.normal([32, 10, 8])\n",
    "lstm = tf.keras.layers.LSTM(4, return_sequences=True, return_state=True)\n",
    "\n",
    "whole_seq_output, final_memory_state, final_carry_state = lstm(inputs)\n",
    "\n",
    "print(whole_seq_output.shape, final_memory_state.shape, final_carry_state.shape)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "85f5044ba23e75135dc4c908fd4d7609c1c80b195047fdb4d16ee0e66a953254"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
