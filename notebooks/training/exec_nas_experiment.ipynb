{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> Restrict GPU memory growth: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# disable tensorflow log level infos\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # show only errors\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "if '../../../../notebooks/' not in sys.path:\n",
    "    sys.path.append('../../../../notebooks/')\n",
    "if 'src' not in sys.path:\n",
    "    sys.path.insert(0, 'src')\n",
    "\n",
    "import utils.constants as cts\n",
    "\n",
    "from data_loaders.data_loader import DLName\n",
    "from gt_loaders.gt_names import GTName\n",
    "from exp_runner import ExperimentRunner\n",
    "from base.model_evaluator import DataSource, DataPredSelection\n",
    "from base.base_models import BaseModel\n",
    "from base.optimizers import Optimizer\n",
    "from base.model_creator import MTLApproach, NAS_MTLApproach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Network runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Init ExperimentRunner -------------------\n",
      "---------------------------\n",
      "Parent Process ID: 71660\n",
      "Process ID: 85591\n",
      "---------------------------\n",
      "-----\n",
      "Use Neptune:  True\n",
      "-----\n",
      "-------------------\n",
      "Args: \n",
      "{'exp_params': {'description': 'Making NAS with APPROACH_1 (random) and '\n",
      "                               'training best architecture for 50 epochs to '\n",
      "                               'evaluate on test set',\n",
      "                'name': 'neural_arch_search',\n",
      "                'src_files': ['src/**/*.py'],\n",
      "                'tags': ['ground truths', 'nas', 'nas_approach_1']},\n",
      " 'nas_params': {'max_blocks_per_branch': 5, 'n_epochs': 5, 'n_trials': 30},\n",
      " 'net_train_params': {'base_model': <BaseModel.VGG16: {'target_size': (224, 224), 'prep_function': <function preprocess_input at 0x7f99cebff430>}>,\n",
      "                      'batch_size': 32,\n",
      "                      'dropout': 0.3,\n",
      "                      'early_stopping': 99,\n",
      "                      'learning_rate': 0.001,\n",
      "                      'n_epochs': 50,\n",
      "                      'optimizer': <Optimizer.ADAMAX: 'Adamax'>},\n",
      " 'properties': {'aligned': False,\n",
      "                'approach': <NAS_MTLApproach.APPROACH_1: 'approach_1'>,\n",
      "                'balance_input_data': False,\n",
      "                'gt_names': {'test': [],\n",
      "                             'train_validation': [],\n",
      "                             'train_validation_test': [<GTName.FVC: 'fvc'>]},\n",
      "                'orig_model_experiment_id': '',\n",
      "                'reqs': [<ICAO_REQ.MOUTH: 'mouth'>,\n",
      "                         <ICAO_REQ.ROTATION: 'rotation'>,\n",
      "                         <ICAO_REQ.L_AWAY: 'l_away'>,\n",
      "                         <ICAO_REQ.EYES_CLOSED: 'eyes_closed'>,\n",
      "                         <ICAO_REQ.CLOSE: 'close'>,\n",
      "                         <ICAO_REQ.HAT: 'hat'>,\n",
      "                         <ICAO_REQ.DARK_GLASSES: 'dark_glasses'>,\n",
      "                         <ICAO_REQ.FRAMES_HEAVY: 'frames_heavy'>,\n",
      "                         <ICAO_REQ.FRAME_EYES: 'frame_eyes'>,\n",
      "                         <ICAO_REQ.FLASH_LENSES: 'flash_lenses'>,\n",
      "                         <ICAO_REQ.VEIL: 'veil'>,\n",
      "                         <ICAO_REQ.REFLECTION: 'reflection'>,\n",
      "                         <ICAO_REQ.LIGHT: 'light'>,\n",
      "                         <ICAO_REQ.SHADOW_FACE: 'sh_face'>,\n",
      "                         <ICAO_REQ.SHADOW_HEAD: 'sh_head'>,\n",
      "                         <ICAO_REQ.BLURRED: 'blurred'>,\n",
      "                         <ICAO_REQ.INK_MARK: 'ink_mark'>,\n",
      "                         <ICAO_REQ.SKIN_TONE: 'skin_tone'>,\n",
      "                         <ICAO_REQ.WASHED_OUT: 'washed_out'>,\n",
      "                         <ICAO_REQ.PIXELATION: 'pixelation'>,\n",
      "                         <ICAO_REQ.HAIR_EYES: 'hair_eyes'>,\n",
      "                         <ICAO_REQ.BACKGROUND: 'background'>,\n",
      "                         <ICAO_REQ.RED_EYES: 'red_eyes'>],\n",
      "                'sample_prop': 1.0,\n",
      "                'sample_training_data': False,\n",
      "                'save_trained_model': True,\n",
      "                'train_model': True,\n",
      "                'use_gt_data': True},\n",
      " 'use_neptune': True}\n",
      "-------------------\n",
      "----\n",
      "Base Model Name:  BaseModel.VGG16\n",
      "----\n",
      "-------------------- start neptune -------------------\n",
      "Starting Neptune\n",
      "https://ui.neptune.ai/guilhermemg/icao-nets-training-2/e/ICAO-264\n",
      "----\n",
      "MTL Model: True\n",
      "Approach: NAS_MTLApproach.APPROACH_1\n",
      "----\n",
      "----\n",
      "Checking model existence locally...\n",
      "Training a new model! Not checking model existence\n",
      "----\n",
      "------------------------------\n",
      "Checking GPU availability\n",
      " ..GPU is available!\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "kwargs = { \n",
    "    'use_neptune': True,\n",
    "    'exp_params' : {\n",
    "        'name': 'neural_arch_search',\n",
    "        'description': 'Making NAS with APPROACH_1 (random) and training best architecture for 50 epochs to evaluate on test set',\n",
    "        'tags': ['ground truths', 'nas', 'nas_approach_1'],\n",
    "        'src_files': [\"src/**/*.py\"]\n",
    "    },\n",
    "    'properties': {\n",
    "        'approach': NAS_MTLApproach.APPROACH_1,\n",
    "        'reqs': list(cts.ICAO_REQ),\n",
    "        'aligned': False,\n",
    "        'use_gt_data': True,\n",
    "        'gt_names': {\n",
    "            'train_validation': [],\n",
    "            'test': [],\n",
    "            'train_validation_test': [GTName.FVC]\n",
    "        },\n",
    "        'balance_input_data': False,\n",
    "        'train_model': True,\n",
    "        'save_trained_model': True,\n",
    "        'orig_model_experiment_id': '',\n",
    "        'sample_training_data': False,\n",
    "        'sample_prop': 1.0\n",
    "    },\n",
    "    'net_train_params': {\n",
    "        'base_model': BaseModel.VGG16,\n",
    "        'batch_size': 32,\n",
    "        'n_epochs': 50,\n",
    "        'early_stopping': 99,\n",
    "        'learning_rate': 1e-3,\n",
    "        'optimizer': Optimizer.ADAMAX,\n",
    "        'dropout': 0.3\n",
    "    },\n",
    "    'nas_params': {\n",
    "        'max_blocks_per_branch': 5,\n",
    "        'n_epochs': 5,\n",
    "        'n_trials': 30\n",
    "    }\n",
    "}\n",
    "\n",
    "runner = ExperimentRunner(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- load training data -------------------\n",
      "Loading data\n",
      "Loading GT FVC - TRAIN split...\n",
      "..Ignoring 0 empty label values\n",
      "Input data.shape: (4928, 26)\n",
      "Loading GT FVC - VALIDATION split...\n",
      "..Ignoring 0 empty label values\n",
      "Input data.shape: (547, 26)\n",
      "Loading GT FVC - TEST split...\n",
      "..Ignoring 0 empty label values\n",
      "Input data.shape: (288, 26)\n",
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "runner.load_training_data()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# <font color='red'>Producing Fake Data</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "runner.produce_fake_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- setup data generators -------------------\n",
      "Starting data generators\n",
      "Found 4928 validated image filenames.\n",
      "Found 547 validated image filenames.\n",
      "Found 288 validated image filenames.\n",
      "TOTAL: 5763\n",
      "\n",
      "Logging class indices\n",
      " .. MTL model not logging class indices!\n",
      "\n",
      "Logging class labels\n",
      " COMPLIANT label: 1\n",
      " NON_COMPLIANT label: 0\n",
      " DUMMY label: -1\n",
      " DUMMY_CLS label: 2\n",
      " NO_ANSWER label: -99\n"
     ]
    }
   ],
   "source": [
    "runner.setup_data_generators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- create experiment -------------------\n",
      "Setup neptune properties and parameters\n",
      "Properties and parameters setup done!\n"
     ]
    }
   ],
   "source": [
    "runner.setup_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "runner.summary_labels_dist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Architecture Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- run neural architecture search -------------------\n",
      "++++++++++++++++++++ STARTING NEW TRAIN ++++++++++++++++++++\n",
      " ----- Training 1 | Config: {'n_denses_0': 3, 'n_denses_1': 2, 'n_denses_2': 2, 'n_denses_3': 1} --------\n",
      "Creating model...\n",
      "Model created\n",
      "Training VGG16 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 15,572,654\n",
      "  .. Trainable params: 857,966\n",
      "  .. Non-trainable params: 14,714,688\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: string series 'monitoring/stdout' value was longer than 1000 characters and was truncated. This warning is printed only once per series.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154/154 [==============================] - 417s 3s/step - loss: 1.0839 - background_loss: 0.6357 - close_loss: 0.5601 - ink_mark_loss: 0.6557 - pixelation_loss: 0.5328 - washed_out_loss: 0.0943 - blurred_loss: 0.4172 - sh_head_loss: 0.4000 - mouth_loss: 0.0282 - veil_loss: 0.6546 - red_eyes_loss: 0.5495 - flash_lenses_loss: 0.3074 - dark_glasses_loss: 0.7277 - l_away_loss: 0.3605 - frame_eyes_loss: 0.7259 - hair_eyes_loss: 0.6667 - eyes_closed_loss: 0.3920 - frames_heavy_loss: 0.0207 - sh_face_loss: 0.8459 - skin_tone_loss: 0.1235 - light_loss: 0.2926 - hat_loss: 0.5251 - rotation_loss: 0.7576 - reflection_loss: 0.5655 - background_accuracy: 0.7190 - close_accuracy: 0.7524 - ink_mark_accuracy: 0.6715 - pixelation_accuracy: 0.7681 - washed_out_accuracy: 0.9880 - blurred_accuracy: 0.8584 - sh_head_accuracy: 0.8711 - mouth_accuracy: 0.9972 - veil_accuracy: 0.6863 - red_eyes_accuracy: 0.7792 - flash_lenses_accuracy: 0.9200 - dark_glasses_accuracy: 0.5110 - l_away_accuracy: 0.9056 - frame_eyes_accuracy: 0.5948 - hair_eyes_accuracy: 0.6254 - eyes_closed_accuracy: 0.8691 - frames_heavy_accuracy: 0.9974 - sh_face_accuracy: 0.5312 - skin_tone_accuracy: 0.9807 - light_accuracy: 0.9180 - hat_accuracy: 0.8133 - rotation_accuracy: 0.5976 - reflection_accuracy: 0.7800 - val_loss: 0.9474 - val_background_loss: 0.5682 - val_close_loss: 0.5279 - val_ink_mark_loss: 0.6091 - val_pixelation_loss: 0.4796 - val_washed_out_loss: 0.0658 - val_blurred_loss: 0.4524 - val_sh_head_loss: 0.3186 - val_mouth_loss: 0.0304 - val_veil_loss: 0.5699 - val_red_eyes_loss: 0.5130 - val_flash_lenses_loss: 0.2539 - val_dark_glasses_loss: 0.6878 - val_l_away_loss: 0.2961 - val_frame_eyes_loss: 0.6567 - val_hair_eyes_loss: 0.6159 - val_eyes_closed_loss: 0.2996 - val_frames_heavy_loss: 0.0028 - val_sh_face_loss: 0.6864 - val_skin_tone_loss: 0.0291 - val_light_loss: 0.2444 - val_hat_loss: 0.4556 - val_rotation_loss: 0.6188 - val_reflection_loss: 0.4920 - val_background_accuracy: 0.7702 - val_close_accuracy: 0.7518 - val_ink_mark_accuracy: 0.6985 - val_pixelation_accuracy: 0.8070 - val_washed_out_accuracy: 0.9890 - val_blurred_accuracy: 0.8290 - val_sh_head_accuracy: 0.9044 - val_mouth_accuracy: 0.9945 - val_veil_accuracy: 0.7243 - val_red_eyes_accuracy: 0.7923 - val_flash_lenses_accuracy: 0.9393 - val_dark_glasses_accuracy: 0.6048 - val_l_away_accuracy: 0.9228 - val_frame_eyes_accuracy: 0.6176 - val_hair_eyes_accuracy: 0.6342 - val_eyes_closed_accuracy: 0.9210 - val_frames_heavy_accuracy: 1.0000 - val_sh_face_accuracy: 0.5662 - val_skin_tone_accuracy: 0.9945 - val_light_accuracy: 0.9430 - val_hat_accuracy: 0.8051 - val_rotation_accuracy: 0.6654 - val_reflection_accuracy: 0.8015\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.94742, saving model to training_ckpt/best_model.hdf5\n",
      "Epoch 2/5\n",
      "154/154 [==============================] - 380s 2s/step - loss: 0.9632 - background_loss: 0.5969 - close_loss: 0.5244 - ink_mark_loss: 0.6127 - pixelation_loss: 0.5031 - washed_out_loss: 0.0710 - blurred_loss: 0.3997 - sh_head_loss: 0.3555 - mouth_loss: 0.0185 - veil_loss: 0.5720 - red_eyes_loss: 0.5119 - flash_lenses_loss: 0.2613 - dark_glasses_loss: 0.6853 - l_away_loss: 0.3060 - frame_eyes_loss: 0.6496 - hair_eyes_loss: 0.6196 - eyes_closed_loss: 0.3580 - frames_heavy_loss: 0.0018 - sh_face_loss: 0.6900 - skin_tone_loss: 0.0502 - light_loss: 0.2868 - hat_loss: 0.4328 - rotation_loss: 0.6140 - reflection_loss: 0.5109 - background_accuracy: 0.7319 - close_accuracy: 0.7541 - ink_mark_accuracy: 0.6849 - pixelation_accuracy: 0.7888 - washed_out_accuracy: 0.9892 - blurred_accuracy: 0.8584 - sh_head_accuracy: 0.8853 - mouth_accuracy: 0.9972 - veil_accuracy: 0.7070 - red_eyes_accuracy: 0.7902 - flash_lenses_accuracy: 0.9367 - dark_glasses_accuracy: 0.5325 - l_away_accuracy: 0.9186 - frame_eyes_accuracy: 0.6240 - hair_eyes_accuracy: 0.6514 - eyes_closed_accuracy: 0.8811 - frames_heavy_accuracy: 1.0000 - sh_face_accuracy: 0.5394 - skin_tone_accuracy: 0.9913 - light_accuracy: 0.9318 - hat_accuracy: 0.8172 - rotation_accuracy: 0.6727 - reflection_accuracy: 0.7831 - val_loss: 0.9301 - val_background_loss: 0.5469 - val_close_loss: 0.5227 - val_ink_mark_loss: 0.6054 - val_pixelation_loss: 0.4676 - val_washed_out_loss: 0.0659 - val_blurred_loss: 0.4588 - val_sh_head_loss: 0.3139 - val_mouth_loss: 0.0318 - val_veil_loss: 0.5417 - val_red_eyes_loss: 0.5049 - val_flash_lenses_loss: 0.2393 - val_dark_glasses_loss: 0.6874 - val_l_away_loss: 0.3103 - val_frame_eyes_loss: 0.6525 - val_hair_eyes_loss: 0.5885 - val_eyes_closed_loss: 0.2916 - val_frames_heavy_loss: 8.4509e-04 - val_sh_face_loss: 0.6867 - val_skin_tone_loss: 0.0280 - val_light_loss: 0.2509 - val_hat_loss: 0.4360 - val_rotation_loss: 0.5842 - val_reflection_loss: 0.4847 - val_background_accuracy: 0.7702 - val_close_accuracy: 0.7518 - val_ink_mark_accuracy: 0.6985 - val_pixelation_accuracy: 0.8070 - val_washed_out_accuracy: 0.9890 - val_blurred_accuracy: 0.8290 - val_sh_head_accuracy: 0.9044 - val_mouth_accuracy: 0.9945 - val_veil_accuracy: 0.7224 - val_red_eyes_accuracy: 0.7923 - val_flash_lenses_accuracy: 0.9393 - val_dark_glasses_accuracy: 0.5055 - val_l_away_accuracy: 0.9228 - val_frame_eyes_accuracy: 0.6360 - val_hair_eyes_accuracy: 0.6930 - val_eyes_closed_accuracy: 0.9210 - val_frames_heavy_accuracy: 1.0000 - val_sh_face_accuracy: 0.5037 - val_skin_tone_accuracy: 0.9945 - val_light_accuracy: 0.9430 - val_hat_accuracy: 0.8051 - val_rotation_accuracy: 0.6930 - val_reflection_accuracy: 0.8015\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.94742 to 0.93006, saving model to training_ckpt/best_model.hdf5\n",
      "Epoch 3/5\n",
      "154/154 [==============================] - 354s 2s/step - loss: 0.9323 - background_loss: 0.5692 - close_loss: 0.5160 - ink_mark_loss: 0.6112 - pixelation_loss: 0.4931 - washed_out_loss: 0.0733 - blurred_loss: 0.3930 - sh_head_loss: 0.3438 - mouth_loss: 0.0192 - veil_loss: 0.5504 - red_eyes_loss: 0.4898 - flash_lenses_loss: 0.2409 - dark_glasses_loss: 0.6725 - l_away_loss: 0.3156 - frame_eyes_loss: 0.6215 - hair_eyes_loss: 0.5979 - eyes_closed_loss: 0.3361 - frames_heavy_loss: 6.9911e-04 - sh_face_loss: 0.6841 - skin_tone_loss: 0.0490 - light_loss: 0.2875 - hat_loss: 0.4218 - rotation_loss: 0.5369 - reflection_loss: 0.4996 - background_accuracy: 0.7291 - close_accuracy: 0.7541 - ink_mark_accuracy: 0.6847 - pixelation_accuracy: 0.7888 - washed_out_accuracy: 0.9892 - blurred_accuracy: 0.8584 - sh_head_accuracy: 0.8853 - mouth_accuracy: 0.9972 - veil_accuracy: 0.7088 - red_eyes_accuracy: 0.7902 - flash_lenses_accuracy: 0.9367 - dark_glasses_accuracy: 0.5765 - l_away_accuracy: 0.9186 - frame_eyes_accuracy: 0.6640 - hair_eyes_accuracy: 0.6859 - eyes_closed_accuracy: 0.8811 - frames_heavy_accuracy: 1.0000 - sh_face_accuracy: 0.5333 - skin_tone_accuracy: 0.9913 - light_accuracy: 0.9318 - hat_accuracy: 0.8170 - rotation_accuracy: 0.7072 - reflection_accuracy: 0.7831 - val_loss: 0.8821 - val_background_loss: 0.5066 - val_close_loss: 0.5080 - val_ink_mark_loss: 0.6094 - val_pixelation_loss: 0.4578 - val_washed_out_loss: 0.0614 - val_blurred_loss: 0.4521 - val_sh_head_loss: 0.3043 - val_mouth_loss: 0.0371 - val_veil_loss: 0.5038 - val_red_eyes_loss: 0.4891 - val_flash_lenses_loss: 0.2217 - val_dark_glasses_loss: 0.6582 - val_l_away_loss: 0.3030 - val_frame_eyes_loss: 0.6220 - val_hair_eyes_loss: 0.5429 - val_eyes_closed_loss: 0.2494 - val_frames_heavy_loss: 1.7763e-04 - val_sh_face_loss: 0.6621 - val_skin_tone_loss: 0.0251 - val_light_loss: 0.2426 - val_hat_loss: 0.4601 - val_rotation_loss: 0.4449 - val_reflection_loss: 0.4600 - val_background_accuracy: 0.7371 - val_close_accuracy: 0.7518 - val_ink_mark_accuracy: 0.6985 - val_pixelation_accuracy: 0.8070 - val_washed_out_accuracy: 0.9890 - val_blurred_accuracy: 0.8290 - val_sh_head_accuracy: 0.9044 - val_mouth_accuracy: 0.9945 - val_veil_accuracy: 0.7224 - val_red_eyes_accuracy: 0.7923 - val_flash_lenses_accuracy: 0.9393 - val_dark_glasses_accuracy: 0.5754 - val_l_away_accuracy: 0.9228 - val_frame_eyes_accuracy: 0.6746 - val_hair_eyes_accuracy: 0.7316 - val_eyes_closed_accuracy: 0.9210 - val_frames_heavy_accuracy: 1.0000 - val_sh_face_accuracy: 0.6544 - val_skin_tone_accuracy: 0.9945 - val_light_accuracy: 0.9430 - val_hat_accuracy: 0.8051 - val_rotation_accuracy: 0.7739 - val_reflection_accuracy: 0.8015\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.93006 to 0.88215, saving model to training_ckpt/best_model.hdf5\n",
      "Epoch 4/5\n",
      "154/154 [==============================] - 346s 2s/step - loss: 0.8927 - background_loss: 0.5423 - close_loss: 0.5086 - ink_mark_loss: 0.6113 - pixelation_loss: 0.4819 - washed_out_loss: 0.0657 - blurred_loss: 0.3901 - sh_head_loss: 0.3226 - mouth_loss: 0.0189 - veil_loss: 0.5299 - red_eyes_loss: 0.4690 - flash_lenses_loss: 0.2153 - dark_glasses_loss: 0.6489 - l_away_loss: 0.2928 - frame_eyes_loss: 0.5987 - hair_eyes_loss: 0.5634 - eyes_closed_loss: 0.3127 - frames_heavy_loss: 4.6547e-04 - sh_face_loss: 0.6663 - skin_tone_loss: 0.0485 - light_loss: 0.2654 - hat_loss: 0.4132 - rotation_loss: 0.4699 - reflection_loss: 0.4915 - background_accuracy: 0.7267 - close_accuracy: 0.7537 - ink_mark_accuracy: 0.6847 - pixelation_accuracy: 0.7888 - washed_out_accuracy: 0.9892 - blurred_accuracy: 0.8584 - sh_head_accuracy: 0.8853 - mouth_accuracy: 0.9972 - veil_accuracy: 0.7015 - red_eyes_accuracy: 0.7902 - flash_lenses_accuracy: 0.9367 - dark_glasses_accuracy: 0.6025 - l_away_accuracy: 0.9186 - frame_eyes_accuracy: 0.6869 - hair_eyes_accuracy: 0.7123 - eyes_closed_accuracy: 0.8801 - frames_heavy_accuracy: 1.0000 - sh_face_accuracy: 0.6090 - skin_tone_accuracy: 0.9913 - light_accuracy: 0.9318 - hat_accuracy: 0.8145 - rotation_accuracy: 0.7508 - reflection_accuracy: 0.7831 - val_loss: 0.8502 - val_background_loss: 0.4834 - val_close_loss: 0.4965 - val_ink_mark_loss: 0.5969 - val_pixelation_loss: 0.4439 - val_washed_out_loss: 0.0473 - val_blurred_loss: 0.4291 - val_sh_head_loss: 0.2902 - val_mouth_loss: 0.0303 - val_veil_loss: 0.5220 - val_red_eyes_loss: 0.4707 - val_flash_lenses_loss: 0.1919 - val_dark_glasses_loss: 0.6494 - val_l_away_loss: 0.2707 - val_frame_eyes_loss: 0.5912 - val_hair_eyes_loss: 0.5227 - val_eyes_closed_loss: 0.2509 - val_frames_heavy_loss: 6.2654e-04 - val_sh_face_loss: 0.6575 - val_skin_tone_loss: 0.0290 - val_light_loss: 0.2314 - val_hat_loss: 0.4363 - val_rotation_loss: 0.4022 - val_reflection_loss: 0.4581 - val_background_accuracy: 0.7702 - val_close_accuracy: 0.7518 - val_ink_mark_accuracy: 0.6985 - val_pixelation_accuracy: 0.8070 - val_washed_out_accuracy: 0.9890 - val_blurred_accuracy: 0.8290 - val_sh_head_accuracy: 0.9044 - val_mouth_accuracy: 0.9945 - val_veil_accuracy: 0.6746 - val_red_eyes_accuracy: 0.7923 - val_flash_lenses_accuracy: 0.9393 - val_dark_glasses_accuracy: 0.6011 - val_l_away_accuracy: 0.9228 - val_frame_eyes_accuracy: 0.6820 - val_hair_eyes_accuracy: 0.7279 - val_eyes_closed_accuracy: 0.9099 - val_frames_heavy_accuracy: 1.0000 - val_sh_face_accuracy: 0.6158 - val_skin_tone_accuracy: 0.9945 - val_light_accuracy: 0.9430 - val_hat_accuracy: 0.7960 - val_rotation_accuracy: 0.7978 - val_reflection_accuracy: 0.8015\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.88215 to 0.85024, saving model to training_ckpt/best_model.hdf5\n",
      "Epoch 5/5\n",
      "154/154 [==============================] - 338s 2s/step - loss: 0.8506 - background_loss: 0.5286 - close_loss: 0.4930 - ink_mark_loss: 0.5914 - pixelation_loss: 0.4570 - washed_out_loss: 0.0519 - blurred_loss: 0.3855 - sh_head_loss: 0.2888 - mouth_loss: 0.0196 - veil_loss: 0.5056 - red_eyes_loss: 0.4447 - flash_lenses_loss: 0.1915 - dark_glasses_loss: 0.6251 - l_away_loss: 0.2643 - frame_eyes_loss: 0.5782 - hair_eyes_loss: 0.5216 - eyes_closed_loss: 0.3002 - frames_heavy_loss: 3.9561e-04 - sh_face_loss: 0.6500 - skin_tone_loss: 0.0506 - light_loss: 0.2583 - hat_loss: 0.4043 - rotation_loss: 0.4254 - reflection_loss: 0.4706 - background_accuracy: 0.7289 - close_accuracy: 0.7539 - ink_mark_accuracy: 0.6920 - pixelation_accuracy: 0.7934 - washed_out_accuracy: 0.9892 - blurred_accuracy: 0.8584 - sh_head_accuracy: 0.8858 - mouth_accuracy: 0.9972 - veil_accuracy: 0.7141 - red_eyes_accuracy: 0.8007 - flash_lenses_accuracy: 0.9367 - dark_glasses_accuracy: 0.6690 - l_away_accuracy: 0.9184 - frame_eyes_accuracy: 0.6944 - hair_eyes_accuracy: 0.7340 - eyes_closed_accuracy: 0.8805 - frames_heavy_accuracy: 1.0000 - sh_face_accuracy: 0.6471 - skin_tone_accuracy: 0.9913 - light_accuracy: 0.9318 - hat_accuracy: 0.8180 - rotation_accuracy: 0.7796 - reflection_accuracy: 0.7859 - val_loss: 0.7999 - val_background_loss: 0.5092 - val_close_loss: 0.4843 - val_ink_mark_loss: 0.5491 - val_pixelation_loss: 0.4046 - val_washed_out_loss: 0.0432 - val_blurred_loss: 0.3990 - val_sh_head_loss: 0.2278 - val_mouth_loss: 0.0284 - val_veil_loss: 0.4378 - val_red_eyes_loss: 0.4550 - val_flash_lenses_loss: 0.1667 - val_dark_glasses_loss: 0.6288 - val_l_away_loss: 0.2624 - val_frame_eyes_loss: 0.5704 - val_hair_eyes_loss: 0.4839 - val_eyes_closed_loss: 0.2467 - val_frames_heavy_loss: 5.0586e-04 - val_sh_face_loss: 0.6373 - val_skin_tone_loss: 0.0325 - val_light_loss: 0.2348 - val_hat_loss: 0.4066 - val_rotation_loss: 0.3775 - val_reflection_loss: 0.4123 - val_background_accuracy: 0.7316 - val_close_accuracy: 0.7463 - val_ink_mark_accuracy: 0.7279 - val_pixelation_accuracy: 0.8364 - val_washed_out_accuracy: 0.9890 - val_blurred_accuracy: 0.8290 - val_sh_head_accuracy: 0.9191 - val_mouth_accuracy: 0.9945 - val_veil_accuracy: 0.7629 - val_red_eyes_accuracy: 0.8272 - val_flash_lenses_accuracy: 0.9393 - val_dark_glasses_accuracy: 0.6581 - val_l_away_accuracy: 0.9228 - val_frame_eyes_accuracy: 0.6949 - val_hair_eyes_accuracy: 0.7408 - val_eyes_closed_accuracy: 0.9118 - val_frames_heavy_accuracy: 1.0000 - val_sh_face_accuracy: 0.6489 - val_skin_tone_accuracy: 0.9945 - val_light_accuracy: 0.9430 - val_hat_accuracy: 0.8162 - val_rotation_accuracy: 0.8254 - val_reflection_accuracy: 0.8199\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.85024 to 0.79989, saving model to training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "18/18 [==============================] - 32s 2s/step\n",
      "Prediction finished!\n",
      "final_EER_mean: 26.23% | final_ACC: 72.63%\n",
      "--------------------FINISHING TRAIN--------------------\n",
      "++++++++++++++++++++ STARTING NEW TRAIN ++++++++++++++++++++\n",
      " ----- Training 2 | Config: {'n_denses_0': 3, 'n_denses_1': 2, 'n_denses_2': 4, 'n_denses_3': 1} --------\n",
      "Creating model...\n",
      "Model created\n",
      "Training VGG16 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 15,639,214\n",
      "  .. Trainable params: 924,526\n",
      "  .. Non-trainable params: 14,714,688\n",
      "Epoch 1/5\n",
      " 60/154 [==========>...................] - ETA: 3:09 - loss: 1.2131 - background_loss: 0.6231 - close_loss: 0.6277 - ink_mark_loss: 0.6991 - pixelation_loss: 0.6563 - washed_out_loss: 0.0818 - blurred_loss: 0.4330 - sh_head_loss: 0.3918 - mouth_loss: 0.3069 - veil_loss: 0.6847 - red_eyes_loss: 0.5523 - flash_lenses_loss: 0.3570 - dark_glasses_loss: 0.7072 - l_away_loss: 0.3567 - frame_eyes_loss: 0.6801 - hair_eyes_loss: 0.6574 - eyes_closed_loss: 0.4117 - frames_heavy_loss: 0.1463 - sh_face_loss: 0.8762 - skin_tone_loss: 0.1509 - light_loss: 0.3783 - hat_loss: 0.6751 - rotation_loss: 0.9128 - reflection_loss: 0.7649 - background_accuracy: 0.7260 - close_accuracy: 0.7630 - ink_mark_accuracy: 0.6797 - pixelation_accuracy: 0.7651 - washed_out_accuracy: 0.9927 - blurred_accuracy: 0.8599 - sh_head_accuracy: 0.8703 - mouth_accuracy: 0.9583 - veil_accuracy: 0.6812 - red_eyes_accuracy: 0.7865 - flash_lenses_accuracy: 0.8875 - dark_glasses_accuracy: 0.5125 - l_away_accuracy: 0.8948 - frame_eyes_accuracy: 0.5990 - hair_eyes_accuracy: 0.6182 - eyes_closed_accuracy: 0.8464 - frames_heavy_accuracy: 0.9865 - sh_face_accuracy: 0.5146 - skin_tone_accuracy: 0.9609 - light_accuracy: 0.8687 - hat_accuracy: 0.7594 - rotation_accuracy: 0.5089 - reflection_accuracy: 0.7323"
     ]
    }
   ],
   "source": [
    "runner.run_neural_architeture_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vizualize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.visualize_model(outfile_path=f\"figs/nas/nas_model_approach_1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "runner.model_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.draw_training_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.load_best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.set_model_evaluator_data_src(DataSource.VALIDATION)\n",
    "runner.test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner.set_model_evaluator_data_src(DataSource.TEST)\n",
    "runner.test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Model Classification"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "runner.visualize_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finishing Experiment Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.finish_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Network Modification"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Input, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_tensor = Input(shape=(20,), name=\"input\")\n",
    "hidden = Dense(100, activation='relu')(input_tensor)\n",
    "out = Dense(10, activation='relu', name=\"out\")(hidden)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=out)\n",
    "model.compile(loss=\"mse\", optimizer='adam')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "out = Dense(5, activation='softmax', name='new_out')(model.layers[-2].output)\n",
    "\n",
    "new_model = Model(input_tensor, out)\n",
    "new_model.summary()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "85f5044ba23e75135dc4c908fd4d7609c1c80b195047fdb4d16ee0e66a953254"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
