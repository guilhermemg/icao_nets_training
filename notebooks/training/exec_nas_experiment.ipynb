{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> Restrict GPU memory growth: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# disable tensorflow log level infos\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # show only errors\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "if '../../../../notebooks/' not in sys.path:\n",
    "    sys.path.append('../../../../notebooks/')\n",
    "if 'src' not in sys.path:\n",
    "    sys.path.insert(0, 'src')\n",
    "\n",
    "import utils.constants as cts\n",
    "\n",
    "from data_loaders.data_loader import DLName\n",
    "from gt_loaders.gt_names import GTName\n",
    "from exp_runner import ExperimentRunner\n",
    "from model_evaluator import DataSource, DataPredSelection\n",
    "from base_models import BaseModel\n",
    "from optimizers import Optimizer\n",
    "from model_creator import MTLApproach, NAS_MTLApproach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Network runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Init ExperimentRunner -------------------\n",
      "---------------------------\n",
      "Parent Process ID: 16240\n",
      "Process ID: 19983\n",
      "---------------------------\n",
      "-----\n",
      "Use Neptune:  False\n",
      "-----\n",
      "-------------------\n",
      "Args: \n",
      "{'exp_params': {'description': 'Training mtl network for ALL requisites - 10 '\n",
      "                               'epochs - without early_stopping in FVC GT '\n",
      "                               'dataset NOT aligned',\n",
      "                'name': 'train_vgg16',\n",
      "                'src_files': ['src/**/*.py'],\n",
      "                'tags': ['vgg16',\n",
      "                         'ground truths',\n",
      "                         'adamax',\n",
      "                         'mtl',\n",
      "                         '10 epochs']},\n",
      " 'nas_params': {'max_blocks_per_branch': 3,\n",
      "                'max_train_steps_per_op': 5,\n",
      "                'n_trials': 2},\n",
      " 'net_train_params': {'base_model': <BaseModel.VGG16: {'target_size': (224, 224), 'prep_function': <function preprocess_input at 0x7f8a47f023a0>}>,\n",
      "                      'batch_size': 32,\n",
      "                      'dropout': 0.3,\n",
      "                      'early_stopping': 10,\n",
      "                      'learning_rate': 0.001,\n",
      "                      'n_epochs': 10,\n",
      "                      'optimizer': <Optimizer.ADAMAX: 'Adamax'>},\n",
      " 'properties': {'aligned': True,\n",
      "                'approach': <NAS_MTLApproach.APPROACH_1: 'approach_1'>,\n",
      "                'balance_input_data': False,\n",
      "                'gt_names': {'test': [],\n",
      "                             'train_validation': [],\n",
      "                             'train_validation_test': [<GTName.FVC: 'fvc'>]},\n",
      "                'orig_model_experiment_id': '',\n",
      "                'reqs': [<ICAO_REQ.MOUTH: 'mouth'>,\n",
      "                         <ICAO_REQ.ROTATION: 'rotation'>,\n",
      "                         <ICAO_REQ.L_AWAY: 'l_away'>,\n",
      "                         <ICAO_REQ.EYES_CLOSED: 'eyes_closed'>,\n",
      "                         <ICAO_REQ.CLOSE: 'close'>,\n",
      "                         <ICAO_REQ.HAT: 'hat'>,\n",
      "                         <ICAO_REQ.DARK_GLASSES: 'dark_glasses'>,\n",
      "                         <ICAO_REQ.FRAMES_HEAVY: 'frames_heavy'>,\n",
      "                         <ICAO_REQ.FRAME_EYES: 'frame_eyes'>,\n",
      "                         <ICAO_REQ.FLASH_LENSES: 'flash_lenses'>,\n",
      "                         <ICAO_REQ.VEIL: 'veil'>,\n",
      "                         <ICAO_REQ.REFLECTION: 'reflection'>,\n",
      "                         <ICAO_REQ.LIGHT: 'light'>,\n",
      "                         <ICAO_REQ.SHADOW_FACE: 'sh_face'>,\n",
      "                         <ICAO_REQ.SHADOW_HEAD: 'sh_head'>,\n",
      "                         <ICAO_REQ.BLURRED: 'blurred'>,\n",
      "                         <ICAO_REQ.INK_MARK: 'ink_mark'>,\n",
      "                         <ICAO_REQ.SKIN_TONE: 'skin_tone'>,\n",
      "                         <ICAO_REQ.WASHED_OUT: 'washed_out'>,\n",
      "                         <ICAO_REQ.PIXELATION: 'pixelation'>,\n",
      "                         <ICAO_REQ.HAIR_EYES: 'hair_eyes'>,\n",
      "                         <ICAO_REQ.BACKGROUND: 'background'>,\n",
      "                         <ICAO_REQ.RED_EYES: 'red_eyes'>],\n",
      "                'sample_prop': 1.0,\n",
      "                'sample_training_data': False,\n",
      "                'save_trained_model': False,\n",
      "                'train_model': True,\n",
      "                'use_gt_data': True},\n",
      " 'use_neptune': False}\n",
      "-------------------\n",
      "----\n",
      "Base Model Name:  BaseModel.VGG16\n",
      "----\n",
      "-------------------- start neptune -------------------\n",
      "Not using Neptune to record Experiment Metadata\n",
      "----\n",
      "MTL Model: True\n",
      "Approach: NAS_MTLApproach.APPROACH_1\n",
      "----\n",
      "----\n",
      "Checking model existence locally...\n",
      "Training a new model! Not checking model existence\n",
      "----\n",
      "------------------------------\n",
      "Checking GPU availability\n",
      " ..GPU is available!\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "kwargs = { \n",
    "    'use_neptune': False,\n",
    "    'exp_params' : {\n",
    "        'name': 'train_vgg16',\n",
    "        'description': 'Training mtl network for ALL requisites - 10 epochs - without early_stopping in FVC GT dataset NOT aligned',\n",
    "        'tags': ['vgg16', 'ground truths', 'adamax', 'mtl', '10 epochs'],\n",
    "        'src_files': [\"src/**/*.py\"]\n",
    "    },\n",
    "    'properties': {\n",
    "        'approach': NAS_MTLApproach.APPROACH_1,\n",
    "        'reqs': list(cts.ICAO_REQ),\n",
    "        'aligned': True,\n",
    "        'use_gt_data': True,\n",
    "        'gt_names': {\n",
    "            'train_validation': [],\n",
    "            'test': [],\n",
    "            'train_validation_test': [GTName.FVC]\n",
    "        },\n",
    "        'balance_input_data': False,\n",
    "        'train_model': True,\n",
    "        'save_trained_model': False,\n",
    "        'orig_model_experiment_id': '',\n",
    "        'sample_training_data': False,\n",
    "        'sample_prop': 1.0\n",
    "    },\n",
    "    'net_train_params': {\n",
    "        'base_model': BaseModel.VGG16,\n",
    "        'batch_size': 32,\n",
    "        'n_epochs': 10,\n",
    "        'early_stopping': 10,\n",
    "        'learning_rate': 1e-3,\n",
    "        'optimizer': Optimizer.ADAMAX,\n",
    "        'dropout': 0.3\n",
    "    },\n",
    "    'nas_params': {\n",
    "        'max_blocks_per_branch': 3,\n",
    "        'max_train_steps_per_op': 5,\n",
    "        'n_trials': 2\n",
    "    }\n",
    "}\n",
    "\n",
    "runner = ExperimentRunner(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- load training data -------------------\n",
      "Loading data\n",
      "Loading GT FVC - TRAIN split...\n",
      "..Ignoring 0 empty label values\n",
      "Input data.shape: (4926, 26)\n",
      "Loading GT FVC - VALIDATION split...\n",
      "..Ignoring 0 empty label values\n",
      "Input data.shape: (547, 26)\n",
      "Loading GT FVC - TEST split...\n",
      "..Ignoring 0 empty label values\n",
      "Input data.shape: (288, 26)\n",
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "runner.load_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Producing Fake Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- producing fake data for experimental purposes -------------------\n",
      "fake_train_data.shape: (500, 26)\n",
      "fake_validation_data_df.shape: (100, 26)\n",
      "fake_test_data_df.shape: (50, 26)\n",
      "fake_train_data.mouth.sum: 266.0\n",
      "fake_train_data.veil.sum: 242.0\n",
      "fake_train_data.flash_lenses.sum: 264.0\n",
      "fake_train_data.hat.sum: 245.0\n",
      "fake_train_data.backgrouund.sum: 249.0\n"
     ]
    }
   ],
   "source": [
    "runner.produce_fake_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- setup data generators -------------------\n",
      "Starting data generators\n",
      "Found 500 validated image filenames.\n",
      "Found 100 validated image filenames.\n",
      "Found 50 validated image filenames.\n",
      "TOTAL: 650\n",
      "\n",
      "Logging class indices\n",
      " .. MTL model not logging class indices!\n",
      "\n",
      "Logging class labels\n",
      " COMPLIANT label: 1\n",
      " NON_COMPLIANT label: 0\n",
      " DUMMY label: -1\n",
      " DUMMY_CLS label: 2\n",
      " NO_ANSWER label: -99\n"
     ]
    }
   ],
   "source": [
    "runner.setup_data_generators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Architecture Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- run neural architecture search -------------------\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++ STARTING NEW TRAIN ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      " ----- Training 0 | Config: {'n_denses_0': 4, 'n_denses_1': 5, 'n_denses_2': 3, 'n_denses_3': 5} --------\n",
      "Creating model...\n",
      "Model created\n",
      "Training VGG16 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 15,759,854\n",
      "  .. Trainable params: 1,045,166\n",
      "  .. Non-trainable params: 14,714,688\n",
      "Epoch 1/2\n",
      "15/15 [==============================] - 22s 693ms/step - loss: 1.8650 - background_loss: 0.8015 - close_loss: 0.7622 - ink_mark_loss: 0.7461 - pixelation_loss: 0.7320 - washed_out_loss: 1.2136 - blurred_loss: 0.7453 - sh_head_loss: 0.8606 - mouth_loss: 0.7157 - veil_loss: 0.7385 - red_eyes_loss: 0.9083 - flash_lenses_loss: 0.8802 - dark_glasses_loss: 0.8728 - l_away_loss: 0.8978 - frame_eyes_loss: 0.8081 - hair_eyes_loss: 0.7620 - eyes_closed_loss: 0.8945 - frames_heavy_loss: 0.9037 - sh_face_loss: 0.7271 - skin_tone_loss: 0.7424 - light_loss: 0.7435 - hat_loss: 0.7347 - rotation_loss: 0.7388 - reflection_loss: 0.7210 - background_accuracy: 0.5107 - close_accuracy: 0.5128 - ink_mark_accuracy: 0.5385 - pixelation_accuracy: 0.5171 - washed_out_accuracy: 0.5256 - blurred_accuracy: 0.5107 - sh_head_accuracy: 0.5171 - mouth_accuracy: 0.5150 - veil_accuracy: 0.5256 - red_eyes_accuracy: 0.4936 - flash_lenses_accuracy: 0.5107 - dark_glasses_accuracy: 0.5406 - l_away_accuracy: 0.5085 - frame_eyes_accuracy: 0.4915 - hair_eyes_accuracy: 0.4915 - eyes_closed_accuracy: 0.4936 - frames_heavy_accuracy: 0.4808 - sh_face_accuracy: 0.4850 - skin_tone_accuracy: 0.4765 - light_accuracy: 0.5214 - hat_accuracy: 0.5064 - rotation_accuracy: 0.5150 - reflection_accuracy: 0.4509 - val_loss: 1.5940 - val_background_loss: 0.6928 - val_close_loss: 0.6906 - val_ink_mark_loss: 0.6934 - val_pixelation_loss: 0.6942 - val_washed_out_loss: 0.6863 - val_blurred_loss: 0.6931 - val_sh_head_loss: 0.6962 - val_mouth_loss: 0.6921 - val_veil_loss: 0.6932 - val_red_eyes_loss: 0.6920 - val_flash_lenses_loss: 0.6941 - val_dark_glasses_loss: 0.6926 - val_l_away_loss: 0.6956 - val_frame_eyes_loss: 0.6916 - val_hair_eyes_loss: 0.6941 - val_eyes_closed_loss: 0.6942 - val_frames_heavy_loss: 0.6922 - val_sh_face_loss: 0.6959 - val_skin_tone_loss: 0.6933 - val_light_loss: 0.6959 - val_hat_loss: 0.6931 - val_rotation_loss: 0.6929 - val_reflection_loss: 0.6908 - val_background_accuracy: 0.5208 - val_close_accuracy: 0.5417 - val_ink_mark_accuracy: 0.5000 - val_pixelation_accuracy: 0.4792 - val_washed_out_accuracy: 0.5938 - val_blurred_accuracy: 0.5104 - val_sh_head_accuracy: 0.4896 - val_mouth_accuracy: 0.5104 - val_veil_accuracy: 0.5417 - val_red_eyes_accuracy: 0.5312 - val_flash_lenses_accuracy: 0.4583 - val_dark_glasses_accuracy: 0.5104 - val_l_away_accuracy: 0.4271 - val_frame_eyes_accuracy: 0.5417 - val_hair_eyes_accuracy: 0.4896 - val_eyes_closed_accuracy: 0.4896 - val_frames_heavy_accuracy: 0.5417 - val_sh_face_accuracy: 0.4375 - val_skin_tone_accuracy: 0.5000 - val_light_accuracy: 0.4583 - val_hat_accuracy: 0.5208 - val_rotation_accuracy: 0.5625 - val_reflection_accuracy: 0.5312\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.59403, saving model to training_ckpt/best_model.hdf5\n",
      "Epoch 2/2\n",
      "15/15 [==============================] - 4s 279ms/step - loss: 1.5951 - background_loss: 0.6926 - close_loss: 0.6939 - ink_mark_loss: 0.6938 - pixelation_loss: 0.6930 - washed_out_loss: 0.6969 - blurred_loss: 0.6950 - sh_head_loss: 0.6931 - mouth_loss: 0.6933 - veil_loss: 0.6925 - red_eyes_loss: 0.6935 - flash_lenses_loss: 0.6941 - dark_glasses_loss: 0.6926 - l_away_loss: 0.6935 - frame_eyes_loss: 0.6937 - hair_eyes_loss: 0.6945 - eyes_closed_loss: 0.6931 - frames_heavy_loss: 0.6922 - sh_face_loss: 0.6929 - skin_tone_loss: 0.6927 - light_loss: 0.6932 - hat_loss: 0.6932 - rotation_loss: 0.6936 - reflection_loss: 0.6935 - background_accuracy: 0.5171 - close_accuracy: 0.5064 - ink_mark_accuracy: 0.5021 - pixelation_accuracy: 0.5235 - washed_out_accuracy: 0.4808 - blurred_accuracy: 0.4637 - sh_head_accuracy: 0.5128 - mouth_accuracy: 0.5000 - veil_accuracy: 0.5342 - red_eyes_accuracy: 0.5171 - flash_lenses_accuracy: 0.4829 - dark_glasses_accuracy: 0.5299 - l_away_accuracy: 0.4893 - frame_eyes_accuracy: 0.4872 - hair_eyes_accuracy: 0.4829 - eyes_closed_accuracy: 0.5128 - frames_heavy_accuracy: 0.5107 - sh_face_accuracy: 0.5214 - skin_tone_accuracy: 0.5064 - light_accuracy: 0.4722 - hat_accuracy: 0.4915 - rotation_accuracy: 0.4722 - reflection_accuracy: 0.5043 - val_loss: 1.5930 - val_background_loss: 0.6925 - val_close_loss: 0.6928 - val_ink_mark_loss: 0.6932 - val_pixelation_loss: 0.6926 - val_washed_out_loss: 0.6866 - val_blurred_loss: 0.6929 - val_sh_head_loss: 0.6928 - val_mouth_loss: 0.6932 - val_veil_loss: 0.6912 - val_red_eyes_loss: 0.6917 - val_flash_lenses_loss: 0.6935 - val_dark_glasses_loss: 0.6942 - val_l_away_loss: 0.6912 - val_frame_eyes_loss: 0.6928 - val_hair_eyes_loss: 0.6936 - val_eyes_closed_loss: 0.6932 - val_frames_heavy_loss: 0.6937 - val_sh_face_loss: 0.6916 - val_skin_tone_loss: 0.6932 - val_light_loss: 0.6943 - val_hat_loss: 0.6933 - val_rotation_loss: 0.6933 - val_reflection_loss: 0.6924 - val_background_accuracy: 0.5208 - val_close_accuracy: 0.5521 - val_ink_mark_accuracy: 0.5000 - val_pixelation_accuracy: 0.5312 - val_washed_out_accuracy: 0.5938 - val_blurred_accuracy: 0.5104 - val_sh_head_accuracy: 0.5104 - val_mouth_accuracy: 0.4896 - val_veil_accuracy: 0.5625 - val_red_eyes_accuracy: 0.5312 - val_flash_lenses_accuracy: 0.4583 - val_dark_glasses_accuracy: 0.4896 - val_l_away_accuracy: 0.5729 - val_frame_eyes_accuracy: 0.5417 - val_hair_eyes_accuracy: 0.4896 - val_eyes_closed_accuracy: 0.4583 - val_frames_heavy_accuracy: 0.4583 - val_sh_face_accuracy: 0.5625 - val_skin_tone_accuracy: 0.5000 - val_light_accuracy: 0.4583 - val_hat_accuracy: 0.4792 - val_rotation_accuracy: 0.4062 - val_reflection_accuracy: 0.5312\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.59403 to 1.59296, saving model to training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "4/4 [==============================] - 2s 319ms/step\n",
      "Prediction finished!\n",
      "{'config': {'n_denses_0': 4, 'n_denses_1': 5, 'n_denses_2': 3, 'n_denses_3': 5},\n",
      " 'final_ACC': 49.09,\n",
      " 'final_EER_mean': 50.91}\n",
      "--------------------------------------------------FINISHING TRAIN--------------------------------------------------\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++ STARTING NEW TRAIN ++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      " ----- Training 1 | Config: {'n_denses_0': 3, 'n_denses_1': 2, 'n_denses_2': 2, 'n_denses_3': 1} --------\n",
      "Creating model...\n",
      "Model created\n",
      "Training VGG16 network\n",
      " .. Not fine tuning base model...\n",
      "  .. Total params: 15,572,654\n",
      "  .. Trainable params: 857,966\n",
      "  .. Non-trainable params: 14,714,688\n",
      "Epoch 1/2\n",
      "15/15 [==============================] - 10s 372ms/step - loss: 2.3553 - background_loss: 1.0263 - close_loss: 0.7793 - ink_mark_loss: 0.7272 - pixelation_loss: 0.7381 - washed_out_loss: 0.7905 - blurred_loss: 0.7814 - sh_head_loss: 0.7479 - mouth_loss: 0.9007 - veil_loss: 1.3637 - red_eyes_loss: 1.6926 - flash_lenses_loss: 0.8223 - dark_glasses_loss: 0.9846 - l_away_loss: 0.9671 - frame_eyes_loss: 0.8791 - hair_eyes_loss: 0.9437 - eyes_closed_loss: 0.9730 - frames_heavy_loss: 1.0038 - sh_face_loss: 1.1897 - skin_tone_loss: 1.1255 - light_loss: 1.5568 - hat_loss: 1.2759 - rotation_loss: 0.8862 - reflection_loss: 1.3976 - background_accuracy: 0.4915 - close_accuracy: 0.5150 - ink_mark_accuracy: 0.4957 - pixelation_accuracy: 0.5043 - washed_out_accuracy: 0.4509 - blurred_accuracy: 0.4637 - sh_head_accuracy: 0.4786 - mouth_accuracy: 0.5021 - veil_accuracy: 0.5299 - red_eyes_accuracy: 0.4637 - flash_lenses_accuracy: 0.4936 - dark_glasses_accuracy: 0.5064 - l_away_accuracy: 0.4679 - frame_eyes_accuracy: 0.5342 - hair_eyes_accuracy: 0.5278 - eyes_closed_accuracy: 0.5406 - frames_heavy_accuracy: 0.4466 - sh_face_accuracy: 0.4915 - skin_tone_accuracy: 0.4957 - light_accuracy: 0.5470 - hat_accuracy: 0.4765 - rotation_accuracy: 0.5128 - reflection_accuracy: 0.4615 - val_loss: 1.5954 - val_background_loss: 0.6930 - val_close_loss: 0.6911 - val_ink_mark_loss: 0.6936 - val_pixelation_loss: 0.6933 - val_washed_out_loss: 0.6917 - val_blurred_loss: 0.6934 - val_sh_head_loss: 0.6935 - val_mouth_loss: 0.6929 - val_veil_loss: 0.6913 - val_red_eyes_loss: 0.6951 - val_flash_lenses_loss: 0.6909 - val_dark_glasses_loss: 0.6934 - val_l_away_loss: 0.6959 - val_frame_eyes_loss: 0.6965 - val_hair_eyes_loss: 0.6927 - val_eyes_closed_loss: 0.6941 - val_frames_heavy_loss: 0.6929 - val_sh_face_loss: 0.6947 - val_skin_tone_loss: 0.6929 - val_light_loss: 0.6987 - val_hat_loss: 0.6929 - val_rotation_loss: 0.6945 - val_reflection_loss: 0.6945 - val_background_accuracy: 0.5208 - val_close_accuracy: 0.5417 - val_ink_mark_accuracy: 0.5000 - val_pixelation_accuracy: 0.4583 - val_washed_out_accuracy: 0.5938 - val_blurred_accuracy: 0.5104 - val_sh_head_accuracy: 0.4896 - val_mouth_accuracy: 0.5104 - val_veil_accuracy: 0.5625 - val_red_eyes_accuracy: 0.4688 - val_flash_lenses_accuracy: 0.5417 - val_dark_glasses_accuracy: 0.4896 - val_l_away_accuracy: 0.4271 - val_frame_eyes_accuracy: 0.4583 - val_hair_eyes_accuracy: 0.5104 - val_eyes_closed_accuracy: 0.4896 - val_frames_heavy_accuracy: 0.5417 - val_sh_face_accuracy: 0.4375 - val_skin_tone_accuracy: 0.4896 - val_light_accuracy: 0.4583 - val_hat_accuracy: 0.5104 - val_rotation_accuracy: 0.4583 - val_reflection_accuracy: 0.4688\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.59535, saving model to training_ckpt/best_model.hdf5\n",
      "Epoch 2/2\n",
      "15/15 [==============================] - 4s 281ms/step - loss: 1.5943 - background_loss: 0.6932 - close_loss: 0.6923 - ink_mark_loss: 0.6920 - pixelation_loss: 0.6932 - washed_out_loss: 0.6932 - blurred_loss: 0.6941 - sh_head_loss: 0.6933 - mouth_loss: 0.6930 - veil_loss: 0.6931 - red_eyes_loss: 0.6940 - flash_lenses_loss: 0.6928 - dark_glasses_loss: 0.6929 - l_away_loss: 0.6927 - frame_eyes_loss: 0.6943 - hair_eyes_loss: 0.6929 - eyes_closed_loss: 0.6934 - frames_heavy_loss: 0.6932 - sh_face_loss: 0.6933 - skin_tone_loss: 0.6933 - light_loss: 0.6922 - hat_loss: 0.6935 - rotation_loss: 0.6939 - reflection_loss: 0.6936 - background_accuracy: 0.5171 - close_accuracy: 0.5342 - ink_mark_accuracy: 0.5278 - pixelation_accuracy: 0.5278 - washed_out_accuracy: 0.5021 - blurred_accuracy: 0.4893 - sh_head_accuracy: 0.5128 - mouth_accuracy: 0.5299 - veil_accuracy: 0.5299 - red_eyes_accuracy: 0.4808 - flash_lenses_accuracy: 0.5171 - dark_glasses_accuracy: 0.5150 - l_away_accuracy: 0.5235 - frame_eyes_accuracy: 0.4808 - hair_eyes_accuracy: 0.4850 - eyes_closed_accuracy: 0.5107 - frames_heavy_accuracy: 0.4936 - sh_face_accuracy: 0.5021 - skin_tone_accuracy: 0.4957 - light_accuracy: 0.5321 - hat_accuracy: 0.4957 - rotation_accuracy: 0.4808 - reflection_accuracy: 0.4915 - val_loss: 1.5947 - val_background_loss: 0.6927 - val_close_loss: 0.6921 - val_ink_mark_loss: 0.6937 - val_pixelation_loss: 0.6928 - val_washed_out_loss: 0.6957 - val_blurred_loss: 0.6930 - val_sh_head_loss: 0.6933 - val_mouth_loss: 0.6931 - val_veil_loss: 0.6924 - val_red_eyes_loss: 0.6945 - val_flash_lenses_loss: 0.6923 - val_dark_glasses_loss: 0.6933 - val_l_away_loss: 0.6948 - val_frame_eyes_loss: 0.6947 - val_hair_eyes_loss: 0.6931 - val_eyes_closed_loss: 0.6933 - val_frames_heavy_loss: 0.6935 - val_sh_face_loss: 0.6912 - val_skin_tone_loss: 0.6932 - val_light_loss: 0.6952 - val_hat_loss: 0.6936 - val_rotation_loss: 0.6917 - val_reflection_loss: 0.6940 - val_background_accuracy: 0.5208 - val_close_accuracy: 0.5417 - val_ink_mark_accuracy: 0.5000 - val_pixelation_accuracy: 0.5312 - val_washed_out_accuracy: 0.4062 - val_blurred_accuracy: 0.5104 - val_sh_head_accuracy: 0.4896 - val_mouth_accuracy: 0.5104 - val_veil_accuracy: 0.5625 - val_red_eyes_accuracy: 0.4688 - val_flash_lenses_accuracy: 0.5417 - val_dark_glasses_accuracy: 0.4896 - val_l_away_accuracy: 0.4271 - val_frame_eyes_accuracy: 0.4583 - val_hair_eyes_accuracy: 0.5104 - val_eyes_closed_accuracy: 0.4896 - val_frames_heavy_accuracy: 0.4583 - val_sh_face_accuracy: 0.5625 - val_skin_tone_accuracy: 0.5000 - val_light_accuracy: 0.4583 - val_hat_accuracy: 0.4792 - val_rotation_accuracy: 0.5521 - val_reflection_accuracy: 0.4688\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.59535 to 1.59471, saving model to training_ckpt/best_model.hdf5\n",
      "..Loading best model\n",
      "..Checkpoint weights loaded\n",
      "Testing Trained Model\n",
      "Predicting labels....\n",
      "4/4 [==============================] - 1s 64ms/step\n",
      "Prediction finished!\n",
      "{'config': {'n_denses_0': 3, 'n_denses_1': 2, 'n_denses_2': 2, 'n_denses_3': 1},\n",
      " 'final_ACC': 49.18,\n",
      " 'final_EER_mean': 50.0}\n",
      "--------------------------------------------------FINISHING TRAIN--------------------------------------------------\n",
      "memory_dict: {'model_0': {'final_EER_mean': 50.91, 'final_ACC': 49.09, 'config': {'n_denses_0': 4, 'n_denses_1': 5, 'n_denses_2': 3, 'n_denses_3': 5}}, 'model_1': {'final_EER_mean': 50.0, 'final_ACC': 49.18, 'config': {'n_denses_0': 3, 'n_denses_1': 2, 'n_denses_2': 2, 'n_denses_3': 1}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_0': {'final_EER_mean': 50.91,\n",
       "  'final_ACC': 49.09,\n",
       "  'config': {'n_denses_0': 4,\n",
       "   'n_denses_1': 5,\n",
       "   'n_denses_2': 3,\n",
       "   'n_denses_3': 5}},\n",
       " 'model_1': {'final_EER_mean': 50.0,\n",
       "  'final_ACC': 49.18,\n",
       "  'config': {'n_denses_0': 3,\n",
       "   'n_denses_1': 2,\n",
       "   'n_denses_2': 2,\n",
       "   'n_denses_3': 1}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.run_neural_architeture_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Network Modification"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Input, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_tensor = Input(shape=(20,), name=\"input\")\n",
    "hidden = Dense(100, activation='relu')(input_tensor)\n",
    "out = Dense(10, activation='relu', name=\"out\")(hidden)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=out)\n",
    "model.compile(loss=\"mse\", optimizer='adam')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "out = Dense(5, activation='softmax', name='new_out')(model.layers[-2].output)\n",
    "\n",
    "new_model = Model(input_tensor, out)\n",
    "new_model.summary()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "85f5044ba23e75135dc4c908fd4d7609c1c80b195047fdb4d16ee0e66a953254"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
